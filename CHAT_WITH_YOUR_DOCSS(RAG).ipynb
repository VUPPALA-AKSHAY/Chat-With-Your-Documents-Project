{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VUPPALA-AKSHAY/Chat-With-Your-Documents-Project/blob/main/CHAT_WITH_YOUR_DOCSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "X9KuOb1CkLwS",
        "outputId": "3349d740-7ab5-4e86-a995-b308c315b0ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.13 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.13)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.28)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (2.27.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6qT9FSJ0mTkx",
        "outputId": "c9913986-0ea5-40a7-f9e5-73452bbdbb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain-community\n",
            "Version: 0.3.13\n",
            "Summary: Community contributed LangChain integrations.\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, dataclasses-json, httpx-sse, langchain, langchain-core, langsmith, numpy, pydantic-settings, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "pip show langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QbFaH3kQwKA-"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypdf"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zemxcXAGpK58",
        "outputId": "6ad85c60-13c2-47b2-fe68-c5d0ab3b1a81"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install docx2txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VuOTLCa-pFwJ",
        "outputId": "b960407e-33c3-4cb0-aab3-eb5342acdb0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.10/dist-packages (0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "8R4n993iw3a1"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H9dd0_Qsz9fG"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFDirectoryLoader('/content/DOCUMENTS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zaed0CifOLEj"
      },
      "outputs": [],
      "source": [
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DcupfMri0AVE",
        "outputId": "e16a53ce-bdc8-4e66-d25e-8ab51e2141d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.13 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.13)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.28)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (0.3.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain-community) (2.10.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.13->langchain-community) (2.27.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0Wt_O1Zu1hzW",
        "outputId": "72d15379-ddd1-4397-c4df-bd89fbd54211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WjSKtgXm1ngB"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OorA3sAc5cOw"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "erpbyTy96lIg"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-x8p1nbZ6s1I"
      },
      "outputs": [],
      "source": [
        "text = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HBvnTacB6yMp",
        "outputId": "c0edda6e-2cc2-4764-b409-fdfb3e23bcfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 0}, page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/277411157\\nDeep Learning\\nArticle\\xa0\\xa0in \\xa0\\xa0Nature · May 2015\\nDOI: 10.1038/nature14539\\xa0·\\xa0Source: PubMed\\nCITATIONS\\n62,682\\nREADS\\n224,697\\n3 authors, including:\\nY. Bengio\\nUniversité de Montréal\\n915 PUBLICATIONS\\xa0\\xa0\\xa0519,140 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll content following this page was uploaded by Y. Bengio on 28 August 2015.\\nThe user has requested enhancement of the downloaded file.'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 1}, page_content='1Facebook AI Research, 770 Broadway, New York, New York 10003 USA. 2New York University, 715 Broadway, New York, New York 10003, USA. 3Department of Computer Science and Operations \\nResearch Université de Montréal, Pavillon André-Aisenstadt, PO Box 6128  Centre-Ville STN Montréal, Quebec H3C 3J7, Canada. 4Google, 1600 Amphitheatre Parkway, Mountain View, California \\n94043, USA. 5Department of Computer Science, University of Toronto, 6 King’s College Road, Toronto, Ontario M5S 3G4, Canada.\\nM\\nachine-learning technology powers many aspects of modern \\nsociety: from web searches to content filtering on social net-\\nworks to recommendations on e-commerce websites, and \\nit is increasingly present in consumer products such as cameras and \\nsmartphones. Machine-learning systems are used to identify objects \\nin images, transcribe speech into text, match news items, posts or \\nproducts with users’ interests, and select relevant results of search. \\nIncreasingly, these applications make use of a class of techniques called \\ndeep learning. \\nConventional machine-learning techniques were limited in their \\nability to process natural data in their raw form. For decades, con -\\nstructing a pattern-recognition or machine-learning system required \\ncareful engineering and considerable domain expertise to design a fea-\\nture extractor that transformed the raw data (such as the pixel values \\nof an image) into a suitable internal representation or feature vector \\nfrom which the learning subsystem, often a classifier, could detect or \\nclassify patterns in the input. \\nRepresentation learning is a set of methods that allows a machine to \\nbe fed with raw data and to automatically discover the representations \\nneeded for detection or classification. Deep-learning methods are \\nrepresentation-learning methods with multiple levels of representa-\\ntion, obtained by composing simple but non-linear modules that each \\ntransform the representation at one level (starting with the raw input) \\ninto a representation at a higher, slightly more abstract level. With the \\ncomposition of enough such transformations, very complex functions \\ncan be learned. For classification tasks, higher layers of representation \\namplify aspects of the input that are important for discrimination and \\nsuppress irrelevant variations. An image, for example, comes in the \\nform of an array of pixel values, and the learned features in the first \\nlayer of representation typically represent the presence or absence of \\nedges at particular orientations and locations in the image. The second \\nlayer typically detects motifs by spotting particular arrangements of \\nedges, regardless of small variations in the edge positions. The third \\nlayer may assemble motifs into larger combinations that correspond \\nto parts of familiar objects, and subsequent layers would detect objects \\nas combinations of these parts. The key aspect of deep learning is that \\nthese layers of features are not designed by human engineers: they \\nare learned from data using a general-purpose learning procedure. \\nDeep learning is making major advances in solving problems that \\nhave resisted the best attempts of the artificial intelligence commu-\\nnity for many years. It has turned out to be very good at discovering \\nintricate structures in high-dimensional data and is therefore applica-\\nble to many domains of science, business and government. In addition \\nto beating records in image recognition1–4 and speech recognition5–7, it \\nhas beaten other machine-learning techniques at predicting the activ-\\nity of potential drug molecules8, analysing particle accelerator data9,10, \\nreconstructing brain circuits11, and predicting the effects of mutations \\nin non-coding DNA on gene expression and disease12,13. Perhaps more \\nsurprisingly, deep learning has produced extremely promising results \\nfor various tasks in natural language understanding 14, particularly \\ntopic classification, sentiment analysis, question answering15 and lan-\\nguage translation16,17.'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 1}, page_content='ity of potential drug molecules8, analysing particle accelerator data9,10, \\nreconstructing brain circuits11, and predicting the effects of mutations \\nin non-coding DNA on gene expression and disease12,13. Perhaps more \\nsurprisingly, deep learning has produced extremely promising results \\nfor various tasks in natural language understanding 14, particularly \\ntopic classification, sentiment analysis, question answering15 and lan-\\nguage translation16,17. \\nWe think that deep learning will have many more successes in the \\nnear future because it requires very little engineering by hand, so it \\ncan easily take advantage of increases in the amount of available com-\\nputation and data. New learning algorithms and architectures that are \\ncurrently being developed for deep neural networks will only acceler-\\nate this progress. \\nSupervised learning \\nThe most common form of machine learning, deep or not, is super-\\nvised learning. Imagine that we want to build a system that can classify \\nimages as containing, say, a house, a car, a person or a pet. We first \\ncollect a large data set of images of houses, cars, people and pets, each \\nlabelled with its category. During training, the machine is shown an \\nimage and produces an output in the form of a vector of scores, one \\nfor each category. We want the desired category to have the highest \\nscore of all categories, but this is unlikely to happen before training. \\nWe compute an objective function that measures the error (or dis-\\ntance) between the output scores and the desired pattern of scores. The \\nmachine then modifies its internal adjustable parameters to reduce \\nthis error. These adjustable parameters, often called weights, are real \\nnumbers that can be seen as ‘knobs’ that define the input–output func-\\ntion of the machine. In a typical deep-learning system, there may be \\nhundreds of millions of these adjustable weights, and hundreds of \\nmillions of labelled examples with which to train the machine. \\nTo properly adjust the weight vector, the learning algorithm com-\\nputes a gradient vector that, for each weight, indicates by what amount \\nthe error would increase or decrease if the weight were increased by a \\ntiny amount. The weight vector is then adjusted in the opposite direc-\\ntion to the gradient vector. \\nThe objective function, averaged over all the training examples, can \\nDeep learning allows computational models that are composed of multiple processing layers to learn representations of \\ndata with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech rec-\\nognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep \\nlearning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine \\nshould change its internal parameters that are used to compute the representation in each layer from the representation in \\nthe previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and \\naudio, whereas recurrent nets have shone light on sequential data such as text and speech. \\nDeep learning\\nY ann LeCun1,2, Y oshua Bengio3 & Geoffrey Hinton4,5\\n436 | NATURE | VOL 521 | 28 MAY 2015\\nREVIEW\\ndoi:10.1038/nature14539\\n© 2015 Macmillan Publishers Limited. All rights reserved'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 2}, page_content='be seen as a kind of hilly landscape in the high-dimensional space of \\nweight values. The negative gradient vector indicates the direction \\nof steepest descent in this landscape, taking it closer to a minimum, \\nwhere the output error is low on average. \\nIn practice, most practitioners use a procedure called stochastic \\ngradient descent (SGD). This consists of showing the input vector \\nfor a few examples, computing the outputs and the errors, computing \\nthe average gradient for those examples, and adjusting the weights \\naccordingly. The process is repeated for many small sets of examples \\nfrom the training set until the average of the objective function stops \\ndecreasing. It is called stochastic because each small set of examples \\ngives a noisy estimate of the average gradient over all examples. This \\nsimple procedure usually finds a good set of weights surprisingly \\nquickly when compared with far more elaborate optimization tech-\\nniques18. After training, the performance of the system is measured \\non a different set of examples called a test set. This serves to test the \\ngeneralization ability of the machine — its ability to produce sensible \\nanswers on new inputs that it has never seen during training. \\nMany of the current practical applications of machine learning use \\nlinear classifiers on top of hand-engineered features. A two-class linear \\nclassifier computes a weighted sum of the feature vector components. \\nIf the weighted sum is above a threshold, the input is classified as \\nbelonging to a particular category. \\nSince the 1960s we have known that linear classifiers can only carve \\ntheir input space into very simple regions, namely half-spaces sepa-\\nrated by a hyperplane19. But problems such as image and speech recog-\\nnition require the input–output function to be insensitive to irrelevant \\nvariations of the input, such as variations in position, orientation or \\nillumination of an object, or variations in the pitch or accent of speech, \\nwhile being very sensitive to particular minute variations (for example, \\nthe difference between a white wolf and a breed of wolf-like white \\ndog called a Samoyed). At the pixel level, images of two Samoyeds in \\ndifferent poses and in different environments may be very different \\nfrom each other, whereas two images of a Samoyed and a wolf in the \\nsame position and on similar backgrounds may be very similar to each \\nother. A linear classifier, or any other ‘shallow’ classifier operating on \\nFigure 1 | Multilayer neural networks and backpropagation. a, A multi-\\nlayer neural network (shown by the connected dots) can distort the input \\nspace to make the classes of data (examples of which are on the red and \\nblue lines) linearly separable. Note how a regular grid (shown on the left) \\nin input space is also transformed (shown in the middle panel) by hidden \\nunits. This is an illustrative example with only two input units, two hidden \\nunits and one output unit, but the networks used for object recognition \\nor natural language processing contain tens or hundreds of thousands of \\nunits. Reproduced with permission from C. Olah (http://colah.github.io/). \\nb, The chain rule of derivatives tells us how two small effects (that of a small \\nchange of x on y, and that of y on z) are composed. A small change Δx in \\nx gets transformed first into a small change Δy in y by getting multiplied \\nby ∂y/∂x (that is, the definition of partial derivative). Similarly, the change \\nΔy creates a change Δz in z. Substituting one equation into the other \\ngives the chain rule of derivatives — how Δx gets turned into Δz through \\nmultiplication by the product of ∂y/∂x and ∂z/∂x. It also works when x, \\ny and z are vectors (and the derivatives are Jacobian matrices). c, The \\nequations used for computing the forward pass in a neural net with two \\nhidden layers and one output layer, each constituting a module through \\nwhich one can backpropagate gradients. At each layer, we first compute'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 2}, page_content='gives the chain rule of derivatives — how Δx gets turned into Δz through \\nmultiplication by the product of ∂y/∂x and ∂z/∂x. It also works when x, \\ny and z are vectors (and the derivatives are Jacobian matrices). c, The \\nequations used for computing the forward pass in a neural net with two \\nhidden layers and one output layer, each constituting a module through \\nwhich one can backpropagate gradients. At each layer, we first compute \\nthe total input z to each unit, which is a weighted sum of the outputs of \\nthe units in the layer below. Then a non-linear function f(.) is applied to \\nz to get the output of the unit. For simplicity, we have omitted bias terms. \\nThe non-linear functions used in neural networks include the rectified \\nlinear unit (ReLU) f(z) = max(0,z), commonly used in recent years, as \\nwell as the more conventional sigmoids, such as the hyberbolic tangent, \\nf(z) = (exp(z) − exp(−z))/(exp(z) + exp(−z)) and logistic function logistic, \\nf(z) = 1/(1 + exp(−z)). d, The equations used for computing the backward \\npass. At each hidden layer we compute the error derivative with respect to \\nthe output of each unit, which is a weighted sum of the error derivatives \\nwith respect to the total inputs to the units in the layer above. We then \\nconvert the error derivative with respect to the output into the error \\nderivative with respect to the input by multiplying it by the gradient of f(z). \\nAt the output layer, the error derivative with respect to the output of a unit \\nis computed by differentiating the cost function. This gives yl − tl if the cost \\nfunction for unit l is 0.5(yl − tl)2, where tl is the target value. Once the ∂E/∂zk \\nis known, the error-derivative for the weight wjk on the connection from \\nunit j in the layer below is just yj ∂E/∂zk.\\nInput\\n(2)\\nOutput\\n(1 sigmoid)\\nHidden\\n(2 sigmoid)\\na b\\ndc\\ny\\ny x\\ny x\\uf0b6\\n\\uf0b6=y\\nz\\n\\uf0b6\\n\\uf0b6\\nx\\ny\\n\\uf0b6\\n\\uf0b6\\nz y\\nzz y\\uf0b6\\n\\uf0b6=/uni0394/uni0394\\n/uni0394/uni0394\\n/uni0394/uni0394z y\\nz\\nx\\ny x\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6=\\nx\\nz\\ny\\nz\\nxx\\ny\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6\\n\\uf0b6=\\nCompare outputs with correct \\nanswer to get error derivatives\\nj\\nk\\nE\\nyl\\n=yl tl\\nE\\nzl\\n= E\\nyl\\nyl\\nzl\\nl\\nE\\nyj\\n= wjk\\nE\\nzk\\nE\\nzj\\n= E\\nyj\\nyj\\nzj\\nE\\nyk\\n= wkl\\nE\\nzl\\nE\\nzk\\n= E\\nyk\\nyk\\nzk\\nwkl\\nwjk\\nwij\\ni\\nj\\nk\\nyl = f (zl )\\nzl = wkl yk\\nl\\nyj = f (zj )\\nzj = wij xi\\nyk = f (zk )\\nzk = wjk yj\\nOutput units \\nInput units \\nHidden units H2 \\nHidden units H1 \\nwkl\\nwjk\\nwij\\nk \\uf065 H2\\nk \\uf065 H2\\nI \\uf065 out\\nj \\uf065 H1\\ni \\uf065 Input\\ni\\n28 MAY 2015 | VOL 521 | NATURE | 437\\nREVIEWINSIGHT\\n© 2015 Macmillan Publishers Limited. All rights reserved'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 3}, page_content='raw pixels could not possibly distinguish the latter two, while putting \\nthe former two in the same category. This is why shallow classifiers \\nrequire a good feature extractor that solves the selectivity–invariance \\ndilemma — one that produces representations that are selective to \\nthe aspects of the image that are important for discrimination, but \\nthat are invariant to irrelevant aspects such as the pose of the animal. \\nTo make classifiers more powerful, one can use generic non-linear \\nfeatures, as with kernel methods20, but generic features such as those \\narising with the Gaussian kernel do not allow the learner to general-\\nize well far from the training examples21. The conventional option is \\nto hand design good feature extractors, which requires a consider -\\nable amount of engineering skill and domain expertise. But this can \\nall be avoided if good features can be learned automatically using a \\ngeneral-purpose learning procedure. This is the key advantage of \\ndeep learning. \\nA deep-learning architecture is a multilayer stack of simple mod -\\nules, all (or most) of which are subject to learning, and many of which \\ncompute non-linear input–output mappings. Each module in the \\nstack transforms its input to increase both the selectivity and the \\ninvariance of the representation. With multiple non-linear layers, say \\na depth of 5 to 20, a system can implement extremely intricate func-\\ntions of its inputs that are simultaneously sensitive to minute details \\n— distinguishing Samoyeds from white wolves — and insensitive to \\nlarge irrelevant variations such as the background, pose, lighting and \\nsurrounding objects. \\nBackpropagation to train multilayer architectures \\nFrom the earliest days of pattern recognition22,23, the aim of research-\\ners has been to replace hand-engineered features with trainable \\nmultilayer networks, but despite its simplicity, the solution was not \\nwidely understood until the mid 1980s. As it turns out, multilayer \\narchitectures can be trained by simple stochastic gradient descent. \\nAs long as the modules are relatively smooth functions of their inputs \\nand of their internal weights, one can compute gradients using the \\nbackpropagation procedure. The idea that this could be done, and \\nthat it worked, was discovered independently by several different \\ngroups during the 1970s and 1980s24–27.  \\nThe backpropagation procedure to compute the gradient of an \\nobjective function with respect to the weights of a multilayer stack \\nof modules is nothing more than a practical application of the chain \\nrule for derivatives. The key insight is that the derivative (or gradi -\\nent) of the objective with respect to the input of a module can be \\ncomputed by working backwards from the gradient with respect to \\nthe output of that module (or the input of the subsequent module) \\n(Fig.\\xa01). The backpropagation equation can be applied repeatedly to \\npropagate gradients through all modules, starting from the output \\nat the top (where the network produces its prediction) all the way to \\nthe bottom (where the external input is fed). Once these gradients \\nhave been computed, it is straightforward to compute the gradients \\nwith respect to the weights of each module. \\nMany applications of deep learning use feedforward neural net -\\nwork architectures (Fig. 1), which learn to map a fixed-size input \\n(for example, an image) to a fixed-size output (for example, a prob-\\nability for each of several categories). To go from one layer to the \\nnext, a set of units compute a weighted sum of their inputs from the \\nprevious layer and pass the result through a non-linear function. At \\npresent, the most popular non-linear function is the rectified linear \\nunit (ReLU), which is simply the half-wave rectifier f(z) = max(z, 0). \\nIn past decades, neural nets used smoother non-linearities, such as \\ntanh(z) or 1/(1 + exp(−z)), but the ReLU typically learns much faster \\nin networks with many layers, allowing training of a deep supervised'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 3}, page_content='next, a set of units compute a weighted sum of their inputs from the \\nprevious layer and pass the result through a non-linear function. At \\npresent, the most popular non-linear function is the rectified linear \\nunit (ReLU), which is simply the half-wave rectifier f(z) = max(z, 0). \\nIn past decades, neural nets used smoother non-linearities, such as \\ntanh(z) or 1/(1 + exp(−z)), but the ReLU typically learns much faster \\nin networks with many layers, allowing training of a deep supervised \\nnetwork without unsupervised pre-training 28. Units that are not in \\nthe input or output layer are conventionally called hidden units. The \\nhidden layers can be seen as distorting the input in a non-linear way \\nso that categories become linearly separable by the last layer (Fig.\\xa01). \\nIn the late 1990s, neural nets and backpropagation were largely \\nforsaken by the machine-learning community and ignored by the \\ncomputer-vision and speech-recognition communities. It was widely \\nthought that learning useful, multistage, feature extractors with lit -\\ntle prior knowledge was infeasible. In particular, it was commonly \\nthought that simple gradient descent would get trapped in poor local \\nminima — weight configurations for which no small change would \\nreduce the average error. \\nIn practice, poor local minima are rarely a problem with large net-\\nworks. Regardless of the initial conditions, the system nearly always \\nreaches solutions of very similar quality. Recent theoretical and \\nempirical results strongly suggest that local minima are not a serious \\nissue in general. Instead, the landscape is packed with a combinato -\\nrially large number of saddle points where the gradient is zero, and \\nthe surface curves up in most dimensions and curves down in the \\nFigure 2 | Inside a convolutional network. The outputs (not the filters) \\nof each layer (horizontally) of a typical convolutional network architecture \\napplied to the image of a Samoyed dog (bottom left; and RGB (red, green, \\nblue) inputs, bottom right). Each rectangular image is a feature map \\ncorresponding to the output for one of the learned features, detected at each \\nof the image positions. Information flows bottom up, with lower-level features \\nacting as oriented edge detectors, and a score is computed for each image class \\nin output. ReLU, rectified linear unit.\\nRed Green Blue\\nSamoyed (16); Papillon (5.7); Pomeranian (2.7); Arctic fox (1.0); Eskimo dog (0.6); white wolf (0.4); Siberian husky (0.4)\\nConvolutions and ReLU\\nMax pooling\\nMax pooling\\nConvolutions and ReLU\\nConvolutions and ReLU\\n438 | NATURE | VOL 521 | 28 MAY 2015\\nREVIEWINSIGHT\\n© 2015 Macmillan Publishers Limited. All rights reserved'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 4}, page_content='remainder29,30. The analysis seems to show that saddle points with \\nonly a few downward curving directions are present in very large \\nnumbers, but almost all of them have very similar values of the objec-\\ntive function. Hence, it does not much matter which of these saddle \\npoints the algorithm gets stuck at. \\nInterest in deep feedforward networks was revived around 2006 \\n(refs\\xa031–34) by a group of researchers brought together by the Cana-\\ndian Institute for Advanced Research (CIFAR). The researchers intro-\\nduced unsupervised learning procedures that could create layers of \\nfeature detectors without requiring labelled data. The objective in \\nlearning each layer of feature detectors was to be able to reconstruct \\nor model the activities of feature detectors (or raw inputs) in the layer \\nbelow. By ‘pre-training’ several layers of progressively more complex \\nfeature detectors using this reconstruction objective, the weights of a \\ndeep network could be initialized to sensible values. A final layer of \\noutput units could then be added to the top of the network and the \\nwhole deep system could be fine-tuned using standard backpropaga-\\ntion33–35. This worked remarkably well for recognizing handwritten \\ndigits or for detecting pedestrians, especially when the amount of \\nlabelled data was very limited 36. \\nThe first major application of this pre-training approach was in \\nspeech recognition, and it was made possible by the advent of fast \\ngraphics processing units (GPUs) that were convenient to program37 \\nand allowed researchers to train networks 10 or 20 times faster. In \\n2009, the approach was used to map short temporal windows of coef-\\nficients extracted from a sound wave to a set of probabilities for the \\nvarious fragments of speech that might be represented by the frame \\nin the centre of the window. It achieved record-breaking results on a \\nstandard speech recognition benchmark that used a small vocabu -\\nlary38 and was quickly developed to give record-breaking results on \\na large vocabulary task39. By 2012, versions of the deep net from 2009 \\nwere being developed by many of the major speech groups6 and were \\nalready being deployed in Android phones. For smaller data sets, \\nunsupervised pre-training helps to prevent overfitting 40, leading to \\nsignificantly better generalization when the number of labelled exam-\\nples is small, or in a transfer setting where we have lots of examples \\nfor some ‘source’ tasks but very few for some ‘target’ tasks. Once deep \\nlearning had been rehabilitated, it turned out that the pre-training \\nstage was only needed for small data sets. \\nThere was, however, one particular type of deep, feedforward net-\\nwork that was much easier to train and generalized much better than \\nnetworks with full connectivity between adjacent layers. This was \\nthe convolutional neural network (ConvNet) 41,42. It achieved many \\npractical successes during the period when neural networks were out \\nof favour and it has recently been widely adopted by the computer-\\nvision community. \\nConvolutional neural networks \\nConvNets are designed to process data that come in the form of \\nmultiple arrays, for example a colour image composed of three 2D \\narrays containing pixel intensities in the three colour channels. Many \\ndata modalities are in the form of multiple arrays: 1D for signals and \\nsequences, including language; 2D for images or audio spectrograms; \\nand 3D for video or volumetric images. There are four key ideas \\nbehind ConvNets that take advantage of the properties of natural \\nsignals: local connections, shared weights, pooling and the use of \\nmany layers. \\nThe architecture of a typical ConvNet (Fig. 2) is structured as a \\nseries of stages. The first few stages are composed of two types of \\nlayers: convolutional layers and pooling layers. Units in a convolu -\\ntional layer are organized in feature maps, within which each unit \\nis connected to local patches in the feature maps of the previous'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 4}, page_content='behind ConvNets that take advantage of the properties of natural \\nsignals: local connections, shared weights, pooling and the use of \\nmany layers. \\nThe architecture of a typical ConvNet (Fig. 2) is structured as a \\nseries of stages. The first few stages are composed of two types of \\nlayers: convolutional layers and pooling layers. Units in a convolu -\\ntional layer are organized in feature maps, within which each unit \\nis connected to local patches in the feature maps of the previous \\nlayer through a set of weights called a filter bank. The result of this \\nlocal weighted sum is then passed through a non-linearity such as a \\nReLU. All units in a feature map share the same filter bank. Differ -\\nent feature maps in a layer use different filter banks. The reason for \\nthis architecture is twofold. First, in array data such as images, local \\ngroups of values are often highly correlated, forming distinctive local \\nmotifs that are easily detected. Second, the local statistics of images \\nand other signals are invariant to location. In other words, if a motif \\ncan appear in one part of the image, it could appear anywhere, hence \\nthe idea of units at different locations sharing the same weights and \\ndetecting the same pattern in different parts of the array. Mathemati-\\ncally, the filtering operation performed by a feature map is a discrete \\nconvolution, hence the name. \\nAlthough the role of the convolutional layer is to detect local con-\\njunctions of features from the previous layer, the role of the pooling \\nlayer is to merge semantically similar features into one. Because the \\nrelative positions of the features forming a motif can vary somewhat, \\nreliably detecting the motif can be done by coarse-graining the posi-\\ntion of each feature. A typical pooling unit computes the maximum  \\nof a local patch of units in one feature map (or in a few feature maps). \\nNeighbouring pooling units take input from patches that are shifted \\nby more than one row or column, thereby reducing the dimension of \\nthe representation and creating an invariance to small shifts and dis-\\ntortions. Two or three stages of convolution, non-linearity and pool-\\ning are stacked, followed by more convolutional and fully-connected \\nlayers. Backpropagating gradients through a ConvNet is as simple as \\nthrough a regular deep network, allowing all the weights in all the \\nfilter banks to be trained. \\nDeep neural networks exploit the property that many natural sig-\\nnals are compositional hierarchies, in which higher-level features \\nare obtained by composing lower-level ones. In images, local combi-\\nnations of edges form motifs, motifs assemble into parts, and parts \\nform objects. Similar hierarchies exist in speech and text from sounds \\nto phones, phonemes, syllables, words and sentences. The pooling \\nallows representations to vary very little when elements in the previ-\\nous layer vary in position and appearance. \\nThe convolutional and pooling layers in ConvNets are directly \\ninspired by the classic notions of simple cells and complex cells in \\nvisual neuroscience 43, and the overall architecture is reminiscent of \\nthe LGN–V1–V2–V4–IT hierarchy in the visual cortex ventral path-\\nway44. When ConvNet models and monkeys are shown the same pic-\\nture, the activations of high-level units in the ConvNet explains half \\nof the variance of random sets of 160\\xa0neurons in the monkey’s infer-\\notemporal cortex45. ConvNets have their roots in the neocognitron46, \\nthe architecture of which was somewhat similar, but did not have an \\nend-to-end supervised-learning algorithm such as backpropagation. \\nA primitive 1D ConvNet called a time-delay neural net was used for \\nthe recognition of phonemes and simple words47,48. \\nThere have been numerous applications of convolutional net -\\nworks going back to the early 1990s, starting with time-delay neu -\\nral networks for speech recognition 47 and document reading42. The \\ndocument reading system used a ConvNet trained jointly with a'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 4}, page_content='end-to-end supervised-learning algorithm such as backpropagation. \\nA primitive 1D ConvNet called a time-delay neural net was used for \\nthe recognition of phonemes and simple words47,48. \\nThere have been numerous applications of convolutional net -\\nworks going back to the early 1990s, starting with time-delay neu -\\nral networks for speech recognition 47 and document reading42. The \\ndocument reading system used a ConvNet trained jointly with a \\nprobabilistic model that implemented language constraints. By the \\nlate 1990s this system was reading over 10% of all the cheques in the \\nUnited States. A number of ConvNet-based optical character recog-\\nnition and handwriting recognition systems were later deployed by \\nMicrosoft49. ConvNets were also experimented with in the early 1990s \\nfor object detection in natural images, including faces and hands50,51, \\nand for face recognition52. \\nImage understanding with deep convolutional networks \\nSince the early 2000s, ConvNets have been applied with great success to \\nthe detection, segmentation and recognition of objects and regions in \\nimages. These were all tasks in which labelled data was relatively abun-\\ndant, such as traffic sign recognition53, the segmentation of biological \\nimages54 particularly for connectomics55, and the detection of faces, \\ntext, pedestrians and human bodies in natural images36,50,51,56–58. A major \\nrecent practical success of ConvNets is face recognition59. \\nImportantly, images can be labelled at the pixel level, which will have \\napplications in technology, including autonomous mobile robots and \\n28 MAY 2015 | VOL 521 | NATURE | 439\\nREVIEWINSIGHT\\n© 2015 Macmillan Publishers Limited. All rights reserved'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 5}, page_content='self-driving cars 60,61. Companies such as Mobileye and NVIDIA are \\nusing such ConvNet-based methods in their upcoming vision sys -\\ntems for cars. Other applications gaining importance involve natural \\nlanguage understanding 14 and speech recognition7. \\nDespite these successes, ConvNets were largely forsaken by the \\nmainstream computer-vision and machine-learning communities \\nuntil the ImageNet competition in 2012. When deep convolutional \\nnetworks were applied to a data set of about a million images from \\nthe web that contained 1,000 different classes, they achieved spec -\\ntacular results, almost halving the error rates of the best compet -\\ning approaches1. This success came from the efficient use of GPUs, \\nReLUs, a new regularization technique called dropout 62, and tech-\\nniques to generate more training examples by deforming the existing \\nones. This success has brought about a revolution in computer vision; \\nConvNets are now the dominant approach for almost all recognition \\nand detection tasks 4,58,59,63–65  and approach human performance on \\nsome tasks. A recent stunning demonstration combines ConvNets \\nand recurrent net modules for the generation of image captions \\n(Fig.\\xa03). \\nRecent ConvNet architectures have 10 to 20 layers of ReLUs, hun-\\ndreds of millions of weights, and billions of connections between \\nunits. Whereas training such large networks could have taken weeks \\nonly two years ago, progress in hardware, software and algorithm \\nparallelization have reduced training times to a few hours. \\nThe performance of ConvNet-based vision systems has caused \\nmost major technology companies, including Google, Facebook, \\nMicrosoft, IBM, Y ahoo!, Twitter and Adobe, as well as a quickly \\ngrowing number of start-ups to initiate research and development \\nprojects and to deploy ConvNet-based image understanding products \\nand services. \\nConvNets are easily amenable to efficient hardware implemen -\\ntations in chips or field-programmable gate arrays 66,67. A number \\nof companies such as NVIDIA, Mobileye, Intel, Qualcomm and \\nSamsung are developing ConvNet chips to enable real-time vision \\napplications in smartphones, cameras, robots and self-driving cars. \\nDistributed representations and language processing \\nDeep-learning theory shows that deep nets have two different expo-\\nnential advantages over classic learning algorithms that do not use \\ndistributed representations21. Both of these advantages arise from the \\npower of composition and depend on the underlying data-generating \\ndistribution having an appropriate componential structure 40. First, \\nlearning distributed representations enable generalization to new \\ncombinations of the values of learned features beyond those seen \\nduring training (for example, 2 n combinations are possible with n \\nbinary features) 68,69. Second, composing layers of representation in \\na deep net brings the potential for another exponential advantage 70 \\n(exponential in the depth). \\nThe hidden layers of a multilayer neural network learn to repre -\\nsent the network’s inputs in a way that makes it easy to predict the \\ntarget outputs. This is nicely demonstrated by training a multilayer \\nneural network to predict the next word in a sequence from a local \\nFigure 3 | From image to text. Captions generated by a recurrent neural \\nnetwork (RNN) taking, as extra input, the representation extracted by a deep \\nconvolution neural network (CNN) from a test image, with the RNN trained to \\n‘translate’ high-level representations of images into captions (top). Reproduced \\nwith permission from ref. 102. When the RNN is given the ability to focus its \\nattention on a different location in the input image (middle and bottom; the \\nlighter patches were given more attention) as it generates each word (bold), we \\nfound86 that it exploits this to achieve better ‘translation’ of images into captions.\\nVision\\nDeep CNN\\nLanguage\\nGenerating RNN\\nA group of people \\nshopping at an outdoor \\nmarket.\\nThere are many \\nvegetables at the'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 5}, page_content='with permission from ref. 102. When the RNN is given the ability to focus its \\nattention on a different location in the input image (middle and bottom; the \\nlighter patches were given more attention) as it generates each word (bold), we \\nfound86 that it exploits this to achieve better ‘translation’ of images into captions.\\nVision\\nDeep CNN\\nLanguage\\nGenerating RNN\\nA group of people \\nshopping at an outdoor \\nmarket.\\nThere are many \\nvegetables at the \\nfruit stand.\\nA woman is throwing a frisbee in a park.\\nA little girl sitting on a bed with a teddy bear. A group of people sitting on a boat in the water. A giraﬀe standing in a forest with\\ntrees in the background.\\nA dog is standing on a hardwood /f_loor. A stop sign is on a road with a\\nmountain in the background\\n440 | NATURE | VOL 521 | 28 MAY 2015\\nREVIEWINSIGHT\\n© 2015 Macmillan Publishers Limited. All rights reserved'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 6}, page_content='context of earlier words71. Each word in the context is presented to \\nthe network as a one-of-N vector, that is, one component has a value \\nof 1 and the rest are\\xa00. In the first layer, each word creates a different \\npattern of activations, or word vectors (Fig.\\xa04). In a language model, \\nthe other layers of the network learn to convert the input word vec -\\ntors into an output word vector for the predicted next word, which \\ncan be used to predict the probability for any word in the vocabulary \\nto appear as the next word. The network learns word vectors that \\ncontain many active components each of which can be interpreted \\nas a separate feature of the word, as was first demonstrated 27 in the \\ncontext of learning distributed representations for symbols. These \\nsemantic features were not explicitly present in the input. They were \\ndiscovered by the learning procedure as a good way of factorizing \\nthe structured relationships between the input and output symbols \\ninto multiple ‘micro-rules’ . Learning word vectors turned out to also \\nwork very well when the word sequences come from a large corpus \\nof real text and the individual micro-rules are unreliable 71. When \\ntrained to predict the next word in a news story, for example, the \\nlearned word vectors for Tuesday and Wednesday are very similar, as \\nare the word vectors for Sweden and Norway. Such representations \\nare called distributed representations because their elements (the \\nfeatures) are not mutually exclusive and their many configurations \\ncorrespond to the variations seen in the observed data. These word \\nvectors are composed of learned features that were not determined \\nahead of time by experts, but automatically discovered by the neural \\nnetwork. Vector representations of words learned from text are now \\nvery widely used in natural language applications 14,17,72–76. \\nThe issue of representation lies at the heart of the debate between \\nthe logic-inspired and the neural-network-inspired paradigms for \\ncognition. In the logic-inspired paradigm, an instance of a symbol is \\nsomething for which the only property is that it is either identical or \\nnon-identical to other symbol instances. It has no internal structure \\nthat is relevant to its use; and to reason with symbols, they must be \\nbound to the variables in judiciously chosen rules of inference. By \\ncontrast, neural networks just use big activity vectors, big weight \\nmatrices and scalar non-linearities to perform the type of fast ‘intui-\\ntive’ inference that underpins effortless commonsense reasoning. \\nBefore the introduction of neural language models71, the standard \\napproach to statistical modelling of language did not exploit distrib-\\nuted representations: it was based on counting frequencies of occur-\\nrences of short symbol sequences of length up to N (called N-grams). \\nThe number of possible N-grams is on the order of V N, where V is \\nthe vocabulary size, so taking into account a context of more than a \\nhandful of words would require very large training corpora. N-grams \\ntreat each word as an atomic unit, so they cannot generalize across \\nsemantically related sequences of words, whereas neural language \\nmodels can because they associate each word with a vector of real \\nvalued features, and semantically related words end up close to each \\nother in that vector space (Fig.\\xa04). \\nRecurrent neural networks \\nWhen backpropagation was first introduced, its most exciting use was \\nfor training recurrent neural networks (RNNs). For tasks that involve \\nsequential inputs, such as speech and language, it is often better to \\nuse RNNs (Fig. 5). RNNs process an input sequence one element at a \\ntime, maintaining in their hidden units a ‘state vector’ that implicitly \\ncontains information about the history of all the past elements of \\nthe sequence. When we consider the outputs of the hidden units at \\ndifferent discrete time steps as if they were the outputs of different'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 6}, page_content='for training recurrent neural networks (RNNs). For tasks that involve \\nsequential inputs, such as speech and language, it is often better to \\nuse RNNs (Fig. 5). RNNs process an input sequence one element at a \\ntime, maintaining in their hidden units a ‘state vector’ that implicitly \\ncontains information about the history of all the past elements of \\nthe sequence. When we consider the outputs of the hidden units at \\ndifferent discrete time steps as if they were the outputs of different \\nneurons in a deep multilayer network (Fig.\\xa05, right), it becomes clear \\nhow we can apply backpropagation to train RNNs. \\nRNNs are very powerful dynamic systems, but training them has \\nproved to be problematic because the backpropagated gradients \\neither grow or shrink at each time step, so over many time steps they \\ntypically explode or vanish77,78. \\nThanks to advances in their architecture 79,80 and ways of training \\nthem81,82, RNNs have been found to be very good at predicting the \\nnext character in the text83 or the next word in a sequence75, but they \\ncan also be used for more complex tasks. For example, after reading \\nan English sentence one word at a time, an English ‘encoder’ network \\ncan be trained so that the final state vector of its hidden units is a good \\nrepresentation of the thought expressed by the sentence. This thought \\nvector can then be used as the initial hidden state of (or as extra input \\nto) a jointly trained French ‘decoder’ network, which outputs a prob-\\nability distribution for the first word of the French translation. If a \\nparticular first word is chosen from this distribution and provided \\nas input to the decoder network it will then output a probability dis-\\ntribution for the second word of the translation and so on until a \\nfull stop is chosen17,72,76. Overall, this process generates sequences of \\nFrench words according to a probability distribution that depends on \\nthe English sentence. This rather naive way of performing machine \\ntranslation has quickly become competitive with the state-of-the-art, \\nand this raises serious doubts about whether understanding a sen -\\ntence requires anything like the internal symbolic expressions that are \\nmanipulated by using inference rules. It is more compatible with the \\nview that everyday reasoning involves many simultaneous analogies \\nFigure 4 | Visualizing the learned word vectors. On the left is an illustration \\nof word representations learned for modelling language, non-linearly projected \\nto 2D for visualization using the t-SNE algorithm103. On the right is a 2D \\nrepresentation of phrases learned by an English-to-French encoder–decoder \\nrecurrent neural network75. One can observe that semantically similar words \\nor sequences of words are mapped to nearby representations. The distributed \\nrepresentations of words are obtained by using backpropagation to jointly learn \\na representation for each word and a function that predicts a target quantity \\nsuch as the next word in a sequence (for language modelling) or a whole \\nsequence of translated words (for machine translation)18,75.\\n−37 −36 −35 −34 −33 −32 −31 −30 −29\\n9\\n10\\n10.5\\n11\\n11.5\\n12\\n12.5\\n13\\n13.5\\n14\\n community\\n organizations institutions\\n society\\n industry company\\n organization\\n school\\n companies\\n Community\\n oﬃce\\n Agency\\n communities\\n Association\\n body\\n schools\\n agencies\\n−5.5 −5 −4.5 −4 −3.5 −3 −2.5 −2\\n−4.2\\n−4\\n−3.8\\n−3.6\\n−3.4\\n−3.2\\n−3\\n−2.8\\n−2.6\\n−2.4\\n−2.2\\nover the past few months\\nthat a few days\\nIn the last few daysthe past few days\\nIn a few months\\nin the coming months\\na few months ago\\n&quot; the two groups\\nof the two groups\\nover the last few months\\ndispute between the two\\nthe last two decades\\nthe next six months\\ntwo months before being\\nfor nearly two months\\nover the last two decades\\nwithin a few months\\n28 MAY 2015 | VOL 521 | NATURE | 441\\nREVIEWINSIGHT\\n© 2015 Macmillan Publishers Limited. All rights reserved'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 7}, page_content='that each contribute plausibility to a conclusion84,85. \\nInstead of translating the meaning of a French sentence into  an \\nEnglish sentence, one can learn to ‘translate’ the meaning of an image \\ninto an English sentence (Fig. 3). The encoder here is a deep Con -\\nvNet that converts the pixels into an activity vector in its last hidden \\nlayer. The decoder is an RNN similar to the ones used for machine \\ntranslation and neural language modelling. There has been a surge of \\ninterest in such systems recently (see examples mentioned in ref. 86). \\nRNNs, once unfolded in time (Fig. 5), can be seen as very deep \\nfeedforward networks in which all the layers share the same weights. \\nAlthough their main purpose is to learn long-term dependencies, \\ntheoretical and empirical evidence shows that it is difficult to learn \\nto store information for very long78.  \\nTo correct for that, one idea is to augment the network with an \\nexplicit memory. The first proposal of this kind is the long short-term \\nmemory (LSTM) networks that use special hidden units, the natural \\nbehaviour of which is to remember inputs for a long time79. A special \\nunit called the memory cell acts like an accumulator or a gated leaky \\nneuron: it has a connection to itself at the next time step that has a \\nweight of one, so it copies its own real-valued state and accumulates \\nthe external signal, but this self-connection is multiplicatively gated \\nby another unit that learns to decide when to clear the content of the \\nmemory. \\nLSTM networks have subsequently proved to be more effective \\nthan conventional RNNs, especially when they have several layers for \\neach time step87, enabling an entire speech recognition system that \\ngoes all the way from acoustics to the sequence of characters in the \\ntranscription. LSTM networks or related forms of gated units are also \\ncurrently used for the encoder and decoder networks that perform \\nso well at machine translation17,72,76. \\nOver the past year, several authors have made different proposals to \\naugment RNNs with a memory module. Proposals include the Neural \\nTuring Machine in which the network is augmented by a ‘tape-like’ \\nmemory that the RNN can choose to read from or write to 88, and \\nmemory networks, in which a regular network is augmented by a \\nkind of associative memory89. Memory networks have yielded excel-\\nlent performance on standard question-answering benchmarks. The \\nmemory is used to remember the story about which the network is \\nlater asked to answer questions. \\nBeyond simple memorization, neural Turing machines and mem-\\nory networks are being used for tasks that would normally require \\nreasoning and symbol manipulation. Neural Turing machines can \\nbe taught ‘algorithms’ . Among other things, they can learn to output \\na sorted list of symbols when their input consists of an unsorted \\nsequence in which each symbol is accompanied by a real value that \\nindicates its priority in the list 88. Memory networks can be trained \\nto keep track of the state of the world in a setting similar to a text \\nadventure game and after reading a story, they can answer questions \\nthat require complex inference90. In one test example, the network is \\nshown a 15-sentence version of the The Lord of the Rings and correctly \\nanswers questions such as “where is Frodo now?”89.  \\nThe future of deep learning \\nUnsupervised learning91–98 had a catalytic effect in reviving interest in \\ndeep learning, but has since been overshadowed by the successes of \\npurely supervised learning. Although we have not focused on it in this \\nReview, we expect unsupervised learning to become far more important \\nin the longer term. Human and animal learning is largely unsupervised: \\nwe discover the structure of the world by observing it, not by being told \\nthe name of every object. \\nHuman vision is an active process that sequentially samples the optic \\narray in an intelligent, task-speciﬁc way using a small, high-resolution'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 7}, page_content='purely supervised learning. Although we have not focused on it in this \\nReview, we expect unsupervised learning to become far more important \\nin the longer term. Human and animal learning is largely unsupervised: \\nwe discover the structure of the world by observing it, not by being told \\nthe name of every object. \\nHuman vision is an active process that sequentially samples the optic \\narray in an intelligent, task-speciﬁc way using a small, high-resolution \\nfovea with a large, low-resolution surround. We expect much of the \\nfuture progress in vision to come from systems that are trained end-to-\\nend and combine ConvNets with RNNs that use reinforcement learning \\nto decide where to look. Systems combining deep learning and rein-\\nforcement learning are in their infancy, but they already outperform \\npassive vision systems99 at classification tasks and produce impressive \\nresults in learning to play many different video games100. \\nNatural language understanding is another area in which deep learn-\\ning is poised to make a large impact over the next few years. We expect \\nsystems that use RNNs to understand sentences or whole documents \\nwill become much better when they learn strategies for selectively \\nattending to one part at a time76,86. \\nUltimately, major progress in artificial intelligence will come about \\nthrough systems that combine representation learning with complex \\nreasoning. Although deep learning and simple reasoning have been \\nused for speech and handwriting recognition for a long time, new \\nparadigms are needed to replace rule-based manipulation of symbolic \\nexpressions by operations on large vectors101. ■\\nReceived 25 February; accepted 1 May 2015.\\n1. Krizhevsky, A., Sutskever, I. & Hinton, G. ImageNet classification with deep \\nconvolutional neural networks. In Proc. Advances in Neural Information \\nProcessing Systems 25 1090–1098 (2012).\\n This report was a breakthrough that used convolutional nets to almost halve \\nthe error rate for object recognition, and precipitated the rapid adoption of \\ndeep learning by the computer vision community.\\n2. Farabet, C., Couprie, C., Najman, L. & LeCun, Y. Learning hierarchical features for \\nscene labeling. IEEE Trans. Pattern Anal. Mach. Intell. 35, 1915–1929 (2013). \\n3. Tompson, J., Jain, A., LeCun, Y. & Bregler, C. Joint training of a convolutional \\nnetwork and a graphical model for human pose estimation. In Proc. Advances in \\nNeural Information Processing Systems 27 1799–1807 (2014). \\n4. Szegedy, C. et al. Going deeper with convolutions. Preprint at http://arxiv.org/\\nabs/1409.4842 (2014). \\n5. Mikolov, T., Deoras, A., Povey, D., Burget, L. & Cernocky, J. Strategies for training \\nlarge scale neural network language models. In Proc. Automatic Speech \\nRecognition and Understanding 196–201 (2011). \\n6. Hinton, G. et al. Deep neural networks for acoustic modeling in speech \\nrecognition. IEEE Signal Processing Magazine 29, 82–97 (2012).\\n This joint paper from the major speech recognition laboratories, summarizing \\nthe breakthrough achieved with deep learning on the task of phonetic \\nclassification for automatic speech recognition, was the first major industrial \\napplication of deep learning.\\n7. Sainath, T., Mohamed, A.-R., Kingsbury, B. & Ramabhadran, B. Deep \\nconvolutional neural networks for LVCSR. In Proc. Acoustics, Speech and Signal \\nProcessing 8614–8618 (2013). \\n8. Ma, J., Sheridan, R. P., Liaw, A., Dahl, G. E. & Svetnik, V. Deep neural nets as a \\nmethod for quantitative structure-activity relationships. J. Chem. Inf. Model. 55, \\n263–274 (2015). \\n9. Ciodaro, T., Deva, D., de Seixas, J. & Damazio, D. Online particle detection with \\nneural networks based on topological calorimetry information. J. Phys. Conf. \\nSeries 368, 012030 (2012). \\n10. Kaggle. Higgs boson machine learning challenge. Kaggle https://www.kaggle.\\ncom/c/higgs-boson (2014). \\n11. Helmstaedter, M. et al. Connectomic reconstruction of the inner plexiform layer \\nin the mouse retina. Nature 500, 168–174 (2013). \\nxtxt−1 xt+1x'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 7}, page_content='263–274 (2015). \\n9. Ciodaro, T., Deva, D., de Seixas, J. & Damazio, D. Online particle detection with \\nneural networks based on topological calorimetry information. J. Phys. Conf. \\nSeries 368, 012030 (2012). \\n10. Kaggle. Higgs boson machine learning challenge. Kaggle https://www.kaggle.\\ncom/c/higgs-boson (2014). \\n11. Helmstaedter, M. et al. Connectomic reconstruction of the inner plexiform layer \\nin the mouse retina. Nature 500, 168–174 (2013). \\nxtxt−1 xt+1x\\nUnfold\\nV W W\\nW W W\\nV V V\\nU U U U\\ns\\no\\nst−1\\not−1 ot\\nst st+1\\not+1\\nFigure 5 | A recurrent neural network and the unfolding in time of the \\ncomputation involved in its forward computation. The artificial neurons \\n(for example, hidden units grouped under node s with values st at time t) get \\ninputs from other neurons at previous time steps (this is represented with the \\nblack square, representing a delay of one time step, on the left). In this way, a \\nrecurrent neural network can map an input sequence with elements xt into an \\noutput sequence with elements ot, with each ot depending on all the previous \\nxtʹ (for tʹ ≤ t). The same parameters (matrices U,V,W ) are used at each time \\nstep. Many other architectures are possible, including a variant in which the \\nnetwork can generate a sequence of outputs (for example, words), each of \\nwhich is used as inputs for the next time step. The backpropagation algorithm \\n(Fig. 1) can be directly applied to the computational graph of the unfolded \\nnetwork on the right, to compute the derivative of a total error (for example, \\nthe log-probability of generating the right sequence of outputs) with respect to \\nall the states st and all the parameters.\\n442 | NATURE | VOL 521 | 28 MAY 2015\\nREVIEWINSIGHT\\n© 2015 Macmillan Publishers Limited. All rights reserved'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 8}, page_content='12. Leung, M. K., Xiong, H. Y., Lee, L. J. & Frey, B. J. Deep learning of the tissue-\\nregulated splicing code. Bioinformatics 30, i121–i129 (2014). \\n13. Xiong, H. Y. et al. The human splicing code reveals new insights into the genetic \\ndeterminants of disease. Science 347, 6218 (2015). \\n14. Collobert, R., et al. Natural language processing (almost) from scratch. J. Mach. \\nLearn. Res. 12, 2493–2537 (2011). \\n15. Bordes, A., Chopra, S. & Weston, J. Question answering with subgraph \\nembeddings. In Proc. Empirical Methods in Natural Language Processing http://\\narxiv.org/abs/1406.3676v3 (2014). \\n16. Jean, S., Cho, K., Memisevic, R. & Bengio, Y. On using very large target \\nvocabulary for neural machine translation. In Proc. ACL-IJCNLP http://arxiv.org/\\nabs/1412.2007 (2015).\\n17. Sutskever, I. Vinyals, O. & Le. Q. V. Sequence to sequence learning with neural \\nnetworks. In Proc. Advances in Neural Information Processing Systems 27 \\n3104–3112 (2014). \\n This paper showed state-of-the-art machine translation results with the \\narchitecture introduced in ref. 72, with a recurrent network trained to read a \\nsentence in one language, produce a semantic representation of its meaning, \\nand generate a translation in another language.\\n18. Bottou, L. & Bousquet, O. The tradeoffs of large scale learning. In Proc. Advances \\nin Neural Information Processing Systems 20 161–168 (2007). \\n19. Duda, R. O. & Hart, P. E. Pattern Classiﬁcation and Scene Analysis (Wiley, 1973). \\n20. Schölkopf, B. & Smola, A. Learning with Kernels (MIT Press, 2002). \\n21. Bengio, Y., Delalleau, O. & Le Roux, N. The curse of highly variable functions \\nfor local kernel machines. In Proc. Advances in Neural Information Processing \\nSystems 18 107–114 (2005). \\n22. Selfridge, O. G. Pandemonium: a paradigm for learning in mechanisation of \\nthought processes. In Proc. Symposium on Mechanisation of Thought Processes \\n513–526 (1958). \\n23. Rosenblatt, F. The Perceptron — A Perceiving and Recognizing Automaton. Tech. \\nRep. 85-460-1 (Cornell Aeronautical Laboratory, 1957). \\n24. Werbos, P. Beyond Regression: New Tools for Prediction and Analysis in the \\nBehavioral Sciences. PhD thesis, Harvard Univ. (1974). \\n25. Parker, D. B. Learning Logic Report TR–47 (MIT Press, 1985). \\n26. LeCun, Y. Une procédure d’apprentissage pour Réseau à seuil assymétrique \\nin Cognitiva 85: a la Frontière de l’Intelligence Artiﬁcielle, des Sciences de la \\nConnaissance et des Neurosciences [in French] 599–604 (1985). \\n27. Rumelhart, D. E., Hinton, G. E. & Williams, R. J. Learning representations by \\nback-propagating errors. Nature 323, 533–536 (1986). \\n28. Glorot, X., Bordes, A. & Bengio. Y. Deep sparse rectiﬁer neural networks. In Proc. \\n14th International Conference on Artificial Intelligence and Statistics 315–323 \\n(2011). \\n This paper showed that supervised training of very deep neural networks is \\nmuch faster if the hidden layers are composed of ReLU.\\n29. Dauphin, Y. et al. Identifying and attacking the saddle point problem in high-\\ndimensional non-convex optimization. In Proc. Advances in Neural Information \\nProcessing Systems 27 2933–2941 (2014). \\n30. Choromanska, A., Henaff, M., Mathieu, M., Arous, G. B. & LeCun, Y. The loss \\nsurface of multilayer networks. In Proc. Conference on AI and Statistics http://\\narxiv.org/abs/1412.0233 (2014). \\n31. Hinton, G. E. What kind of graphical model is the brain? In Proc. 19th \\nInternational Joint Conference on Artificial intelligence 1765–1775 (2005). \\n32. Hinton, G. E., Osindero, S. & Teh, Y.-W. A fast learning algorithm for deep belief \\nnets. Neural Comp. 18, 1527–1554 (2006).\\n This paper introduced a novel and effective way of training very deep neural \\nnetworks by pre-training one hidden layer at a time using the unsupervised \\nlearning procedure for restricted Boltzmann machines. \\n33. Bengio, Y., Lamblin, P., Popovici, D. & Larochelle, H. Greedy layer-wise training \\nof deep networks. In Proc. Advances in Neural Information Processing Systems 19 \\n153–160 (2006).'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 8}, page_content='nets. Neural Comp. 18, 1527–1554 (2006).\\n This paper introduced a novel and effective way of training very deep neural \\nnetworks by pre-training one hidden layer at a time using the unsupervised \\nlearning procedure for restricted Boltzmann machines. \\n33. Bengio, Y., Lamblin, P., Popovici, D. & Larochelle, H. Greedy layer-wise training \\nof deep networks. In Proc. Advances in Neural Information Processing Systems 19 \\n153–160 (2006). \\n This report demonstrated that the unsupervised pre-training method \\nintroduced in ref. 32 significantly improves performance on test data and \\ngeneralizes the method to other unsupervised representation-learning \\ntechniques, such as auto-encoders.\\n34. Ranzato, M., Poultney, C., Chopra, S. & LeCun, Y. Efﬁcient learning of sparse \\nrepresentations with an energy-based model. In Proc. Advances in Neural \\nInformation Processing Systems 19 1137–1144 (2006). \\n35. Hinton, G. E. & Salakhutdinov, R. Reducing the dimensionality of data with \\nneural networks. Science 313, 504–507 (2006). \\n36. Sermanet, P., Kavukcuoglu, K., Chintala, S. & LeCun, Y. Pedestrian detection with \\nunsupervised multi-stage feature learning. In Proc. International Conference \\non Computer Vision and Pattern Recognition http://arxiv.org/abs/1212.0142 \\n(2013). \\n37. Raina, R., Madhavan, A. & Ng, A. Y. Large-scale deep unsupervised learning \\nusing graphics processors. In Proc. 26th Annual International Conference on \\nMachine Learning 873–880 (2009). \\n38. Mohamed, A.-R., Dahl, G. E. & Hinton, G. Acoustic modeling using deep belief \\nnetworks. IEEE Trans. Audio Speech Lang. Process. 20, 14–22 (2012). \\n39. Dahl, G. E., Yu, D., Deng, L. & Acero, A. Context-dependent pre-trained deep \\nneural networks for large vocabulary speech recognition. IEEE Trans. Audio \\nSpeech Lang. Process. 20, 33–42 (2012). \\n40. Bengio, Y., Courville, A. & Vincent, P. Representation learning: a review and new \\nperspectives. IEEE Trans. Pattern Anal. Machine Intell. 35, 1798–1828 (2013). \\n41. LeCun, Y. et al. Handwritten digit recognition with a back-propagation network. \\nIn Proc. Advances in Neural Information Processing Systems 396–404 (1990). \\n This is the first paper on convolutional networks trained by backpropagation \\nfor the task of classifying low-resolution images of handwritten digits.\\n42. LeCun, Y., Bottou, L., Bengio, Y. & Haffner, P. Gradient-based learning applied to \\ndocument recognition. Proc. IEEE 86, 2278–2324 (1998). \\n This overview paper on the principles of end-to-end training of modular \\nsystems such as deep neural networks using gradient-based optimization \\nshowed how neural networks (and in particular convolutional nets) can be \\ncombined with search or inference mechanisms to model complex outputs \\nthat are interdependent, such as sequences of characters associated with the \\ncontent of a document.\\n43. Hubel, D. H. & Wiesel, T. N. Receptive ﬁelds, binocular interaction, and functional \\narchitecture in the cat’s visual cortex. J. Physiol. 160, 106–154 (1962). \\n44. Felleman, D. J. & Essen, D. C. V. Distributed hierarchical processing in the \\nprimate cerebral cortex. Cereb. Cortex 1, 1–47 (1991). \\n45. Cadieu, C. F. et al. Deep neural networks rival the representation of primate \\nit cortex for core visual object recognition. PLoS Comp. Biol. 10, e1003963 \\n(2014). \\n46. Fukushima, K. & Miyake, S. Neocognitron: a new algorithm for pattern \\nrecognition tolerant of deformations and shifts in position. Pattern Recognition \\n15, 455–469 (1982). \\n47. Waibel, A., Hanazawa, T., Hinton, G. E., Shikano, K. & Lang, K. Phoneme \\nrecognition using time-delay neural networks. IEEE Trans. Acoustics Speech \\nSignal Process. 37, 328–339 (1989). \\n48. Bottou, L., Fogelman-Soulié, F., Blanchet, P. & Lienard, J. Experiments with time \\ndelay networks and dynamic time warping for speaker independent isolated \\ndigit recognition. In Proc. EuroSpeech 89 537–540 (1989). \\n49. Simard, D., Steinkraus, P. Y. & Platt, J. C. Best practices for convolutional neural'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 8}, page_content='47. Waibel, A., Hanazawa, T., Hinton, G. E., Shikano, K. & Lang, K. Phoneme \\nrecognition using time-delay neural networks. IEEE Trans. Acoustics Speech \\nSignal Process. 37, 328–339 (1989). \\n48. Bottou, L., Fogelman-Soulié, F., Blanchet, P. & Lienard, J. Experiments with time \\ndelay networks and dynamic time warping for speaker independent isolated \\ndigit recognition. In Proc. EuroSpeech 89 537–540 (1989). \\n49. Simard, D., Steinkraus, P. Y. & Platt, J. C. Best practices for convolutional neural \\nnetworks. In Proc. Document Analysis and Recognition 958–963 (2003). \\n50. Vaillant, R., Monrocq, C. & LeCun, Y. Original approach for the localisation of \\nobjects in images. In Proc. Vision, Image, and Signal Processing 141, 245–250 \\n(1994). \\n51. Nowlan, S. & Platt, J. in Neural Information Processing Systems 901–908 (1995). \\n52. Lawrence, S., Giles, C. L., Tsoi, A. C. & Back, A. D. Face recognition: a \\nconvolutional neural-network approach. IEEE Trans. Neural Networks 8, 98–113 \\n(1997). \\n53. Ciresan, D., Meier, U. Masci, J. & Schmidhuber, J. Multi-column deep neural \\nnetwork for trafﬁc sign classiﬁcation. Neural Networks 32, 333–338 (2012). \\n54. Ning, F. et al. Toward automatic phenotyping of developing embryos from \\nvideos. IEEE Trans. Image Process. 14, 1360–1371 (2005). \\n55. Turaga, S. C. et al. Convolutional networks can learn to generate afﬁnity graphs \\nfor image segmentation. Neural Comput. 22, 511–538 (2010). \\n56. Garcia, C. & Delakis, M. Convolutional face ﬁnder: a neural architecture for \\nfast and robust face detection. IEEE Trans. Pattern Anal. Machine Intell. 26, \\n1408–1423 (2004). \\n57. Osadchy, M., LeCun, Y. & Miller, M. Synergistic face detection and pose \\nestimation with energy-based models. J. Mach. Learn. Res. 8, 1197–1215 \\n(2007). \\n58. Tompson, J., Goroshin, R. R., Jain, A., LeCun, Y. Y. & Bregler, C. C. Efﬁcient object \\nlocalization using convolutional networks. In Proc. Conference on Computer \\nVision and Pattern Recognition http://arxiv.org/abs/1411.4280 (2014). \\n59. Taigman, Y., Yang, M., Ranzato, M. & Wolf, L. Deepface: closing the gap to \\nhuman-level performance in face veriﬁcation. In Proc. Conference on Computer \\nVision and Pattern Recognition 1701–1708 (2014). \\n60. Hadsell, R. et al. Learning long-range vision for autonomous off-road driving. \\nJ. Field Robot. 26, 120–144 (2009). \\n61. Farabet, C., Couprie, C., Najman, L. & LeCun, Y. Scene parsing with multiscale \\nfeature learning, purity trees, and optimal covers. In Proc. International \\nConference on Machine Learning http://arxiv.org/abs/1202.2160 (2012). \\n62. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I. & Salakhutdinov, R. \\nDropout: a simple way to prevent neural networks from overﬁtting. J. Machine \\nLearning Res. 15, 1929–1958 (2014). \\n63. Sermanet, P. et al. Overfeat: integrated recognition, localization and detection \\nusing convolutional networks. In Proc. International Conference on Learning \\nRepresentations http://arxiv.org/abs/1312.6229 (2014). \\n64. Girshick, R., Donahue, J., Darrell, T. & Malik, J. Rich feature hierarchies for \\naccurate object detection and semantic segmentation. In Proc. Conference on \\nComputer Vision and Pattern Recognition 580–587 (2014). \\n65. Simonyan, K. & Zisserman, A. Very deep convolutional networks for large-scale \\nimage recognition. In Proc. International Conference on Learning Representations \\nhttp://arxiv.org/abs/1409.1556 (2014). \\n66. Boser, B., Sackinger, E., Bromley, J., LeCun, Y. & Jackel, L. An analog neural \\nnetwork processor with programmable topology. J. Solid State Circuits 26, \\n2017–2025 (1991). \\n67. Farabet, C. et al. Large-scale FPGA-based convolutional networks. In Scaling \\nup Machine Learning: Parallel and Distributed Approaches (eds Bekkerman, R., \\nBilenko, M. & Langford, J.) 399–419 (Cambridge Univ. Press, 2011). \\n68. Bengio, Y. Learning Deep Architectures for AI (Now, 2009). \\n69. Montufar, G. & Morton, J. When does a mixture of products contain a product of'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 8}, page_content='network processor with programmable topology. J. Solid State Circuits 26, \\n2017–2025 (1991). \\n67. Farabet, C. et al. Large-scale FPGA-based convolutional networks. In Scaling \\nup Machine Learning: Parallel and Distributed Approaches (eds Bekkerman, R., \\nBilenko, M. & Langford, J.) 399–419 (Cambridge Univ. Press, 2011). \\n68. Bengio, Y. Learning Deep Architectures for AI (Now, 2009). \\n69. Montufar, G. & Morton, J. When does a mixture of products contain a product of \\nmixtures? J. Discrete Math. 29, 321–347 (2014). \\n70. Montufar, G. F., Pascanu, R., Cho, K. & Bengio, Y. On the number of linear regions \\nof deep neural networks. In Proc. Advances in Neural Information Processing \\nSystems 27 2924–2932 (2014). \\n71. Bengio, Y., Ducharme, R. & Vincent, P. A neural probabilistic language model. In \\nProc. Advances in Neural Information Processing Systems 13 932–938 (2001). \\n This paper introduced neural language models, which learn to convert a word \\nsymbol into a word vector or word embedding composed of learned semantic \\nfeatures in order to predict the next word in a sequence.\\n72. Cho, K. et al. Learning phrase representations using RNN encoder-decoder \\n28 MAY 2015 | VOL 521 | NATURE | 443\\nREVIEWINSIGHT\\n© 2015 Macmillan Publishers Limited. All rights reserved'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 9}, page_content='for statistical machine translation. In Proc. Conference on Empirical Methods in \\nNatural Language Processing 1724–1734 (2014).  \\n73. Schwenk, H. Continuous space language models. Computer Speech Lang. 21, \\n492–518 (2007). \\n74. Socher, R., Lin, C. C-Y., Manning, C. & Ng, A. Y. Parsing natural scenes and \\nnatural language with recursive neural networks. In Proc. International \\nConference on Machine Learning 129–136 (2011). \\n75. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. & Dean, J. Distributed \\nrepresentations of words and phrases and their compositionality. In Proc. \\nAdvances in Neural Information Processing Systems 26 3111–3119 (2013). \\n76. Bahdanau, D., Cho, K. & Bengio, Y. Neural machine translation by jointly \\nlearning to align and translate. In Proc. International Conference on Learning \\nRepresentations http://arxiv.org/abs/1409.0473 (2015).\\n77. Hochreiter, S. Untersuchungen zu dynamischen neuronalen Netzen [in \\nGerman] Diploma thesis, T.U. Münich (1991). \\n78. Bengio, Y., Simard, P. & Frasconi, P. Learning long-term dependencies with \\ngradient descent is difﬁcult. IEEE Trans. Neural Networks 5, 157–166 (1994). \\n79. Hochreiter, S. & Schmidhuber, J. Long short-term memory. Neural Comput. 9, \\n1735–1780 (1997). \\n This paper introduced LSTM recurrent networks, which have become a crucial \\ningredient in recent advances with recurrent networks because they are good \\nat learning long-range dependencies. \\n80. ElHihi, S. & Bengio, Y. Hierarchical recurrent neural networks for long-term \\ndependencies. In Proc. Advances in Neural Information Processing Systems 8 \\nhttp://papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-\\nlong-term-dependencies (1995). \\n81. Sutskever, I. Training Recurrent Neural Networks. PhD thesis, Univ. Toronto \\n(2012). \\n82. Pascanu, R., Mikolov, T. & Bengio, Y. On the difﬁculty of training recurrent neural \\nnetworks. In Proc. 30th International Conference on Machine Learning 1310–\\n1318 (2013). \\n83. Sutskever, I., Martens, J. & Hinton, G. E. Generating text with recurrent neural \\nnetworks. In Proc. 28th International Conference on Machine Learning 1017–\\n1024 (2011). \\n84. Lakoff, G. & Johnson, M. Metaphors We Live By (Univ. Chicago Press, 2008). \\n85. Rogers, T. T. & McClelland, J. L. Semantic Cognition: A Parallel Distributed \\nProcessing Approach (MIT Press, 2004). \\n86. Xu, K. et al. Show, attend and tell: Neural image caption generation with visual \\nattention. In Proc. International Conference on Learning Representations http://\\narxiv.org/abs/1502.03044 (2015). \\n87. Graves, A., Mohamed, A.-R. & Hinton, G. Speech recognition with deep recurrent \\nneural networks. In Proc. International Conference on Acoustics, Speech and \\nSignal Processing 6645–6649 (2013). \\n88. Graves, A., Wayne, G. & Danihelka, I. Neural Turing machines. http://arxiv.org/\\nabs/1410.5401 (2014). \\n89. Weston, J. Chopra, S. & Bordes, A. Memory networks. http://arxiv.org/\\nabs/1410.3916 (2014). \\n90. Weston, J., Bordes, A., Chopra, S. & Mikolov, T. Towards AI-complete question \\nanswering: a set of prerequisite toy tasks. http://arxiv.org/abs/1502.05698 \\n(2015). \\n91. Hinton, G. E., Dayan, P., Frey, B. J. & Neal, R. M. The wake-sleep algorithm for \\nunsupervised neural networks. Science 268, 1558–1161 (1995). \\n92. Salakhutdinov, R. & Hinton, G. Deep Boltzmann machines. In Proc. International \\nConference on Artificial Intelligence and Statistics 448–455 (2009). \\n93. Vincent, P., Larochelle, H., Bengio, Y. & Manzagol, P.-A. Extracting and composing \\nrobust features with denoising autoencoders. In Proc. 25th International \\nConference on Machine Learning 1096–1103 (2008). \\n94. Kavukcuoglu, K. et al. Learning convolutional feature hierarchies for visual \\nrecognition. In Proc. Advances in Neural Information Processing Systems 23 \\n1090–1098 (2010). \\n95. Gregor, K. & LeCun, Y. Learning fast approximations of sparse coding. In Proc. \\nInternational Conference on Machine Learning 399–406 (2010).'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/DEEPLERNING10.pdf', 'page': 9}, page_content='robust features with denoising autoencoders. In Proc. 25th International \\nConference on Machine Learning 1096–1103 (2008). \\n94. Kavukcuoglu, K. et al. Learning convolutional feature hierarchies for visual \\nrecognition. In Proc. Advances in Neural Information Processing Systems 23 \\n1090–1098 (2010). \\n95. Gregor, K. & LeCun, Y. Learning fast approximations of sparse coding. In Proc. \\nInternational Conference on Machine Learning 399–406 (2010). \\n96. Ranzato, M., Mnih, V., Susskind, J. M. & Hinton, G. E. Modeling natural images \\nusing gated MRFs. IEEE Trans. Pattern Anal. Machine Intell. 35, 2206–2222 \\n(2013). \\n97. Bengio, Y., Thibodeau-Laufer, E., Alain, G. & Yosinski, J. Deep generative \\nstochastic networks trainable by backprop. In Proc. 31st International \\nConference on Machine Learning 226–234 (2014). \\n98. Kingma, D., Rezende, D., Mohamed, S. & Welling, M. Semi-supervised learning \\nwith deep generative models. In Proc. Advances in Neural Information Processing \\nSystems 27 3581–3589 (2014). \\n99. Ba, J., Mnih, V. & Kavukcuoglu, K. Multiple object recognition with visual \\nattention. In Proc. International Conference on Learning Representations http://\\narxiv.org/abs/1412.7755 (2014). \\n100. Mnih, V. et al. Human-level control through deep reinforcement learning. Nature  \\n518, 529–533 (2015).\\n101. Bottou, L. From machine learning to machine reasoning. Mach. Learn. 94, \\n133–149 (2014). \\n102. Vinyals, O., Toshev, A., Bengio, S. & Erhan, D. Show and tell: a neural image \\ncaption generator. In Proc. International Conference on Machine Learning http://\\narxiv.org/abs/1502.03044 (2014).\\n103. van der Maaten, L. & Hinton, G. E. Visualizing data using t-SNE. J. Mach. Learn.\\nResearch 9, 2579–2605 (2008).\\nAcknowledgements The authors would like to thank the Natural Sciences and \\nEngineering Research Council of Canada, the Canadian Institute For Advanced \\nResearch (CIFAR), the National Science Foundation and Office of Naval Research \\nfor support. Y.L. and Y.B. are CIFAR fellows.\\nAuthor Information Reprints and permissions information is available at \\nwww.nature.com/reprints. The authors declare no competing financial \\ninterests. Readers are welcome to comment on the online version of this \\npaper at go.nature.com/7cjbaa. Correspondence should be addressed to Y.L. \\n(yann@cs.nyu.edu).\\n444 | NATURE | VOL 521 | 28 MAY 2015\\nREVIEWINSIGHT\\n© 2015 Macmillan Publishers Limited. All rights reservedView publication stats'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 0}, page_content='Introduction to natural\\nlanguage processing\\nR. Kibble\\nCO3354\\n2013\\nUndergraduate study in \\nComputing and related programmes\\nThis is an extract from a subject guide for an undergraduate course offered as part of the \\nUniversity of London International Programmes in Computing. Materials for these programmes \\nare developed by academics at Goldsmiths.\\nFor more information, see: www.londoninternational.ac.uk'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 1}, page_content='This guide was prepared for the University of London International Programmes by:\\nR. Kibble\\nThis is one of a series of subject guides published by the University. We regret that due to pressure of work the author is \\nunable to enter into any correspondence relating to, or arising from, the guide. If you have any comments on this subject \\nguide, favourable or unfavourable, please use the form at the back of this guide.\\nUniversity of London International Programmes \\nPublications Office \\n32 Russell Square \\nLondon WC1B 5DN \\nUnited Kingdom \\nwww.londoninternational.ac.uk\\nPublished by: University of London \\nCopyright © Department of Computing, Goldsmiths 2013\\nThe University of London and Goldsmiths assert copyright over all material in this subject guide except where otherwise \\nindicated. All rights reserved. No part of this work may be reproduced in any form, or by any means, without permission in \\nwriting from the publisher. We make every effort to respect copyright. If you think we have inadvertently used your copyright \\nmaterial, please let us know.'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 2}, page_content='Contents\\nPreface 1\\nAbout this half unit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\\nAssessment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\\nThe subject guide and other learning resources . . . . . . . . . . . . . . . . 2\\nSuggested study time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\nAcknowledgement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n1 Introduction: how to use this subject guide 5\\n1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.2 Aims of the course . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.3 Learning outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n1.4 Reading list and other learning resources . . . . . . . . . . . . . . . . . 6\\n1.5 Software requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n1.6 How to use the guide/structure of the course . . . . . . . . . . . . . . 8\\n1.6.1 Chapter 2: Introducing NLP: patterns and structures in language 8\\n1.6.2 Chapter 3: Getting to grips with natural language data . . . . . 8\\n1.6.3 Chapter 4: Computational tools for text analysis . . . . . . . . . 9\\n1.6.4 Chapter 5: Statistically-based techniques for text analysis . . . 9\\n1.6.5 Chapter 6: Analysing sentences: syntax and parsing . . . . . . 9\\n1.6.6 Appendices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n1.7 What the course does not cover . . . . . . . . . . . . . . . . . . . . . . 9\\n2 Introducing NLP: patterns and structure in language 11\\nEssential reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\nRecommended reading . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\nAdditional reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n2.1 Learning outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n2.2 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n2.3 Basic concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n2.3.1 Tokenised text and pattern matching . . . . . . . . . . . . . . . 12\\nActivity: Recognising names . . . . . . . . . . . . . . . . . . . . . . . . 13\\n2.3.2 Parts of speech . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nActivity: identify parts of speech . . . . . . . . . . . . . . . . . . . . . 14\\n2.3.3 Constituent structure . . . . . . . . . . . . . . . . . . . . . . . . 14\\nActivity: Writing production rules . . . . . . . . . . . . . . . . . . . . . 15\\n2.4 A closer look at syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n2.4.1 Operation of a ﬁnite-state machine . . . . . . . . . . . . . . . . 16\\nActivity: Finite-state machines . . . . . . . . . . . . . . . . . . . . . . . 17\\n2.4.2 Representing ﬁnite-state machines . . . . . . . . . . . . . . . . 17\\n2.4.3 Declarative alternatives to ﬁnite-state machines . . . . . . . . . 18\\nActivity: Coding regular expressions . . . . . . . . . . . . . . . . . . . 19\\nActivity: tree diagrams for a regular language . . . . . . . . . . . . . . 21\\n2.4.4 Limitations of ﬁnite-state methods – introducing context-free\\ngrammars . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nActivity: Regular grammars . . . . . . . . . . . . . . . . . . . . . . . . 21\\nActivity: Context-free grammar . . . . . . . . . . . . . . . . . . . . . . 23\\n2.4.5 Looking ahead: some further uses of regular expressions . . . . 23\\ni'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 3}, page_content='CO3354 Introduction to natural language processing\\n2.4.6 Looking ahead: grammars and parsing . . . . . . . . . . . . . . 24\\n2.5 Word structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\nActivity: Past tense formation . . . . . . . . . . . . . . . . . . . . . . . 25\\n2.6 A brief history of natural language processing . . . . . . . . . . . . . . 25\\n2.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n2.8 Sample examination questions . . . . . . . . . . . . . . . . . . . . . . 27\\n3 Getting to grips with natural language data 29\\nEssential reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nRecommended reading . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nAdditional reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n3.1 Learning outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n3.2 Using the Natural Language Toolkit . . . . . . . . . . . . . . . . . . . . 29\\n3.3 Corpora and other data resources . . . . . . . . . . . . . . . . . . . . . 30\\n3.4 Some uses of corpora . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\\n3.4.1 Lexicography . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n3.4.2 Grammar and syntax . . . . . . . . . . . . . . . . . . . . . . . . 32\\n3.4.3 Stylistics: variation across authors, periods, genres and chan-\\nnels of communication . . . . . . . . . . . . . . . . . . . . . . . 32\\n3.4.4 Training and evaluation . . . . . . . . . . . . . . . . . . . . . . 33\\n3.5 Corpora . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\\n3.5.1 Brown corpus . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n3.5.2 British National Corpus . . . . . . . . . . . . . . . . . . . . . . 34\\n3.5.3 COBUILD Bank of English . . . . . . . . . . . . . . . . . . . . . 34\\n3.5.4 Penn Treebank . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n3.5.5 Gutenberg archive . . . . . . . . . . . . . . . . . . . . . . . . . 36\\n3.5.6 Other corpora . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\nActivity: Online corpus queries . . . . . . . . . . . . . . . . . . . . . . 37\\n3.5.7 WordNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\\n3.6 Some basic corpus analysis . . . . . . . . . . . . . . . . . . . . . . . . 38\\n3.6.1 Frequency distributions . . . . . . . . . . . . . . . . . . . . . . 38\\nActivity: Using NLTK tools . . . . . . . . . . . . . . . . . . . . . . . . . 39\\n3.6.2 DIY corpus: some worked examples . . . . . . . . . . . . . . . 39\\nActivity: building and analysing a DIY corpus . . . . . . . . . . . . . . 41\\n3.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\\n3.8 Sample examination question . . . . . . . . . . . . . . . . . . . . . . . 42\\n4 Computational tools for text analysis 43\\nEssential reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\nRecommended reading . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\nAdditional reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\n4.1 Introduction and learning outcomes . . . . . . . . . . . . . . . . . . . 43\\n4.1.1 Learning outcomes . . . . . . . . . . . . . . . . . . . . . . . . . 43\\n4.2 Data structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nActivity: strings and sequences . . . . . . . . . . . . . . . . . . . . . . 44\\n4.3 Tokenisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\n4.3.1 Some issues with tokenisation . . . . . . . . . . . . . . . . . . . 45\\n4.3.2 Tokenisation in the NLTK . . . . . . . . . . . . . . . . . . . . . 46\\nActivity: Tokenising text . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\n4.4 Stemming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nActivity: Comparing stemmers . . . . . . . . . . . . . . . . . . . . . . . 48\\n4.5 Tagging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 3}, page_content='4.3.1 Some issues with tokenisation . . . . . . . . . . . . . . . . . . . 45\\n4.3.2 Tokenisation in the NLTK . . . . . . . . . . . . . . . . . . . . . 46\\nActivity: Tokenising text . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\n4.4 Stemming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\nActivity: Comparing stemmers . . . . . . . . . . . . . . . . . . . . . . . 48\\n4.5 Tagging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\n4.5.1 RE tagging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nActivity: Tagging with REs . . . . . . . . . . . . . . . . . . . . . . . . . 51\\n4.5.2 Trained taggers and backoff . . . . . . . . . . . . . . . . . . . . 51\\nii'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 4}, page_content='4.5.3 Transformation-based tagging . . . . . . . . . . . . . . . . . . . 53\\n4.5.4 Evaluation and performance . . . . . . . . . . . . . . . . . . . . 53\\nActivity: Trained taggers . . . . . . . . . . . . . . . . . . . . . . . . . . 53\\n4.6 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\\n4.7 Sample examination question . . . . . . . . . . . . . . . . . . . . . . . 54\\n5 Statistically-based techniques for text analysis 57\\nEssential reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\\nRecommended reading . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\\nAdditional reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\\n5.1 Learning outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\\n5.2 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\n5.3 Some fundamentals of machine learning . . . . . . . . . . . . . . . . . 58\\n5.3.1 Naive Bayes classiﬁers . . . . . . . . . . . . . . . . . . . . . . . 58\\nActivity: Bayes’ rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\n5.3.2 Hidden Markov models . . . . . . . . . . . . . . . . . . . . . . 60\\n5.3.3 Information and entropy . . . . . . . . . . . . . . . . . . . . . . 61\\n5.3.4 Decision trees and maximum entropy classiﬁers . . . . . . . . . 62\\nActivity: further reading . . . . . . . . . . . . . . . . . . . . . . . . . . 63\\n5.3.5 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\\n5.4 Machine learning in action: document classiﬁcation . . . . . . . . . . . 64\\n5.4.1 Summary: document classiﬁcation . . . . . . . . . . . . . . . . 65\\nActivity: document classiﬁcation . . . . . . . . . . . . . . . . . . . . . 66\\n5.5 Machine learning in action: information extraction . . . . . . . . . . . 66\\n5.5.1 Types of information extraction . . . . . . . . . . . . . . . . . . 67\\n5.5.2 Regular expressions for personal names . . . . . . . . . . . . . 67\\nActivity: coding regular expressions for proper names . . . . . . . . . . 69\\n5.5.3 Information extraction as sequential classiﬁcation: chunking\\nand NE recognition . . . . . . . . . . . . . . . . . . . . . . . . . 69\\nActivity: chunking and NE recognition . . . . . . . . . . . . . . . . . . 71\\n5.6 Limitations of statistical methods . . . . . . . . . . . . . . . . . . . . . 71\\n5.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72\\n5.8 Sample examination question . . . . . . . . . . . . . . . . . . . . . . . 72\\n6 Analysing sentences: syntax and parsing 75\\nEssential reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nRecommended reading . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\nAdditional reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\n6.1 Learning outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\n6.2 Grammars and parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\\n6.3 Complicating CFGs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\n6.3.1 Verb categories . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\nActivity: Verb categories . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\n6.3.2 Agreement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\nActivity: feature-based grammar . . . . . . . . . . . . . . . . . . . . . 80\\n6.3.3 Unbounded dependencies . . . . . . . . . . . . . . . . . . . . . 80\\n6.3.4 Ambiguity and probabilistic grammars . . . . . . . . . . . . . . 82\\nActivity: probabilistic grammar . . . . . . . . . . . . . . . . . . . . . . 85\\n6.4 Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\\n6.4.1 Recursive descent parsing . . . . . . . . . . . . . . . . . . . . . 86\\n6.4.2 Shift-reduce parsing . . . . . . . . . . . . . . . . . . . . . . . . 87\\n6.4.3 Parsing with a well-formed substring table . . . . . . . . . . . . 87\\n6.4.4 Finite-state machines and context-free parsing . . . . . . . . . . 89'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 4}, page_content='Activity: probabilistic grammar . . . . . . . . . . . . . . . . . . . . . . 85\\n6.4 Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\\n6.4.1 Recursive descent parsing . . . . . . . . . . . . . . . . . . . . . 86\\n6.4.2 Shift-reduce parsing . . . . . . . . . . . . . . . . . . . . . . . . 87\\n6.4.3 Parsing with a well-formed substring table . . . . . . . . . . . . 87\\n6.4.4 Finite-state machines and context-free parsing . . . . . . . . . . 89\\nActivity: Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\\n6.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\\niii'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 5}, page_content='CO3354 Introduction to natural language processing\\n6.6 Sample examination question . . . . . . . . . . . . . . . . . . . . . . . 91\\nA Bibliography 93\\nB Glossary 95\\nC Answers to selected activities 97\\nChapter 2: Introducing NLP: patterns and structure in natural language . . . 97\\nIdentify parts of speech, page 14 . . . . . . . . . . . . . . . . . . . . . 97\\nOperation of a ﬁnite-state machine, page 17 . . . . . . . . . . . . . . . 97\\nCoding regular expressions, page 19 . . . . . . . . . . . . . . . . . . . 97\\nRegular grammars, page 21 . . . . . . . . . . . . . . . . . . . . . . . . 98\\nPast tense forms, page 25 . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nChapter 3: Getting to grips with natural language data . . . . . . . . . . . . 98\\nOnline corpus queries, page 37 . . . . . . . . . . . . . . . . . . . . . . 98\\nUsing NLTK tools, page 39 . . . . . . . . . . . . . . . . . . . . . . . . . 99\\nChapter 4: Computational tools for text analysis . . . . . . . . . . . . . . . . 100\\nComparing stemmers, page 48 . . . . . . . . . . . . . . . . . . . . . . . 100\\nTagging with REs, page 51 . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nChapter 5: Statistically-based techniques for text analysis . . . . . . . . . . . 101\\nActivity: Bayes’ Rule, page 59 . . . . . . . . . . . . . . . . . . . . . . . 101\\nChapter 6: Analysing sentences: syntax and parsing . . . . . . . . . . . . . . 102\\nActivity: Verb categories, page 78 . . . . . . . . . . . . . . . . . . . . . 102\\nActivity: Feature-based grammar, page 80 . . . . . . . . . . . . . . . . 102\\nD Trace of recursive descent parse 105\\nE Sample examination paper with answering guidelines 107\\nE.1 Sample examination questions . . . . . . . . . . . . . . . . . . . . . . 108\\nE.2 Answering guidelines for sample examination questions . . . . . . . . 113\\niv'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 6}, page_content='Preface\\nAbout this half unit\\nThis half unit course combines a critical introduction to key topics in theoretical and\\ncomputational linguistics with hands-on practical experience of using existing\\nsoftware tools and developing applications to process texts and access linguistic\\nresources. The aims of the course and learning outcomes are listed in Chapter 1.\\nThis course has no speciﬁc prerequisites. There will be some programming involved\\nand you will need to acquire some familiarity with the Python language, but you will\\nnot be expected to develop substantial original code or to encode specialised\\nalgorithms. The course involves some statistical techniques, but the only\\nmathematical knowledge assumed is an understanding of elementary probability\\nand familiarity with the concept of logarithms.\\nBefore the advent of the world wide web, most machine-readable information was\\nstored in structured databases and accessed via specialised query languages such as\\nStructured Query Language (SQL). Nowadays the situation is reversed: most\\ninformation is found in unstructured or semi-structured natural language documents\\nand there is increasing demand for techniques to ‘unlock’ this data. Computing\\ngraduates with knowledge of natural language processing techniques are ﬁnding\\nemployment in areas such as text analytics, sentiment analysis, topic detection and\\ninformation extraction.\\nAssessment\\nThe course is assessed via an unseen written examination. A sample examination\\npaper is provided in the Appendix at the end of this subject guide, with some\\nguidelines on how to answer the questions. You will be required to attempt three\\nquestions out of a choice of ﬁve. The questions will cover ‘book knowledge’, problem\\nsolving and short essays on more theoretical topics. The examination is not a\\nmemory test but will be designed to assess your understanding of the course\\ncontent. There will also be coursework which will include a similar mix of questions,\\nbut with a stronger focus on practical problem-solving.\\nYou will be expected to provide electronic copies of your coursework for plagiarism\\nchecking purposes. It is very important that any material that is not original to you\\nshould be properly attributed and placed in quotation marks, with a full list of\\nreferences at the end of your submission. You should follow the style used in this\\nsubject guide for citing references, for example:\\nSegaran (2007, pp.117–118) discusses some problems with rule-based spam ﬁlters.\\nAnswers which consist entirely or mostly of quoted material are unlikely to get many\\nmarks even if properly attributed, as simply reproducing an answer in someone\\nelse’s words does not demonstrate that you have fully understood the material.\\nIn order to give you some practice in problem-solving and writing short essays, there\\n1'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 7}, page_content='CO3354 Introduction to natural language processing\\nare a number of Activities throughout this subject guide. The Appendix includes a\\nsection ‘Answers to selected activities’, although these will not always provide\\ncomplete answers to the questions but are intended to indicate how particular types\\nof questions should be approached. Sample examination questions are provided at\\nthe end of each chapter. Some, but not all, of these are included in the sample\\nexamination paper with suggested answers at the end of the guide.\\nThe subject guide and other learning resources\\nThis subject guide is not intended as a self-contained textbook but sets out speciﬁc\\ntopics for study in the CO3354 half unit. There is a recommended textbook and a\\nnumber of other readings are listed at appropriate places. There are also links to\\nwebsites providing useful resources such as software tools and access to online\\nlinguistic data. The learning outcomes listed in the next chapter assume that you are\\nworking through the recommended readings, activities and sample examination\\nquestions. It will not be possible to pass this half unit by reading only the subject\\nguide. Please refer to the Computing VLE for other resources, which should be used\\nas an aid to your learning.\\nSuggested study time\\nThe Student Handbook states that ‘To be able to gain the most beneﬁt from the\\nprogramme, it is likely that you will have to spend at least 300 hours studying for\\neach full unit, though you are likely to beneﬁt from spending up to twice this time’.\\nNote that this subject is a half unit.\\nThe course is designed to be delivered over a ten-week term as one of four\\nconcurrent modules, and this guide has six chapters. Chapter 1 goes into more detail\\nabout the structure of the guide and the course, while Chapters 2 to 6 are each\\ndedicated to a particular topic. It is suggested that you spend about two weeks on\\nChapters 1 and 2 together and each of Chapters 3 to 6, including the associated\\nreading and web-based material, and work through the activities and sample\\nexamination questions during this time.\\n2'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 8}, page_content='Contents\\nAcknowledgement\\nThis subject guide draws closely on:\\nBird, S., E. Klein and E. Loper, Natural Language Processing with Python. (O’Reilly\\nMedia 2009) [ISBN 9780596516499; http://nltk.org/book].\\nYou will be expected to draw on it in your studies and to use the accompanying\\nsoftware package, the Natural Language Toolkit, which requires the Python\\nlanguage.Natural language processing with Python has been made available under\\nthe terms of the Creative Commons Attribution Noncommercial No-Derivative-Works\\n3.0 US License:http://creativecommons.org/licenses/by-nc-nd.3.0/us/legalcode (last\\nvisited 13th April 2013).\\n3'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 9}, page_content='CO3354 Introduction to natural language processing\\n4'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 10}, page_content='Chapter 1\\nIntroduction: how to use this subject guide\\n1.1 Introduction\\nThe idea of computers being able to understand ordinary languages and hold\\nconversations with human beings has been a staple of science ﬁction since the ﬁrst\\nhalf of the twentieth century and was envisaged in a classic paper by Alan Turing\\n(1950) as a hallmark of computational intelligence. Since the start of the\\ntwenty-ﬁrst century this vision has been starting to look more plausible: artiﬁcial\\nintelligence techniques allied with the scientiﬁc study of language have emerged\\nfrom universities and research laboratories to inform a variety of industrial and\\ncommercial applications. Many websites now offer automatic translation; mobile\\nphones can appear to understand spoken questions and commands; search engines\\nlike Google use basic linguistic techniques for automatically completing or\\n‘correcting’ your queries and for ﬁnding relevant results that are closely matched to\\nyour search terms. We are still some way from full machine understanding of natural\\nlanguage, however. Automated translations still need to be reviewed and edited by\\nskilled human translators while no computer system has yet come close to passing\\nthe ‘Turing Test’ of convincingly simulating human conversation. Indeed it has been\\nargued that the Turing Test is a blind alley and that research should focus on\\nproducing effective applications for speciﬁc requirements without seeking to\\ngenerate an illusion that users are interacting with a human rather than a machine\\n(Hayes and Ford, 1995). Hopefully , by the time you ﬁnish this course you will have\\ncome to appreciate some of the challenges posed by full understanding of natural\\nlanguage as well as the very real achievements that have resulted from focusing on a\\nrange of speciﬁc, well-deﬁned tasks.\\n1.2 Aims of the course\\nThis course combines a critical introduction to key topics in theoretical linguistics\\nwith hands-on practical experience of developing applications to process texts and\\naccess linguistic resources. The main topics covered are:\\naccessing text corpora and lexical resources\\nprocessing raw text\\ncategorising and tagging\\nextracting information from text\\nanalysing sentence structure.\\n5'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 11}, page_content='CO3354 Introduction to natural language processing\\n1.3 Learning outcomes\\nOn successful completion of this course, including recommended readings, exercises\\nand activities, you should be able to:\\n1. utilise and explain the function of software tools such as corpus readers,\\nstemmers, taggers and parsers\\n2. explain the difference between regular and context-free grammars and deﬁne\\nformal grammars for fragments of a natural language\\n3. critically appraise existing Natural Language Processing (NLP) applications such\\nas chatbots and translation systems\\n4. describe some applications of statistical techniques to natural language analysis,\\nsuch as classiﬁcation and probabilistic parsing.\\nEach main chapter contains a list of learning outcomes speciﬁc to that chapter at the\\nbeginning, as well as a summary at the end of the chapter.\\n1.4 Reading list and other learning resources\\nThis is a list of textbooks and other resources which will be useful for all or most\\nparts of the course. Additional readings will be given at the start of each chapter. See\\nthe bibliography for a full list of books and articles referred to, including all ISBNs.\\nIn some cases several different books will be listed: you are not expected to read all\\nof them, rather the intention is to give you some alternatives in case particular texts\\nare hard to obtain.\\nEssential reading\\nBird, Klein, and Loper (2009): Natural Language Processing with Python. The full\\ntext including diagrams is freely available online at http://nltk.org/book (last\\nvisited 13th April 2013). The main textbook for this course, Natural Language\\nProcessing with Python is the outcome of a project extending over several years\\nto develop the Natural Language Toolkit (NLTK), which is a set of tools and\\nresources for teaching computational linguistics. The NLTK comprises a suite of\\nsoftware modules written in Python and a collection of corpora and other\\nresources. See section 1.5 below for advice on installing the NLTK and other\\nsoftware packages.\\nIn the course of working through this text you will gain some experience and\\nfamiliarity with the Python language, though you will not be expected to\\nproduce substantial original code as part of the learning outcomes of the course.\\nRecommended reading\\nPinker (2007). The Language Instinct. This book is aimed at non-specialists and\\ndeals with many psychological and cultural aspects of language. Chapter 4 is\\nparticularly relevant to this course as it provides a clear and accessible\\npresentation of two standard techniques for modelling linguistic structure:\\nﬁnite-state machines and context-free grammars (though Pinker does not in fact\\nuse these terms, as we will see in Chapter 2 of the subject guide).\\n6'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 12}, page_content='Reading list and other learning resources\\nJurafsky and Martin (2009): Speech and Language Processing, second edition.\\nCurrently the deﬁnitive introductory textbook in this ﬁeld, covering the major\\ntopics in a way which combines theoretical issues with presentations of key\\ntechnologies, formalisms and mathematical techniques. Much of this book goes\\nbeyond what you will need to pass this course, but it is always worth turning to\\nif you’re looking for a more in-depth discussion of any particular topics.\\nPerkins (2010): Python Text Processing with NLTK 2.0 Cookbook. This book will be\\nsuitable for students who want to get more practice in applying Python\\nprogramming to natural language processing. Perkins explains several\\ntechniques and algorithms in more technical detail than Bird et al. (2009) and\\nprovides a variety of worked examples and code snippets.\\nSegaran (2007) Programming Collective Intelligence. This highly readable and\\ninformative text includes tutorial material on machine learning techniques using\\nthe Python language.\\nAdditional reading\\nRussell and Norvig (2010) Artiﬁcial Intelligence: a modern approach, third edition.\\nThis book is currently regarded as the deﬁnitive textbook in Artiﬁcial\\nIntelligence, and includes useful material on natural language processing as well\\nas on machine learning, which has many applications in NLP.\\nMitkov (2003) The Oxford Handbook of Computational Linguistics. Edited by Ruslan\\nMitkov. A collection of short articles on major topics in the ﬁeld, contributed by\\nacknowledged experts in their respective disciplines.\\nPartee et al. (1990) Mathematical Methods in Linguistics. A classic text, whose\\ncontents indicate how much the ﬁeld has changed since its publication. A book\\nwith such a title nowadays would be expected to include substantial coverage of\\nstatistics, probability and information theory , but this text is devoted exclusively\\nto discrete mathematics including set theory , formal logic, algebra and automata.\\nThese topics are particularly applicable to the content of Chapters 2 and 6.\\nWebsites\\nIntroductory/Reference The Internet Grammar of English is a clear and informative\\nintroductory guide to English grammar which also serves as a tutorial in\\ngrammatical terminology and concepts. The site is hosted by the Survey of\\nEnglish Usage at University College London\\n(http://www.ucl.ac.uk/internet-grammar/home.htm, last visited 27th May\\n2013).\\nHands-on corpus analysis\\nBNCWeb is a web-based interface to the British National Corpus hosted at Lancaster\\nUniversity which supports a variety of online queries for corpus analysis\\n(http://bncweb.info/; last visited 27th May 2013).\\nThe Bank of English forms part of the Collins Corpus, developed by Collins\\nDictionaries and the University of Birmingham. Used as a basis for Collins\\nAdvanced Learner’s Dictionary , grammars and various tutorial materials for\\nlearners of English. Limited online access at\\nhttp://www.collinslanguage.com/wordbanks; (last visited 27th May 2013).\\nJournals and conferences\\nComputational Linguistics is the leading journal in this ﬁeld and is freely available at\\nhttp://www.mitpressjournals.org/loi/coli (last visited 27th May 2013).\\nConference Proceedings are often freely downloadable and many of these are\\nhosted by the ACL Anthology at http://aclweb.org/anthology-new/ (last visited\\n27th May 2013).\\n7'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 13}, page_content='CO3354 Introduction to natural language processing\\n1.5 Software requirements\\nThis course assumes you have access to the Natural Language Toolkit (NLTK) either\\non your own computer or at your institution. The NLTK can be freely downloaded\\nand it is strongly recommended that you install it on your own machine: Windows,\\nMac OSX and Linux distributions are available from http://nltk.org (last visited\\nApril 10th 2013) and some distributions of Linux have it in their package/software\\nmanagers. Full instructions are available at the cited website along with details of\\nassociated packages which should also be installed, including Python itself which is\\nalso freely available. Once you have installed the software you should also download\\nthe required datasets as explained in the textbook (Bird et al., 2009, p. 3).\\nYou should check the NLTK website to determine what versions of Python are\\nsupported. Current stable releases of NLTK are compatible with Python 2.6 and 2.7.\\nA version supporting Python 3 is under development and may be available for\\ntesting by the time you read this guide (as of April 2013).\\n1.6 How to use the guide/structure of the course\\nThis section gives a brief summary of each chapter. These learning outcomes are\\nlisted at the beginning of each main chapter and assume that you have worked\\nthrough the recommended readings and activities for that chapter.\\n1.6.1 Chapter 2: Introducing NLP: patterns and structures in language\\nThis chapter looks at different approaches to analysing texts, ranging from ‘shallow’\\ntechniques that focus on individual words and phrases to ‘deeper’ methods that\\nproduce a full representation of the grammatical structure of a sentence as a\\nhierarchical tree diagram. The chapter introduces two important formalisms:\\nregular expressions, which will play an important part throughout the course, and\\ncontext-free grammars which we return to in Chapter 6 of the subject guide.\\n1.6.2 Chapter 3: Getting to grips with natural language data\\nThis chapter looks at the different kinds of data resources that can be used for\\ndeveloping tools to harvest information that has been published as machine-readable\\ndocuments. In particular, we introduce the notion of a ‘corpus’ (pluralcorpora) – for\\nthe purposes of this course, a computer-readable collection of text or speech. The\\nNLTK includes a selection of excerpts from several well-known corpora and we\\nprovide brief descriptions of the most important of these and of the different formats\\nin which corpora are stored.\\n8'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 14}, page_content='What the course does not cover\\n1.6.3 Chapter 4: Computational tools for text analysis\\nThe previous chapter introduced some relatively superﬁcial techniques for language\\nanalysis such as concordancing and collocations. This chapter covers some\\nfundamental operations in text analysis:\\ntokenisation: breaking up a character string into words, punctuation marks and\\nother meaningful expressions;\\nstemming: removing afﬁxes from words, e.g. mean+ing, distribut+ion;\\ntagging: associating each word in a text with a grammatical category or part of\\nspeech.\\n1.6.4 Chapter 5: Statistically-based techniques for text analysis\\nStatistical and probabilistic methods are pervasive in modern computational\\nlinguistics. These methods generally do not aim at complete understanding or\\nanalysis of a text, but at producing reliable answers to well-deﬁned problems such as\\nsentiment analysis, topic detection or recognising named entities and relations\\nbetween them in a text.\\n1.6.5 Chapter 6: Analysing sentences: syntax and parsing\\nThis chapter resumes the discussion of natural language syntax that was introduced\\nin Chapter 2, concentrating on context-free grammar formalisms and various ways\\nthey need to be modiﬁed and extended beyond the model that was presented in that\\nchapter. Formal grammars do not encode any kind of processing strategy but simply\\nprovide a declarative speciﬁcation of the well-formed sentences in a language.\\nParsers are computer programs that use grammar rules to analyse sentences, and\\nthis chapter introduces some fundamental approaches to syntactic parsing.\\n1.6.6 Appendices\\nThe Appendices include:\\nA. A bibliography listing all works referenced in the subject guide, including\\npublication details and ISBNs.\\nB. A glossary of technical terms used in this subject guide.\\nC. Answers to selected activities.\\nD. A trace of a recursive descent parse as described in Chapter 6 of the subject guide.\\nE. A sample examination paper with guidelines on how to answer questions.\\n1.7 What the course does not cover\\nThe ﬁeld of natural language processing or computational linguistics is a large and\\ndiverse one, and includes many topics we will not be able to address in this course.\\nSome of these are listed below:\\n9'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 15}, page_content='CO3354 Introduction to natural language processing\\nspeech recognition and synthesis\\ndialogue and question answering\\nmachine translation\\nsemantic analysis, including word meanings and logical structure\\ngenerating text or speech from non-linguistic inputs.\\nHowever, the course should provide you with a basis for investigating some of these\\nareas for your ﬁnal year project. Some of these topics are dealt with in the later\\nchapters of Bird et al. (2009) and most of them are touched on by Jurafsky and\\nMartin (2009).\\n10'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 16}, page_content='Chapter 2\\nIntroducing NLP: patterns and structure in\\nlanguage\\nEssential reading\\nSteven Pinker (2007), The Language Instinct, Chapter 4.\\nRecommended reading\\nJurafsky and Martin (2009), Speech and Language Processing second edition,\\nChapters/Sections 2 ‘Regular Expressions and Automata’, 5.1 ‘(Mostly) English Word\\nClasses’, 12.1 ‘Constituency’, 12.2 ‘Context-Free Grammars’, 12.3 ‘Some Grammar\\nRules for English’.\\nAdditional reading\\nThe Internet Grammar of English;\\nhttp://www.ucl.ac.uk/internet-grammar/home.htmespecially sections ‘Word\\nClasses’ and ‘Introducing Phrases’.\\nPartee, ter Meulen and Wall, (1990), Mathematical Methods in Linguistics,\\nChapters/Sections 16.1–4, 17.1–3 (omitting 17.1.2–5, 17.2.1), 18.2, 18.6.\\n2.1 Learning outcomes\\nBy the end of this chapter, and having completed the Essential reading and activities,\\nyou should be able to:\\nexplain the concept of ﬁnite state machines (FSMs) and their connections with\\nregular expressions; work through simple FSMs\\nwrite regular expressions for well-deﬁned patterns of symbols\\nanalyse sentences in terms of parts of speech (POS) and constituent structure,\\nincluding the use of tree diagrams\\nwrite regular and context-free grammars for small fragments of natural language\\nexplain the concept of stemming and specify word-formation rules for given\\nexamples.\\n11'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 17}, page_content='CO3354 Introduction to natural language processing\\n2.2 Introduction\\nPeople communicate in many different ways: through speaking and listening,\\nmaking gestures, using specialised hand signals (such as when driving or directing\\ntrafﬁc), using sign languages for the deaf, or through various forms of text.\\nBy text we mean words that are written or printed on a ﬂat surface (paper, card,\\nstreet signs and so on) or displayed on a screen or electronic device in order to be\\nread by their intended recipient (or by whoever happens to be passing by).\\nThis course will focus only on the last of these: we will be concerned with various\\nways in which computer systems can analyse and interpret texts, and we will assume\\nfor convenience that these texts are presented in an electronic format. This is of\\ncourse quite a reasonable assumption, given the huge amount of text we can access\\nvia the World Wide Web and the increasing availability of electronic versions of\\nnewspapers, novels, textbooks and indeed subject guides. This chapter introduces\\nsome essential concepts, techniques and terminology that will be applied in the rest\\nof the course. Some material in this chapter is a little technical but no programming\\nis involved at this stage.\\nWe will begin in section 2.3 by considering texts as strings of characters which can\\nbe broken up into sub-strings, and introduce some techniques for informally\\ndescribing patterns of various kinds that occur in texts. Subsequently in section 2.4\\nwe will begin to motivate the analysis of texts in terms of hierarchical structures in\\nwhich elements of various kinds can be embedded within each other, in a\\ncomparable way to the elements that make up an HTML web document. This section\\nintroduces some technical machinery such as: ﬁnite-state machines (FSMs), regular\\nexpressions, regular grammars and context-free grammars.\\n2.3 Basic concepts\\n2.3.1 Tokenised text and pattern matching\\nOne of the more basic operations that can be applied to a text is tokenising:\\nbreaking up a stream of characters into words, punctuation marks, numbers and\\nother discrete items. So for example the character string\\n“Dr. Watson, Mr. Sherlock Holmes”, said Stamford, introducing us.\\ncan be tokenised as in the following example, where each token is enclosed in single\\nquotation marks:\\n`\"\\' `Dr.\\' `Watson\\' `,\\' `Mr.\\' `Sherlock\\' `Holmes\\' `\"\\' `,\\'\\n`said\\' `Stamford\\' `,\\' `introducing\\' `us\\' `.\\'\\nAt this level, words have not been classiﬁed into grammatical categories and we\\nhave very little indication of syntactic structure. Still, a fair amount of information\\nmay be obtained from relatively shallow analysis of tokenised text. For example,\\nsuppose we want to develop a procedure for ﬁnding all personal names in a given\\ntext. We know that personal names always start with capital letters, but that is not\\nenough to distinguish them from names of countries, cities, companies, racehorses\\n12'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 18}, page_content='Basic concepts\\nand so on, or from capitalisation at the start of a sentence. Some additional ways to\\nidentify personal names include:\\nUse of a title Dr., Mr., Mrs., Miss, Professor and so on.\\nA capitalised word or words followed by a comma and a number, usually below\\n100: this is a common way of referring to people in news reports, where the\\nnumber stands for their age – for example Pierre Vinken, 61, . . .\\nA capitalised word followed by a verb that usually applies to humans: said,\\nreported, claimed, thought, argued . . . This can over-generate in the case of\\ncountry or organisation names as in the Crown argues or Britain claimed.\\nWe can express these more concisely as follows, where jis the disjunction symbol,\\nWord stands for a capitalised word and Int is an integer:\\n(Dr. jProfessor jMr. jMrs. jMiss jMs) Word\\nWord Word, Int\\nWord (said jthought jbelieved jclaimed jargued j...)\\nLearning activity\\n1. Write down your own examples of names that match each of the above patterns.\\n2. Pick a newspaper article or webpage that provides a variety of examples of people’s names. Do they\\nmatch the patterns we have encoded above? If not, see if you can devise additional rules for\\nrecognising names and write them out in a similar format.\\n2.3.2 Parts of speech\\nA further stage in analysing text is to associate every token with a grammatical\\ncategory or part of speech (POS). A number of different POS classiﬁcations have\\nbeen developed within computational linguistics and we will see some examples in\\nsubsequent chapters. The following is a list of categories that are often encountered\\nin general linguistics: you will be familiar with many of them already from learning\\nthe grammar of English or other languages, though some terms such asDeterminer\\nor Conjunction may be new to you.\\nNoun ﬁsh, book, house, pen, procrastination, language\\nProper noun John, France, Barack, Goldsmiths, Python\\nVerb loves, hates, studies, sleeps, thinks, is, has\\nAdjective grumpy , sleepy , happy , bashful\\nAdverb slowly , quickly , now, here, there\\nPronoun I, you, he, she, we, us, it, they\\nPreposition in, on, at, by , around, with, without\\nConjunction and, but, or, unless\\nDeterminer the, a, an, some, many , few, 100\\n13'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 19}, page_content='CO3354 Introduction to natural language processing\\nBird et al. (2009, pp. 184–5) make the standard distinction that nouns ‘generally\\nrefer to people, places, things or concepts’ while verbs ‘describe events or actions’.\\nThis may be helpful when one is starting to learn grammatical terminology but is\\nsomething of an over-simpliﬁcation. One can easily ﬁnd or construct examples\\nwhere the same concept can be expressed by a noun or a verb, or by an adjective or\\nan adverb. And on the other hand, there are many words that can take different\\nparts of speech depending on what they do in a sentence:\\n1. Rome fell swiftly.\\n2. The fall of Rome was swift.\\n3. The enemy completely destroyed the city .\\n4. The enemy’s destruction of the city was complete.\\n5. John likes to ﬁsh on the river bank.\\n6. John caught a ﬁsh.\\nAdditionally , some types of verbs do not correspond to any particular action but\\nserve a purely grammatical function: these include the auxiliary verbs such asdid,\\nshall and so on. So in summary , we can often only assign a part of speech to a word\\ndepending on its function in context rather than how it relates to real things or\\nevents in the world.\\nLearning activity\\nIdentify parts of speech in these examples:\\n1. The cat sat on the mat.\\n2. John sat on the chair.\\n3. The dog saw the rabbit.\\n4. Jack and Jill went up the hill.\\n5. The owl and the pussycat went to sea.\\n6. The train travelled slowly.\\n2.3.3 Constituent structure\\nYou will have noticed several recurring patterns in the above examples: Det Noun,\\nPrep Det Noun and so on. You may also have noticed that some types of phrase can\\noccur in similar contexts: (John jthe cat) sat, a Proper Noun or a sequence Det Noun\\ncan come before a Verb. Some of these possibilities can be captured using the\\npattern-matching notation introduced above, for example:\\n(((the ja)(cat jdog))(John jJack jSusan))(barked jslept)\\nThis will match any sequence which ends in a verb barked or slept preceded by\\neither a Determiner a or the followed by a Noun cat or dog or a proper name John,\\nJack or Susan.\\nPatterns that have similar distributions (meaning that they can occur in similar\\ncontexts) are standardly identiﬁed by phrasal categories such as Noun Phrase or Verb\\n14'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 20}, page_content='A closer look at syntax\\nPhrase. A common way to represent information about constituent structure is by\\nmeans of production rules of the form X !A;B;C::: . Using rules of this form,\\ngrammatical sentences can be broken down into constituent phrases consisting of\\nvarious combinations of POS:\\nSentence !Noun Phrase, Verb Phrase\\nNoun Phrase !Determiner, Noun (Example: the, dog)\\nNoun Phrase !Proper Noun (Example: Jack)\\nNoun Phrase !Noun Phrase, Conj, Noun Phrase (Examples: Jack and Jill, the owl and the pussycat)\\nVerb Phrase !Verb, Noun Phrase (Example: saw the rabbit)\\nVerb Phrase !Verb, Preposition, Noun Phrase (Examples: went up the hill, sat on the mat)\\nLearning activity\\nRead through the recommended sections of the UCL ‘Internet Grammar of English’. Write production rules\\nthat cover some of the examples in these sections.\\n2.4 A closer look at syntax\\nThis section aims to motivate the idea that texts can be analysed as hierarchical\\nstructures rather than ‘ﬂat’ sequences whose elements are organised in various\\npatterns. The Essential reading for this chapter by Steven Pinker gives a concise and\\naccessible introduction to some fundamental distinctions we will make in this\\nsection, from the point of view of Chomskyan linguistics (compare Chomsky,\\n1957/2002). Chomsky and his followers argue that some components of our\\nknowledge of language are innate, and Pinker (2007, chapter 4) sketches some\\narguments in support of this claim. This position is considered to be contentious by\\nmany linguists and we will not address it in this course. However, Pinker’s chapter\\nprovides a useful introduction to syntactic analysis and clearly distinguishes between\\ntwo formal techniques for modelling grammatical knowledge, which underlie\\nregularand context-free grammars respectively (these terms will be explained as\\nwe go along).\\nLearning activity\\nIf you have access to it, read through the recommended chapter by Pinker and make notes, and have it to\\nhand while working through the remainder of this section.\\nPinker notes that language makes ‘inﬁnite use of ﬁnite means’, in Humboldt’s\\nphrase1. That is, there is no principled upper limit to the length of a grammatical\\nsentence: we can always add another phrase, even if it’s a banal one like ‘one could\\nsay that’, ‘and that’s a fact’ or ‘and you can tell that to the Marines’. A large\\n1‘Sie [die Sprache] muss daher von endlichen Mitteln einen unendlichen Gebrauch machen’ (von Hum-\\nboldt, 1836, p. 122).\\n15'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 21}, page_content='CO3354 Introduction to natural language processing\\nproportion, perhaps most of the sentences we read, hear or speak every day may be\\nentirely novel, at least to us. Consequently , knowledge of a language seems to\\nconsist in knowing rules that specify what sentences belong to the language, rather\\nthan memorising long lists of sentences to be produced on appropriate occasions.\\nPinker considers two different formal systems for generating or recognising\\nsentences in English:\\n‘wordchain’ devices, equivalent to ﬁnite state machines. These devices\\nincorporate three distinct operations:sequence, selection and iteration.\\nPhrase structure grammars, which include the additional operation of recursion.\\nNote that Pinker deliberately uses the more descriptive expression ‘wordchain’ as he\\nis concerned to avoid the use of forbidding technical terminology . In what follows\\nwe will stick to the standard term ﬁnite-state machine which you are more likely to\\nﬁnd in textbooks. You may also encounter the terms ﬁnite-state automaton or just\\nﬁnite automaton.\\n2.4.1 Operation of a ﬁnite-state machine\\nA wordchain device or ﬁnite-state machine (FSM) can be seen as a set of lists of\\nsymbols (such as words or ﬁxed phrases) and rules for going from list to list. A\\nsimple example:\\nWord lists\\n1. The, a, one\\n2. Cat, dog, ﬁsh\\n3. Barked, slept, swam\\nRules\\nIt is important to keep in mind that FSMs are neutral between accepting and\\ngenerating strings. That is to say , one way to operate a FSM is to read a string, one\\nsymbol at a time, and determine whether the symbol is found in the list at the\\ncurrent state of the machine. If it is, we advance to the next state and read the next\\nsymbol. Alternatively , this FSM could be used to generate strings by picking one\\nword from each list in sequence. Some possible matching strings are:\\nThe dog swam\\nA cat barked\\nA ﬁsh slept\\n. . .\\nA more complex example:\\n1. John/Mary/Fred OR\\n1a. the/a/one\\n1b. cat/dog/ﬁsh\\n16'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 22}, page_content='A closer look at syntax\\n2. (optional): and/or GO TO 1\\n3. slept/barked/swam OR\\n3a. sat/walked\\n3b. on\\n3c. a/the\\n3d. mat/hill\\n4. (optional) and/or GO TO 3\\n5. (optional) and/or/but GO TO 1.\\nThis formulation involves the basic operations of sequence, selection and iteration as\\nfollows:\\nSEQUENCE\\nMoving from list to list in numerical order: 1, 2, 3 . . .\\nSELECTION\\nChoosing an item from a list, for example cat, dog or ﬁsh; choosing between lists.\\nITERATION\\nRepeating particular sequences, for example:\\nJohn and Mary or a ﬁsh (repeats step 1.)\\nThe cat barked but Fred walked on the hill. (Repeats steps 1–5, omitting step 4.)\\nLearning activity\\n1. Find the shortest sentence generated or accepted by the above FSM.\\n2. Write out four sentences between six and 20 words long which are accepted by the FSM.\\n2.4.2 Representing ﬁnite-state machines\\nThere are various conventional ways of representing a non-deterministic FSM in\\nterms of a number of states and the permissible transitions between states. In our\\ninformal exposition above, the numbered steps represent states and each symbol or\\nword in a list counts as a possible transition to the next state. Pinker adopts a\\ngraphical convention where states are depicted as nodes in a graph and transitions\\nare directed, labelled arcs between the nodes; see also Partee et al. (1990, p. 457\\nand following). Alternatively , the states and transitions can be shown in tabular form\\nas in Table 2.1 whereq1 is the initial state and q4 the ﬁnal state:\\n17'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 23}, page_content='CO3354 Introduction to natural language processing\\nq1 john q2\\nq1 mary q2\\nq1 the q1a\\nq1 a q1a\\nq1a cat q2\\nq1a dog q2\\nq2 slept q3\\nq2 barked q3\\nq2 swam q3\\nq3 and q1\\nq3 or q1\\nq3 . q4\\nTable 2.1: A ﬁnite-state machine represented as a state-transition table.\\n2.4.3 Declarative alternatives to ﬁnite-state machines\\nThe FSMs shown above combine a formal speciﬁcation of a language with a\\nprocessing strategy . It is often convenient to separate the two and deﬁne the\\nlanguage using expressions from a declarative formalism which can be manipulated\\nusing various different algorithms. This section considers two such formalisms:\\nregular expressionsand regular grammars.\\nRegular expressions (REs) provide a simple but powerful means of identifying\\npatterns in text and are widely used in various applications of computer science. REs\\nare based on three fundamental concepts which as we have seen are characteristic of\\nﬁnite-state machines:\\nsequence – to do with the order in which items occur: may include a wildcard\\ncharacter which is written as the period or full stop ‘.’ and may be replaced by\\nany character.\\nselection – specifying a choice between alternative items or sequences, indicated by\\nthe ‘j’ operator\\niteration – repetition of items or sequences, indicated by the ‘*’ operator, meaning\\nzero or more occurrences of whatever precedes the star.\\nSome simple examples:\\na* matches sequences of zero or more a’s:a, aaaa, aaaaaaaaaaa and so on. A\\nsequence of zero elements is known as the ‘empty string’ and conventionally\\ndenoted by the Greek letter epsilon or \\x0f.\\naa* sequences of one or more a’s\\nab* sequences of one a followed by zero or more b’s:a, ab, abbbb, . . .\\n(ab)* sequences of zero or more pairs ab: \\x0f, ab, abab, ababab . . .\\n(ab)j(ba) ab or ba\\n((ab)j(ba))* possibly empty sequences of ab and ba pairs: \\x0f, ab, abab, baab,\\nbababa, abba . . . Note that parentheses operate in the usual manner as in\\nmathematical or logical expressions, to denote the scope of operators.\\nb.*a all strings that start with b and end with a: ba, bbbaaaa, bcccccccca . . .\\n18'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 24}, page_content='A closer look at syntax\\nProgramming languages such as Java, Perl and Python implement extensions of REs\\nwith operators which are mostly redundant in that they can be reduced to\\ncombinations of the above operations, but can make programs much more compact\\nand readable, including:\\n+ – one or more of the previous item\\n? – the previous item is optional\\n[A-Z], [0-9] – this expression matches one of a range of characters\\nˆabc – matches pattern abc at the start of a string\\nabc$ – matches pattern abc at the end of a string.\\nSee also Bird et al. (2009, Table 3.3) and the other recommended readings on this\\ntopic.\\nHere are some examples of our suggested ways of recognising personal names coded\\nas regular expressions. These are intended to be applied to tokenised text and every\\nsequence enclosed by angled brackets<:::> stands for an individual token. In\\nExamples 1, 3 and 4 below, the material within parentheses represents the target\\nstring and sequences outside parentheses provide the context.\\n1. <Mrs?>(<.+>) matches ‘Mr’ or ‘Mrs’ followed by any string. The ﬁrst token\\nconsists of the sequence Mr followed optionally by the character s. The second\\nconsists of a sequence of one or more characters: any character may occur in\\nplace of the wildcard ‘.’.\\n2. <[A-Z][a-z]+>+ matches any sequence of one or more capitalised words.\\n3. ( <[A-Z][a-z]+>+)<,><[0-9]+>matches capitalised word(s) followed by a\\ncomma and a number (age).\\n4. ( <[A-Z][a-z]+>+)<saidjreportedjclaimed>.\\nLearning activity\\n1. Write a regular expression for all strings consisting of an odd number of a’s followed by an even\\nnumber of b’s.\\n2. Write a regular expression for all sequences of a’s andb’s of length 3.\\n3. Write a regular expression for all strings that contain abba somewhere within them.\\nAs you have probably observed, the pattern-matching notation we used in section\\n2.3 employed a subset of the RE syntax, and we could in principle use regular\\nexpressions to encode simple grammars as presented in that section. For example:\\n( (JohnjMaryjFred) j( (theja)(catjdogjﬁsh) )\\n(barked jslept jswam)\\n((and jor) (barked jslept jswam))*\\nmatches sentences like:\\n1. John slept\\n2. The cat barked or swam\\n3. Mary swam and barked or slept\\n19'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 25}, page_content='CO3354 Introduction to natural language processing\\n4. . . .\\nIt can be seen that even conceptually simple REs can rapidly become almost\\nunreadable. A more manageable formalism is a regular grammar, made up of\\nproduction rules or rewrite rules of the kind you have seen in the previous section:\\nS !John jMary jFred VP\\nS !the ja S1\\nS1 !cat jdog jﬁsh VP\\nVP !barked jslept jswam VP1\\nVP1 !and jor VP\\nVP1 !\\x0f\\nA sequence of words forms a grammatical sentence according to a grammar of this\\ntype if one can draw a tree diagram like Figure 2.1 such that:\\n1. The root node is S or Sentence.\\n2. For every node that matches the left hand side (LHS) of a grammar rule, one can\\ndraw a subtree with the items on the right hand side (RHS) as daughter nodes.\\n3. When no more grammar rules can be applied, every leaf node of the tree\\nmatches a word in the language or the empty string \\x0f.\\nS\\nthe\\nS1\\ncat\\nVP\\nbarked\\nVP1\\nor\\nVP\\nswam\\nVP1\\n\\x0f\\nFigure 2.1: A right-branching tree.\\nSymbols which only occur on the right-hand side of rules, and so can only appear as\\nleaf-nodes in a tree, are known as terminal symbols. Regular grammars have the\\nrestriction that when non-terminal symbols appear on the RHS they must either\\nalways be the rightmost symbol, or always the leftmost. These classes of grammars\\nare known as right-linear and left-linear respectively . A right-linear grammar will\\nalways result in a right-branching tree as in the above example.\\n20'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 26}, page_content='A closer look at syntax\\nLearning activity\\nDraw tree diagrams according to the above grammar for the sentences:\\n1. The dog slept.\\n2. Mary swam and barked or slept.\\n2.4.4 Limitations of ﬁnite-state methods – introducing context-free grammars\\nPinker (2007, p.86) gives an example of a ‘wordchain device’ or FSM which is\\nintended to show the limitations of ﬁnite-state methods for handling natural\\nlanguage. The procedure is apparently designed to deal with complex sentences\\nincluding constructions like If. . . then. . .and Either. . . or . . .. If we look at a few\\npossible matching strings, we see clearly that some are grammatical sentences but\\nothers are nonsensical. (Following a standard convention in linguistics, the\\nunacceptable cases are marked with an asterisk ‘*’.)\\nEither a happy girl eats ice cream or the boy eats hot dogs.\\n*Either a happy girl eats ice cream then one dog eats candy .\\nIf a girl eats ice cream then the boy eats candy .\\n*If a girl eats ice cream or the boy eats candy .\\nLearning activity\\n1. Write a regular grammar that is equivalent to the FSM in Pinker (2007, p. 86).\\n2. Convince yourself that it allows you to draw well-formed trees for the ungrammatical examples above.\\n3. What characteristic of the grammar prevents it from ruling out the ill-formed examples?\\nSee ‘Answers to Activities’ in Appendix C (p. 98) for further discussion.\\nIn order to handle these kinds of sentences correctly we need to add new kinds of\\nrewrite rules, going beyond the class of right- or left-linear grammars:\\n1. To match pairs of words like if . . . then, either . . . or, we need rules where a\\nnon-terminal symbol on the RHS can have additional material on both sides as\\nin the ﬁrst two rules below.\\n2. In order to allow for indeﬁnite nesting – if either John will come if Mary does, or\\n. . . we need rules where the same symbol can occur on both sides of the arrow.\\nThis is known as self-embedding or centre-embedding.\\nNote that centre-embedding is an instance of recursion in grammar; right-linear\\ngrammars may also include recursive rules but they can always be processed\\niteratively rather than recursively (Jurafsky and Martin, 2009, p. 447).\\n21'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 27}, page_content='CO3354 Introduction to natural language processing\\nS !Either S or S\\nS !If S then S\\nS !NP VP\\nNP !Det N\\nDet !a jthe j\\x0f\\nN !girl jboy jdog jcat jburgers jcandy jcream jcake\\nVP !V NP\\nVP !V PP\\nPP !P NP\\nV !eats jlikes jsat\\nP !on\\nThe above grammar handles these cases correctly as well as simple sentences like\\nThe cat sat on the mat:\\nS\\nNP\\nDet\\nthe\\nN\\ncat\\nVP\\nV\\nsat\\nPP\\nP\\non\\nNP\\nDet\\nthe\\nN\\nmat\\nFigure 2.2: Tree diagram for The cat sat on the mat.\\nIt is also acceptable to represent trees using labelled bracketed strings as in the\\nexample below:\\n(S\\n(NP (Det the ) (N cat ))\\n(VP (V sat )\\n(PP\\n(P on )\\n(NP\\n(Det the ) (N mat ) )\\n)\\n)\\n)\\n22'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 28}, page_content='A closer look at syntax\\nFigure 2.3 is an example of self-embedding.\\nS\\nIf S\\nNP\\nDet\\nthe\\nN\\ncat\\nVP\\nV\\nlikes\\nNP\\nDet\\n\\x0f\\nN\\ncream\\nthen S\\nNP\\nDet\\nthe\\nN\\nboy\\nVP\\nV\\neats\\nNP\\nDet\\n\\x0f\\nN\\nburgers\\nFigure 2.3: Tree diagram with self-embedding.\\nLearning activity\\n1. Trace through the grammar rules and satisfy yourself that Figure 2.3 represents the structure of the\\nsentence If the cat likes cream then the boy eats burgersaccording to the grammar.\\n2. What is the shortest sentence generated by the above grammar?\\n3. Using the above grammar, draw complete tree diagrams for:\\n(a) If the girl likes cake then either the boy eats burgers or the boy eats candy.\\n(b) If either the boy likes cake or the girl likes burgers then the dog eats candy.\\n4. Think of ways to modify the grammar to generate more natural-sounding sentences.\\n2.4.5 Looking ahead: some further uses of regular expressions\\nIn this chapter we have so far looked at ﬁnite-state formalisms as techniques for\\ngenerating or recognising short phrases as well as whole sentences, and found them\\nto be wanting. Many current applications in language technology do not, in fact,\\nrequire complete analysis of sentences but proceed by looking for patterns of interest\\nwithin a text and discarding what does not match these patterns. Finite-state\\nmethods are often quite adequate for these applications and you will see many uses\\nfor regular expressions in later chapters of this guide. Some examples we will look at\\nin more detail in later chapters are:\\nstemming: extracting the ‘base form’ of a word as informally presented in\\nsection 2.5 of this chapter\\ntagging: automatically assigning POS or other forms of mark-up to elements in a\\ntext\\nchunking: grouping together a sequence of words as a phrase\\ninformation extraction: identifying chunks that denote meaningful entities,\\nevents or other items of interest.\\n23'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 29}, page_content='CO3354 Introduction to natural language processing\\n2.4.6 Looking ahead: grammars and parsing\\nThe pseudocode and graphical representations of wordchains (FSMs) combine a\\nspeciﬁcation of the well-formed sentences in a language fragment with a processing\\nstrategy . It is important to keep in mind that formal grammars made up of a series of\\nproduction rules donot encode a processing strategy . As stated above, a grammar is\\na declarative speciﬁcation of the strings that make up a language while parsers use a\\nvariety of algorithms to apply the grammar rules. We will look at some of these\\nparsing strategies in Chapter 6 of this subject guide.\\n2.5 Word structure\\nWords combine in different orders to form sentences and phrases; they also have\\ninternal structure. Nouns in English may have different endings according to\\nwhether they are singular (a box) or plural (some boxes) while in some languages\\nthis information may be expressed at the start of the word, for example Swahili ziwa\\n(‘lake’) vsmaziwa (‘lakes’). In English, endings of verbs can indicate person, number,\\ntense and mood2, while other languages may make different dictinctions. Nouns and\\nverbs are sometimes classiﬁed as regular or irregular according to whether their\\ninﬂected forms can be derived by following simple rules. Table 2.2 shows examples\\nof some common past tense forms in English.\\nPresent Past\\nbecome became\\ncome came\\nmistake mistook\\nmisunderstand misunderstood\\nring rang\\nsell sold\\nshake shook\\nsing sang\\nsink sank\\nstand stood\\ntake took\\ntell told\\ntravel travelled\\nunderstand understood\\nwithstand withstood\\nTable 2.2: Past tense forms (1).\\nThe subﬁeld of linguistics known as morphology is concerned with the structure of\\nwords and is concerned, among other things, with formulating rules for deriving\\ndifferent forms of a word according to its grammatical role. Here are some rules\\nwhich appear to cover the examples in the table:\\n2See the Internet Grammar of English at http://www.ucl.ac.uk/internet-grammar/verbs/verbs.htm (last\\nvisited 27th May 2013) for explanations of these terms.\\n24'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 30}, page_content='A brief history of natural language processing\\nSome rules for past-tense formation\\n-come !-came\\n-take !-took\\n-ing !-ang\\n-ink !-ank\\n-ell !-old\\n-and !-ood\\n-el !-elled\\nSome of these rules could be made more general: we could combine the -ing and\\n-ink rules to a single rule, -in !-an . On the other hand, some rules which work for\\nthese particular examples would fail if applied to a wider range of data: we have\\ncome !came, become !became but not welcome !*welcame. This is an example of\\nrules overﬁtting the data.\\nLearning activity\\nModify the above rules so that they will account for the past tense forms in Table 2.3 as well as in Table 2.2.\\nPresent Past\\nbake baked\\ncommand commanded\\nbring brought\\nsling slung\\nsmell smelt\\nthink thought\\nwake woke\\nTable 2.3: Past tense forms (2).\\nA natural language application such as a machine translation system will typically\\ninclude a database of words or lexicon along with rules for deriving word endings:\\nfor example, a translation from English into Dutch might handle the word brought as\\nfollows:\\n1. Find the stem of brought and interpret the inﬂection: bring+past\\n2. Find the Dutch equivalent of bring: brengen\\n3. Find the past tense of brengen: bracht\\nThe process of removing afﬁxes from words to derive the basic form is called\\nstemming. We will look at some tools for doing this in Chapter 4, and you will also\\nhave the opportunity to encode your own rules as regular expressions.\\n2.6 A brief history of natural language processing\\nThe ﬁeld of natural language processing or computational linguistics builds on\\ntechniques and insights from a number of different disciplines, principally\\n25'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 31}, page_content='CO3354 Introduction to natural language processing\\ntheoretical linguistics and computer science but with some input from mathematical\\nlogic and psychology .\\nThe notions of a ﬁnite-state machine and context-free grammar (CFG) were ﬁrst\\nintroduced to linguistics by Chomsky (1957; see Pullum (2011) for a somewhat\\ncritical reappraisal). Chomsky argued that both formalisms were inadequate for\\nmodelling natural language and proposed an additional operation of\\ntransformations, which could essentially permute the output string of a CFG in\\nvarious ways. Chomsky’s work introduced a methodology which was to dominate\\ntheoretical linguistics for the next couple of decades: linguists concentrated on\\npostulating formal rules of grammar which were tested against their own intuitions\\nor those of native speakers of other languages, rather than seeking to induce rules\\nfrom large collections of data. Part of the rationale for this was that native speakers\\nof a language are able to recognise whether a sequence of words makes up an\\nacceptable sentence in their language, even if they have never encountered those\\nwords in that particular order before. Prior to what was to become known as the\\nChomskyan revolution, corpus-based approaches had been the norm in general\\nlinguistics. This tradition was overshadowed for a time by so-called ‘generative’\\nlinguistics, but corpus-based research continued in some quarters until its resurgence\\nin the 1980s, including the development of the ﬁrst machine-readable corpus by the\\nJesuit priest Fr Robert Busa. Busa developed a 10 million-word corpus of medieval\\nphilosophy on punch-cards, with the support of Thomas Watson of IBM (McEnery\\nand Wilson, 2001, pp. 20–21).\\nWork in formal grammar tended to assume a ‘backbone’ of context-free rules,\\naugmented with various mechanisms to handle data that appeared to go beyond the\\ncontext-free model; some important developments were Generalised Phrase\\nStructure Grammar (Gazdar et al., 1985) and Head-driven Phrase Structure\\nGrammar (Pollard and Sag, 1994). We will see examples of these extra mechanisms\\nin Chapter 6.\\nEarly work on automated language processing was essentially procedural in its\\nmethodology , working with a type of ﬁnite-state machine calledtransition\\nnetworks which were extended as augmented transition networks to cope with\\nvarious linguistic constructions (Woods, 1970). Later work based on declarative\\ngrammar formalisms employed techniques includingdeductive parsing (Pereira and\\nWarren, 1983) and uniﬁcation (Kay, 1984). The former adopts techniques from the\\nAI ﬁeld of automated reasoning: the core idea is that parsing a sentence can be seen\\nas constructing a logical proof that a particular sequence of words forms a proper\\nsentence according to a given set of grammar rules. Uniﬁcation grammars treat\\nlinguistic objects as sets of attributes or features with a ﬁnite range of values, and\\ngrammar rules specify that particular items in a sentence must have the same or\\ncompatible values for certain features. For example, the subject and main verb of a\\nsentence should have the same value for the number feature. We will consider\\ndetailed examples in Chapter 6.\\nMeanwhile, substantial progress was made in lower-level tasks such as speech\\nrecognition and morphological analysis using probabilistic techniques and\\nﬁnite-state models. During the late 1990s these techniques were extended to cover\\ntasks such as parsing, part-of-speech tagging and reference resolution (recognising\\nwhether or not different expressions in a document referred to the same person or\\nentity). These developments were driven by a number of factors: the continuing\\nincrease in the processing speed and memory capacity of computers; the availability\\nof massive amounts of spoken and written material, both in unstructured form on\\nthe world wide web and with various types of annotation in corpora such as the\\n26'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 32}, page_content='Sample examination questions\\nPenn Treebank3 or the British National Corpus4, and events such as the Message\\nUnderstanding Conferences5 which were initially sponsored by the US Department\\nof Defense to measure and foster progress in extracting information from\\nunstructured text.\\nMuch work since around the year 2000 has involved the use of machine learning\\ntechniques such as Bayesian models and maximum entropy (see Chapter 5). This\\nhas involved using annotated corpora to train systems to segment and annotate texts\\naccording to various morphological, syntactic or semantic criteria. These techniques\\nhave been systematically applied to particular tasks such as parsing, word sense\\ndisambiguation, question answering and summarisation.\\n2.7 Summary\\n1. This chapter has characterised the subject matter of the course as being\\nconcerned with various ways of using computer programs to analyse text, by\\nwhich we mean words, numbers, punctuation and other meaningful symbols\\nthat are printed on paper or some other ﬂat surface, or displayed on a screen.\\n2. Some fundamental operations in text analysis include tokenisation, which\\ninvolves extracting these meaningful elements from a stream of electronic\\ncharacters and discarding white space, line feed characters and other material\\nwhich has no explicit meaning for a human reader, and using regular\\nexpressions to identify patterns in a text.\\n3. Regular expressions are composed of the three basic operations of sequence,\\nselection and iteration, and have many applications in computational linguistics\\nand computer science at large. A ﬁnite-state machine is a process whose\\noperations can be speciﬁed by means of regular expressions. A regular grammar\\nis a set of production rules or rewrite rules that deﬁnes the sentences that make\\nup a language, and any language deﬁned by a regular grammar can be\\nprocessed by a ﬁnite state machine or described using a regular expression.\\n4. A complete syntactic analysis of natural language sentences is generally held to\\nrequire the additional operation of centre-embedded recursion, which is beyond\\nthe power of ﬁnite-state methods. Recursion is formally encoded in context-free\\ngrammars.\\n5. Not only do words combine in various patterns and structures to form sentences;\\nthey also have internal structure which can be described to an extent using rules\\nfor regular and irregular forms.\\n6. The current state of NLP or computational linguistics builds on research results\\nand concepts from many different ﬁelds, and we have sketched some of the\\nhighlights in a very short history of the discipline.\\n2.8 Sample examination questions\\nYou can expect a list of RE operators to be included as an appendix in the\\nexamination paper.\\n3http://www.cis.upenn.edu/\\x18treebank/; last visited 27th May 2013\\n4http://www.natcorp.ox.ac.uk/; last visited 27th May 2013\\n5http://www.itl.nist.gov/iaui/894.02/related projects/muc/; last visited 27th May 2013\\n27'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 33}, page_content='CO3354 Introduction to natural language processing\\n1. S !NP VP\\nNP !Det N\\nNP !PN\\nVP !V\\nVP !V NP\\nVP !V NP PP\\nVP !VP Adv\\nPP !P NP\\nDet !the ja\\nN !waiter jchairs jtables jhotel jmanager\\nPN !Oscar jParis\\nV !died jput jsaw jcalled\\nAdv !suddenly jquickly jslowly\\nP !in jon\\n(a) Using the grammar rules above, draw syntax trees for:\\ni. Oscar died suddenly .\\nii. The waiter put the chairs on the tables.\\niii. Oscar called the waiter.\\n(b) Modify the grammar so that it generates the unstarred sentences below as\\nwell as (i–iii) above but not the starred ones. Explain the reasons for your\\nmodiﬁcations.\\ni. Oscar died in Paris.\\nii. Oscar died in a hotel in Paris.\\niii. The waiter came to the table when Oscar called him.\\niv. When Oscar called him the waiter came to the table.\\nv. * Oscar put\\nvi. * The waiter saw on the tables\\nvii. * The waiter put in the chairs\\nviii. * The waiter put the chairs\\nix. * Oscar died the table\\nx. * When Oscar called him when the waiter came to the table.\\n2. Write a regular expression that will identify male and female names in context,\\nin an English-language text. Discuss ways in which this might over- or\\nunder-generate.\\n3. Explain the difference between regular and context-free grammars and discuss\\nthe claim that natural language grammars need at least context-free power.\\n4. (a) Write a regular grammar which generates the following sentences:\\ni. This is the kid that my father bought.\\nii. This is the cat that killed the kid that my father bought.\\niii. This is the dog that worried the cat that killed the kid that my father\\nbought.\\niv. This is the stick that beat the dog that worried the cat that killed the kid\\nthat my father bought.\\n(Brewer’s Dictionary of Phrase and Fable, 1896)\\n(b) Write out three more sentences generated by your grammar.\\n28'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 34}, page_content='Chapter 3\\nGetting to grips with natural language data\\nEssential reading\\nBird et al. (2009) Natural Language Processing with Python Chapters 1 and 2\\nparticularly: 1.1–1.3, 2.1–2.2, 2.5.\\nRecommended reading\\nMcEnery (2003) ‘Corpus Linguistics’ in Mitkov (2003) is a succinct overview of the\\ntopic from one of the leading scholars in the ﬁeld.\\nAdditional reading\\nMcEnery and Wilson (2001) Corpus Linguistics is an established undergraduate\\ntextbook; Chapters 2 and 3 are especially relevant for this topic.\\nMcEnery and Hardie (2011) Corpus Linguistics: Method, Theory and Practice. Chapter\\n3 addresses the important topic of research ethics for corpus linguistics, which is\\noften neglected in technical or academic presentations of the subject.\\n3.1 Learning outcomes\\nBy the end of this chapter, and having completed the Essential reading and activities,\\nyou should be able to:\\nexplain what is meant by a corpus in the context of natural language processing,\\nand describe some different types, structures and uses of corpora\\ndescribe the characteristics of some well-known corpora and other language\\nresources such as the Brown corpus, Penn treebank, Project Gutenberg and\\nWordNet\\nUse online interfaces and other software tools to do some basic corpus analysis,\\nincluding concordancing and ﬁnding collocations\\nlocate and format raw text documents and analyse them using corpus tools.\\n3.2 Using the Natural Language Toolkit\\nAs stated in Chapter 1, this subject guide is not intended as a stand-alone tutorial in\\nusing the NLTK or the Python language. You are advised to read through the\\nrecommended sections of Bird et al. (2009) and work through the exercises marked\\n29'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 35}, page_content='CO3354 Introduction to natural language processing\\nYour turn. You may also ﬁnd it useful to attempt some of the exercises provided at\\nthe end of each chapter.\\nFrom this chapter onwards you will be running Python sessions and using the NLTK.\\nYou should get into the habit of starting sessions with the following commands:\\n>>> from __future__ import division\\n>>> import nltk, re, pprint\\nOne of the features that makes the Python language suitable for natural language\\napplications is the very ﬂexible treatment of data structures such as lists, strings and\\nsequences. You should be familiar with these structures from previous programming\\ncourses, but should ensure you understand the way they are handled in Python. For\\nthis chapter, only lists are relevant and you should study Bird et al. (2009, section\\n1.2) before trying any of the learning activities in this chapter.\\n3.3 Corpora and other data resources\\nAs explained in the previous chapter, much natural language processing relies on\\nlarge collections of linguistic data known as corpora (plural of corpus). A corpus can\\nbe simply deﬁned as no more than a collection of language data, composed of\\nwritten texts, transcriptions of speech or a combination of recorded speech and\\ntranscriptions.\\nCorpora fall into three broad categories (McEnery, 2003, p.450):\\nMonolingual corpora consist, as the name suggests, of data from a single\\nlanguage.\\nComparable corpora include a range of monolingual corpora in different\\nlanguages, preferably with a similar level of balance and representativeness, and\\ncan be used for contrastive studies of those languages.\\nParallel corpora include original texts in one language with translations of those\\ntexts in one or more different languages. Parallel corpora can be used to train\\nstatistical translation systems.\\nA corpus is generally expected to have additional characteristics: corpora are usually\\nconstructed so as to bebalanced and representative of a particular domain (McEnery\\nand Wilson, 2001, pp. 29–30). (Sometimes the term is used more loosely to cover\\nany large collection of language data which need not have been compiled\\nsystematically , as in the phrase ‘the web as corpus’.)Sampling theory is a branch of\\nstatistics that deals with questions such as: how many respondents are needed in an\\nopinion poll for the results to be considered to represent public opinion at large?\\nSimilar considerations arise in corpus linguistics. This is particularly important if a\\ncorpus is to be used for quantitative analysis of the kind described in Chapter 5: if\\nthe corpus data is skewed or unrepresentative then results of the analysis may not be\\nreliable. These considerations may be less important if the corpus is collected for the\\nliterary or historical interest of the documents that make it up, as is the case with\\nProject Gutenberg for example.\\nFor example, Bird et al. (2009, pp. 407–412) refer to the TIMIT corpus, an annotated\\nspeech corpus developed by Texas Instruments and MIT. To ensure\\nrepresentativeness, it was designed to include a wide coverage of dialect variations.\\nCorpus builders need to exercise expert judgment in deciding on the sampling frame,\\n30'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 36}, page_content='Some uses of corpora\\nor ‘the entire population of texts from which we will take our samples’ (McEnery and\\nWilson, 2001, p. 78) and calculating the size of the corpus that is necessary for it to\\nbe maximally representative. The sampling frame may , for example, bebibliographic,\\nbased on some comprehensive index or the holdings of a particular library , or\\ndemographic, selecting informants on the basis of various social categories as is often\\ndone in public opinion research.\\nCorpora have tended to be of a ﬁnite size and to remain ﬁxed once they have been\\ncompiled. There are also what is known as monitor corpora which are continually\\nupdated with new material. This is particularly useful for compilers of dictionaries\\nwho need to be able to track new words entering the language and the changing or\\ndeclining use of old ones. An example of a monitor corpus is the COBUILD Bank of\\nEnglishTM, which had around 300 million words when it was referred to by McEnery\\n(2003) and has since more than doubled in size to 650 million words.\\nA further distinction is between corpora consisting solely of the original or ‘raw’ text\\nand those that have been marked up with various annotations. One common\\ntechnique isstandoff annotation where the mark-up is stored in a different ﬁle from\\nthe original text (McEnery and Wilson, 2001, p.38); (Bird et al., 2009, p.415).\\nFinally , corpora can be further classifed according to their structure:\\nIsolated – an unorganised collection of individual texts such as the Gutenberg\\nonline collection of literary works.\\nCategorised – texts are organised by categories such as genre; an example is the\\nBrown corpus described below.\\nOverlapping – some categories overlap. A news corpus such as Reuters may contain\\nstories which cover both politics and sport, for example.\\nTemporal – texts indicate language use over time. Examples are the Inaugural\\ncorpus of all inaugural speeches by US Presidents, and the Helsinki Diachronic\\ncorpus of about 1.6 million words of English dating from the early 9th century\\nCE to 1710.\\nSome examples of corpora, which will be described in more detail later in the\\nchapter, are:\\nBrown Developed at Brown University in the early 1960s.\\nBNC British National Corpus, created and managed by BNC consortium which\\nincludes Oxford and Lancaster universities, dictionary publishers OUP,\\nLongmans and Chambers, and the British Library .\\nCOBUILD (Bank of English) The Bank of EnglishTMforms part of the Collins\\nCorpus, developed by Collins Dictionaries and the University of Birmingham,\\nand contains 650 million words.\\nGutenberg An archive of free electronic books in various formats hosted at\\nhttp://www.gutenberg.org/\\nPenn Treebank A corpus of reports from the Wall Street Journal and other sources\\nin various different formats.\\n3.4 Some uses of corpora\\nMcEnery and Wilson (2001, Chapter 4) discuss a variety of uses for corpora, some of\\nwhich are brieﬂy discussed below.\\n31'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 37}, page_content='CO3354 Introduction to natural language processing\\n3.4.1 Lexicography\\nModern dictionaries such as Chambers, Collins and Longmans now rely heavily on\\ncorpus data in order to classify and inventorise the various ways words can be used\\nin contemporary English as well as any ways these uses may have changed. For\\nexample, a lexicographer who wishes to determine whether the wordsscapegoat,\\nthermostat or leverage can be used as verbs can enter the appropriate search string\\nand be presented with examples such as the following (from the BNC):\\nScapegoating an individual prevents the debate and delays community\\nunderstanding.\\nThe measuring cell is immersed in a vat of liquid, usually benzene or xylene which\\ncan bethermostatted at temperatures between 273 and 400 K.\\nThese one-time costs once met could be leveraged over much more business activity\\naround the globe than we then enjoyed.\\nMcEnery and Wilson (2001, p. 107) discuss a case where they claim that two\\nwell-known dictionaries had ‘got it wrong’ by listingquake as a solely intransitive\\nverb, while examples in a transitive construction can in fact be found through a\\ncorpus search:\\nThese sudden movements quake the Earth. (BNC)\\nIt is perhaps debatable whether the dictionaries in question were ‘wrong’ to\\ndisregard examples like this, or the compilers may have judged this to be an\\nidiosyncratic usage which did not merit being included in a work of reference with\\nthe status of standard usage.\\n3.4.2 Grammar and syntax\\nLarge-scale grammars for pedagogic and reference use such as the Comprehensive\\nGrammar of the English Language (Quirk et al., 1985) or the Cambridge Grammar of\\nthe English Language (Huddleston and Pullum, 2002) use corpora among their\\nsources of information along with results of linguistic research and the compilers’\\nown subjective intuitions as competent speakers of the language, although this has\\ntended to involve qualitative rather than quantitative analysis. Recent advances in\\ncomputational power and developments in parsed corpora and tools to analyse them\\nhave made it possible for researchers to carry out quantitative studies of various\\nkinds of grammatical frequency , such as the relative frequency of different clause\\ntypes in English. Other studies use corpora to test predictions made by formal\\ngrammars that have been developed within the generative school of linguistics. The\\nCOBUILD project which provided the resources for Collins English dictionaries has\\nalso resulted in a series of small handbooks covering various kinds of grammatical\\nconstruction, which are useful both for advanced language learners and for linguists\\nin search of examples.\\n3.4.3 Stylistics: variation across authors, periods, genres and channels of\\ncommunication\\nThe notion of style in communication is that people generally have a choice between\\ndifferent ways of expressing themselves and not only do individuals tend to make\\n32'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 38}, page_content='Corpora\\nsimilar choices each time they communicate, but their particular choices may be\\nmore characteristic of particular genres (romantic ﬁction, ﬁnancial news, court\\nreports and so on), time periods and channels of communication. By channels we\\nmean distinctions such as written text compared with spoken discourse, both of\\nwhich can be further subdivided: people will make different choices when\\ncomposing emails, sending text messages or (rarely) writing a letter by hand. We\\nprobably also adopt different styles when talking face-to-face and on the telephone.\\nLiterary scholars as well as law enforcement and intelligence agencies may have an\\ninterest in identifying the author of a document from internal evidence. There have\\nbeen various famous and less well-known instances of controversial attribution of\\nauthorship: for example, various ﬁgures have been put forward as the authors of\\nShakespeare’s plays.\\n3.4.4 Training and evaluation\\nIn addition to the applications listed above, corpora are routinely used in linguistic\\nresearch for training and testing machine-learning systems for speciﬁc tasks in text\\nanalytics such as:\\ndetecting the topic of a document\\nanalysing the sentiments expressed for or against some product or policy\\nidentifying individuals described in a text, relations between them and events\\nthey participate in\\nstatistical parsing\\nstatistical machine translation.\\nFor example, the Brown corpus and the WSJ corpus are typically used for evaluating\\ntext segmentation among other text processing tasks (Mikheev, 2003, p. 203).\\nThese topics will be covered in more detail in Chapter 5 of this subject guide, where\\nyou will be introduced to various machine-learning techniques. These will all be\\ntypes of supervised learning, where a system is trained on ‘corpora containing the\\ncorrect label for each input’ (Bird et al., 2009, p. 222), as opposed tounsupervised\\nlearning where the system is designed to detect patterns in the input without any\\nfeedback. This normally means that the corpus has been marked up by human\\nannotators. Standard practice is to divide a corpus into training and test sets; the\\ntest set is considered agold standard for comparing the accuracy of trained learning\\nsystems with that of the annotators. Of course humans are fallible, and it is good\\npractice to use multiple annotators for at least a sample of the corpus and report the\\nlevel ofinter-annotator agreement that was achieved. This will set an upper bound\\nfor the performance that can be expected from the system, as it seems meaningless\\nto say that a computer program can achieve 100 per cent accuracy on tasks where\\nhuman annotators disagree (see Jurafsky and Martin, 2009, p. 189).\\n3.5 Corpora\\nThis section provides brief descriptions of various corpora, some of which are\\ndistributed in full or in part with the NLTK and others can be accessed online.\\n33'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 39}, page_content='CO3354 Introduction to natural language processing\\n3.5.1 Brown corpus\\nThis was one of the ﬁrst ‘large-scale’ machine readable corpora, though it may seem\\nrather small by today’s standards, consisting of one million words. It was developed\\nat Brown University from the early 1960s and took around two decades to complete.\\nIt was intended as a ‘standard corpus of present-day edited American English’ and is\\ncaterorised by genre under headings such as:\\nNews Chicago Tribune: Society Reportage\\nEditorial Christian Science Monitor: Editorials\\nReviews Time Magazine: Reviews\\nGovernment US Ofﬁce of Civil Defense: The Family Fallout Shelter\\nScience Fiction Heinlein: Stranger in a Strange Land\\nHumour Thurber: The future, if any, of comedy.\\nThe Brown corpus is provided with the NLTK in tagged and untagged versions and\\ncan be accessed using the various methods listed by Bird et al. (2009, Table 2.3,\\np. 50).\\n3.5.2 British National Corpus\\nThe BNC is created and managed by the BNC consortium, which includes Oxford\\nand Lancaster universities, dictionary publishers OUP, Longmans and Chambers, and\\nthe British Library . It was developed between 1991 and 1994 and consists of 100\\nmillion words: 90 per cent written and 10 per cent transcriptions of speech. This\\nwas one of the ﬁrst corpora to include spontaneous spoken English. The corpus was\\nmarked up using an automated part-of-speech tagger which resulted in a signiﬁcant\\nsaving of time and expense compared with manual annotation by competent\\nspeakers of the language, but means that there is inevitably a degree of error – as\\nyou may discover in the course of the exercise given later in this chapter.\\nYou can access this corpus online and perform various kinds of analysis using the\\nSimple Query language. Registration is required via the following link but there is\\ncurrently no charge:\\nhttp://bncweb.lancs.ac.uk/bncwebSignup/user/login.php (last visited 27th\\nMay 2013)\\n3.5.3 COBUILD Bank of English\\nThe COBUILD project involved Collins Dictionaries and the University of\\nBirmingham. The Collins corpus is a 2.5-billion word analytical database of English.\\nIt contains written material from websites, newspapers, magazines and books\\npublished around the world, and spoken material from radio, TV and everyday\\nconversations. The Bank of EnglishTMforms part of the Collins Corpus and contains\\n650 million words. It was used as a basis for the Collins Advanced Learner’s\\nDictionary , grammars and various tutorial materials for learners of English. It is not\\nincluded in the NLTK but there is limited online access via\\nhttp://www.collinslanguage.com/wordbanks.\\n34'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 40}, page_content='Corpora\\n3.5.4 Penn Treebank\\nThe Penn Treebank with its various offshoots is one of the widely used linguistic\\nresources among empirical researchers.\\nIt includes a collection of texts in four different formats:\\nRaw text (original).\\nTagged with POS using a tagset which was developed as part of the project.\\n‘Parsed’; that is, marked up with constituent structure.\\nCombined, including both POS tags and constituent structure.\\nThe Penn Treebank project . . . has produced treebanks from the Brown, Switchboard, ATIS andWall Street\\nJournal corpora of English, as well as treebanks in Arabic and Chinese.\\nJurafsky and Martin (2009, p. 438)\\nThe project began at the University of Pennsylvania in the 1990s and the results\\nhave been used as a basis for further annotation efforts involving semantics and\\nrhetorical structure. The NLTK includes a selection from theWall Street Journal\\n(WSJ) component of the Treebank, which can be accessed in each of the above\\nformats and additionally with a simpliﬁed POS tagset (Bird et al., 2009, Table 5-1,\\np. 183). Here is an excerpt showing the four different formats:\\nRaw text\\nPierre Vinken, 61 years old, will join the board as a\\nnonexecutive director Nov. 29.\\nTagged\\n[ Pierre/NNP Vinken/NNP ]\\n,/,\\n[ 61/CD years/NNS ]\\nold/JJ ,/, will/MD join/VB\\n[ the/DT board/NN ]\\nas/IN\\n[ a/DT nonexecutive/JJ director/NN Nov./NNP 29/CD ]\\n./.\\nParsed\\n( (S (NP-SBJ (NP Pierre Vinken)\\n,\\n(ADJP (NP 61 years) old)\\n35'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 41}, page_content='CO3354 Introduction to natural language processing\\n,)\\n(VP will\\n(VP join\\n(NP the board)\\n(PP-CLR as\\n(NP a nonexecutive director))\\n(NP-TMP Nov. 29)))\\n.))\\nCombined\\n( (S\\n(NP-SBJ\\n(NP (NNP Pierre) (NNP Vinken) )\\n(, ,)\\n(ADJP\\n(NP (CD 61) (NNS years) )\\n(JJ old) )\\n(, ,) )\\n(VP (MD will)\\n(VP (VB join)\\n(NP (DT the) (NN board) )\\n(PP-CLR (IN as)\\n(NP (DT a) (JJ nonexecutive) (NN director) ))\\n(NP-TMP (NNP Nov.) (CD 29) )))\\n(. .) ))\\n3.5.5 Gutenberg archive\\nThe NLTK includes a small selection of out-of-copyright literary texts from Project\\nGutenberg, an archive of free electronic books hosted at http://www.gutenberg.org/\\nSome of the texts included are:\\nJane Austen: Emma, Persuasion\\nGK Chesterton: Father Brown stories, The Man Who Was Thursday\\nWilliam Blake: Poems\\nMilton: Paradise Lost\\nShakespeare: Julius Caesar, Macbeth, Hamlet\\n3.5.6 Other corpora\\nSome further corpora included with the NLTK are:\\nThe Reuters corpus distributed with the NLTK contains 10,788 news documents\\ntotalling 1.3m words, partitioned into ‘training’ and ‘test’ sets. This split is for\\ntraining and testing machine learning algorithms: we return to this topic in\\nChapter 5 of this subject guide.\\n36'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 42}, page_content='Corpora\\nUS Presidents’ inaugural and State of the Union addresses, organised as separate\\nﬁles.\\nUN Declaration of Human Rights in 300+ languages. Here are a few excerpts:\\n\\x0f All human beings are born free and equal in dignity and rights.\\n\\x0f Abantu bonke bazalwa bekhululekile njalo belingana kumalungelo abo.\\n\\x0f Todos os seres humanos nascem livres e iguais em dignidade e em direitos.\\nOther corpora with online query interfaces include:\\n1. The Corpus of Contemporary American English, hosted at Brigham Young\\nUniversity , is claimed to be ‘the only large and balanced corpus of American\\nEnglish’.http://corpus.byu.edu/coca/ (last visited 27th May 2013)\\n2. The Intellitext project at the University of Leeds ‘aims to facilitate corpus use for\\nacademics working in various areas of the humanities’ and currently provides\\naccess to monolingual and parallel corpora in several European and Asian\\nlanguages.http://corpus.leeds.ac.uk/it/ (last visited 27th May 2013)\\nLearning activity\\n1. Pick two or three of the corpora mentioned above and research them online, focusing on questions\\nsuch as:\\nhow large is the corpus?\\nwhat language(s) and genre(s) does it represent?\\nwhen was it constructed and what is its intended use?\\nwhat is the sampling frame?\\nwhat level of interannotator agreement was achieved, if reported?\\n2. Logon to the BNC Web (free registration needed) or another online corpus. Study the documentation\\nprovided and search for data to answer the following questions:\\nWhat syntactic categories can the following words have? total, pancake, requisition, acquisition.\\nThe guide to Simple Query Syntax provided with the BNC warns that ‘part-of-speech tags have\\nbeen assigned by an automatic software tool and are not always correct’. Have your answers to\\nthe previous question shown up any examples of incorrect classiﬁcation, in your view?\\nWhat prepositions can follow the verb talk? Give an example in each case.\\n3.5.7 WordNet\\nThe NLTK also includes English WordNet, with 155,287 words and 117,659\\nsynonym sets or synsets. A synset consists of a set of synonymous words paired with\\na deﬁnition and linked to words with more general or more speciﬁc meanings. For\\nexample,table has various meanings:\\ntable.n.01 [\\'table\\', \\'tabular\\\\_array\\'], \"a set of data arranged in\\nrows and columns\"\\ntable.n.02 [\\'table\\'], \"a piece of furniture having a smooth flat top\\n37'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 43}, page_content='CO3354 Introduction to natural language processing\\nthat is usually supported by one or more vertical legs\"\\ntable.n.02 hyponyms: drop-leaf\\\\_table, coffee\\\\_table, pool\\\\_table, altar,\\ntable.n.02 hypernyms: furniture\\n3.6 Some basic corpus analysis\\nThis chapter describes some relatively simple techniques, extracting various kinds of\\ndata in suitable formats for human interpretation of the results. Chapters 4 and 5 of\\nthe subject guide will look at ways the analysis and interpretation itself can be\\nautomated to varying degrees.\\nConcordancing involves locating every instance of a word or phrase within a text or\\ncorpus and presenting it in context, usually a ﬁxed number of words before and\\nafter each occurrence.\\nCollocations are pairs of sequences of words that occur together in a text more\\nfrequently than would be expected by chance, and so provide a rough indication\\nof the content or style of a document.\\nConditional frequency distributions support an elementary form of statistical\\nanalysis. A frequency distribution counts observable events and a conditional\\nfrequency distribution pairs each event with a condition. Some sample\\napplications are:\\nComparing the use of particular words in different genres.\\nComparing word lengths in different languages.\\n3.6.1 Frequency distributions\\nThe following worked example displays some rudimentary stylistic analysis by\\nranking the POS tags in a corpus according to frequency .\\nCalculating tag frequency\\n1. Import the Brown corpus.\\n2. List the different categories within the corpus.\\n3. Count the number of sentences in the science ﬁction category .\\n4. Extract all the word tokens from the science ﬁction category , paired with their\\ntags, and store them in the variable bsf. Note that the simpliﬁed tagset is\\nselected.\\n5. Calculate a frequency distribution of the tags: this gives an ordered list of the\\ntags paired with their frequency in the variable sf\\ntag fd. (Only the 12 most\\nfrequent are shown.)\\n>>> from nltk.corpus import brown\\n>>> brown.categories()\\n[\\'adventure\\', \\'belles_lettres\\', \\'editorial\\', \\'fiction\\',\\n\\'government\\', \\'hobbies\\', \\'humor\\', \\'learned\\', \\'lore\\',\\n38'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 44}, page_content=\"Some basic corpus analysis\\n'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\\n>>> sf_sents = brown.sents(categories = 'science_fiction')\\n>>> len(sf_sents)\\n948\\n>>> bsf = brown.tagged_words(categories = 'science_fiction',\\nsimplify_tags=True)\\n>>> sf_tag_fd = nltk.FreqDist(tag for (word,tag) in bsf)\\n>>> sf_tag_fd.keys()\\n['N', 'V', 'DET', 'PRO', 'P', '.', 'ADJ', ',', 'CNJ', 'ADV', 'VD', 'NP', ]\\n>>> sf_tag_fd.tabulate()\\nN V DET PRO P . ADJ , CNJ ADV VD NP\\n2232 1473 1345 1268 1182 1078 793 791 685 644 531 467\\nLearning activity\\n1. Repeat the above process for other categories such as romance, news and religion. How do the\\nfrequency distributions and sentence counts enable you to compare the literary styles of these\\ngenres? Explain any assumptions you make.\\n2. Having read through Bird et al. (2009, section 2.1), with particular attention to Table 2-3 on page 50,\\nanswer the following questions:\\n(a) Summarise the README ﬁle from the Reuters corpus.\\n(b) Create a variable soysents containing all sentences from reports concerning soy products.\\n(c) Display the ﬁrst ten sentences in soysents.\\n(d) Create a variable metalwords containing all words from reports concerning metals.\\n(e) What are the most frequently mentioned metals in this collection? Caution: why might this result\\nbe less than 100 per cent reliable?\\n3.6.2 DIY corpus: some worked examples\\nNLTK’s plain text corpus reader can be used to build a ‘corpus’ from a collection of\\ntext ﬁles. The resulting corpus will be formatted for access as raw text, lists of words\\nor lists of sentences and can be re-formatted for other functions such as\\nconcordancing and ﬁnding collocations.\\nThe ﬁrst example involves a one-text ‘corpus’ of the recent report from the UK\\nEquality and Human Rights Commission: How fair is Britain?\\nStep 1 Download the report as a PDF from http://www.equalityhumanrights.com\\nStep 2 Manually extract text using Adobe Acrobat or another PDF reader and save\\nas a .txt ﬁle\\nStep 3 Point the corpus reader to the directory where you have saved the text ﬁle.\\n>>> import nltk\\n>>> from nltk.corpus import PlaintextCorpusReader\\n>>> corpus_root = 'C:\\\\NLP-stuff\\\\Corpora'\\n>>> mycorpus = PlaintextCorpusReader(corpus_root,'.*')\\n39\"),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 45}, page_content=\"CO3354 Introduction to natural language processing\\nWe can now use the raw, words and sents methods to display the content in\\ndifferent formats:\\n>>> mycorpus.fileids()\\n['howfair.txt']\\n>>> mycorpus.words('howfair.txt')\\n['Equality', 'and', 'Human', 'Rights', 'Commission', ]\\n>>> hf_raw = mycorpus.raw('howfair.txt')\\n>>> hf_raw[:100]\\n'Equality and Human Rights Commission\\\\r\\\\nTriennial\\nReview 2010\\\\r\\\\nExecutive Summary\\\\r\\\\nHow fair\\\\r\\\\nis Britain'\\n>>> mycorpus.sents('howfair.txt')\\n[['Equality', 'and', 'Human', 'Rights', 'Commission', 'Triennial',\\n'Review', '2010', 'Executive', 'Summary', 'How', 'fair', 'is',\\n'Britain', '?'], ...\\nConcordancing and collocations\\nThe Text method formats the content in a way which can be accessed by the\\nconcordance and collocation methods. Note that concordancing will always\\nreturn ﬁxed-length strings which include your target text as a substring, and so may\\nbe cut off in the middle of a word.\\n>>> fair=nltk.Text(mycorpus.words('howfair.txt'))\\n>>> fair.concordance('equal')\\nBuilding index...\\nDisplaying 3 of 3 matches:\\nhas narrowed considerably since the equal Pay Act 1970 came into force in 1975\\nsonal circumstances , should have an equal opportunity to have a say in decisio\\nthat every individual should have an equal chance to make the most of their tal\\n>>> fair.collocations()\\nBuilding collocations list\\nHuman Rights; Rights Commission; Significant findings; Headline data;\\nExecutive Summary; less likely; ethnic minority; life expectancy;\\n0845 604; domestic violence; hate crime; labour market; disabled people;\\nmental health; Black Caribbean; different groups; religiously motivated;\\nsexual assault; minority groups; formal childcare\\nConditional frequency distribution\\nRecall that a frequency distribution is a set of ordered pairs <event; count>\\nwhere count is the number of times event occurs. In our context event is a word-type\\nand count is the number of tokens of that type in a text. A conditional frequency\\ndistribution is a collection of frequency distributions, each one for a different\\ncondition.\\nFor this example we add a second document to the corpus, extracted from a PDF\\n‘Guide to data protection’.\\nStep 1 Create a single variable text\\nword consisting of pairs of each word-token\\nwith the ﬁleid of the document it occurs in.\\n40\"),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 46}, page_content=\"Summary\\nStep 2 Create a conditional frequency distribution, which will tell you the frequency\\nof each word in both texts.\\nStep 3 Pick a sample of words which are likely to occur in both documents, and\\ntabulate their comparative frequency .\\n>>> text_word = [(text,word) for text in ['howfair.txt','guide.txt']\\nfor word in mycorpus.words(text)]\\n>>> text_word[:10]\\n[('howfair.txt', 'Equality'), ('howfair.txt', 'and'),\\n('howfair.txt', 'Human'),('howfair.txt', 'Rights'),\\n('howfair.txt', 'Commission'), ('howfair.txt', 'Triennial'),\\n('howfair.txt', 'Review'), ('howfair.txt', '2010'),\\n('howfair.txt', 'Executive'),\\n('howfair.txt', 'Summary')]\\n>>> cfd = nltk.ConditionalFreqDist(text_word)\\n>>> cfd\\n<ConditionalFreqDist with 2 conditions>\\n>>> cfd.conditions()\\n['guide.txt', 'howfair.txt']\\n>>> cfd['howfair.txt']\\n<FreqDist with 16391 outcomes>\\n>>> cfd['guide.txt']\\n<FreqDist with 47064 outcomes>\\nTesting the CFD\\n>>> cfd['guide.txt']['fair']\\n31\\n>>> cfd['howfair.txt']['fair']\\n30\\n>>> keywords = ['fair','police','crime','office','equal','privacy']\\n>>>>cfd.tabulate(conditions=['howfair.txt','guide.txt'],\\nsamples=keywords)\\nfair police crime office equal privacy\\nhowfair.txt 30 15 29 4 2 0\\nguide.txt 31 16 17 2 0 26\\nLearning activity\\nFind some suitable electronic documents and follow the above techniques to construct a ‘mini-corpus’. The\\ndocuments in these examples were sourced from UK government websites: you may ﬁnd similar\\ndocuments on the website of your own country’s government, or of transnational organisations like the\\nEuropean Union or the United Nations. Think of some terms which are likely to occur in several of these\\ndocuments and compare them using a conditional frequency distribution. If you can ﬁnd a lengthy report\\nwhich is issued along with a shorter summary, it is an interesting exercise to pick some key terms and see if\\ntheir comparative frequency is the same or similar in the original document and the summary.\\n3.7 Summary\\n1. A corpus is a collection of linguistic data which was not originally produced for\\nthe purposes of linguistic analysis. Properly speaking it should be constructed so\\nas to be balanced and representative. If a corpus includes any kind of\\n41\"),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 47}, page_content='CO3354 Introduction to natural language processing\\nannotation, it is good practice to use multiple annotators for at least a sample of\\nthe corpus and report the level of inter-annotator agreement that was\\nachieved.\\n2. Some uses of corpora include:\\nLexicography (compiling dictionaries).\\nCompiling grammars for education and reference purposes.\\nStylistics: developing techniques to identify the author or genre of a\\ndocument; investigating the effect on language use of different channels\\nsuch as email, chat, face-to-face conversation, telephone calls and\\nhand-written letters.\\nTraining and evaluation in linguistic research, using machine learning\\ntechniques.\\n3. This chapter includes brief descriptions of several well-known and widely-used\\ncorpora such as the Brown corpus, the BNC and the Penn Treebank.\\n4. Students on this course can access a variety of corpora through online interfaces\\nor by using corpus tools provided with the NLTK.\\n5. Some simple techniques for analysing corpora include concordancing,\\ncollocations and (conditional) frequency distributions. None of these techniques\\ninvolve automated linguistic analysis: the interpretation of the outputs is down\\nto the analyst.\\n3.8 Sample examination question\\na) Explain what is meant by the following types of corpus, and describe an example\\nin each category that you have encountered during this course:\\nisolated\\ncategorised\\noverlapping\\ntemporal.\\nb) What applications would a tagged and parsed corpus be suitable for? What are\\nsome advantages and disadvantages of using an automated tagger to build such a\\ncorpus?\\nc) Suppose the following lists show the number of sentences and the most commonly\\noccurring part-of-speech tags in three different categories of text in a corpus, with\\ntheir frequency of occurrence in brackets. What can you say about the styles of these\\ndocuments from studying these results? Discuss any assumptions you make.\\nCategory A (4623 sentences) N (22236) P (10845) DET (10648) NP (8336) V\\n(7346) ADJ (5435) ‘,’ (5188) ‘.’ (4472) CNJ (4227) PRO (3408) ADV (2770) VD\\n(2531) . . .\\nCategory B (948 sentences) N (2232) V (1473) DET (1345) PRO (1268) P (1182)\\n‘.’ (1078) ADJ (793) ‘,’ (791) CNJ (685) ADV (644) VD (531) NP (467) . . .\\nCategory C (1716 sentences) N (7304) P (4364) DET (4239) V (3863) ADJ (2620)\\nCNJ (2324) PRO (2243) ‘,’ (1913) ‘.’ (1892) ADV (1485) NP (1224) VN (952)\\n. . .\\n42'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 48}, page_content='Appendix C\\nAnswers to selected activities\\nThis section includes model solutions to some of the exercises and activities where\\nappropriate. In other cases there is no ‘correct’ answer and the point of the activity is\\nto stimulate you to engage in independent self-directed learning.\\nChapter 2: Introducing NLP: patterns and structure in natural\\nlanguage\\nIdentify parts of speech, page 14\\nJack (Proper Noun) and (conjunction) Jill (Proper Noun) went (verb) up\\n(preposition) the (determiner) hill (noun).\\nThe (determiner) owl (noun) and (conjunction) the (determiner) pussycat (noun)\\nwent (verb) to (preposition) sea (noun).\\nOperation of a ﬁnite-state machine, page 17\\n1. John swam.\\n2. (a) John and Mary walked on the hill.\\n(b) The cat sat on the mat and slept.\\n(c) John or a ﬁsh walked on a hill and barked.\\n(d) . . .\\nCoding regular expressions, page 19\\n1. a(aa)*(bb)*\\n2. (aaa)j(aab)j(abb)j(bbb)j(bba)j(baa)j(aba)j(bab)\\n97'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 49}, page_content='CO3354 Introduction to natural language processing\\nRegular grammars, page 21\\nS !either jif S1\\nS !the ja jone S2\\nS2 !happy S2\\nS2 !(boy jgirl jdog) eats (‘ice cream’j‘hot dogs’jcandy) S3\\nS3 !or jthen S2\\nS3 !\\x0f\\nThis is a slightly idealised rendering of Pinker’s state diagram which appears to have\\nno halting state.\\nThe problem with this grammar can be clearly seen: the rule S3 !or jthen S2 has\\nno connection with the rule that introduces either or if and so there is no way to\\nensure that the appropriate conjunction is used.\\nPast tense forms, page 25\\nThe general idea is that rules need to be conditional in order to handle\\nnon-standard cases before applying general regularities: so a reasonable rule based\\non this data set might be:\\nwelcome !welcomed else\\n-come !-came\\nChapter 3: Getting to grips with natural language data\\nOnline corpus queries, page 37\\nExamples of incorrect tagging: search on to total/V gives examples like:\\n. . . a ticketto total oblivion.\\n. . . to describe itto total strangers.\\nas well as ‘correct’ examples like\\n. . . thoughtto total about 1,500 families . . .\\n. . . a great opportunityto total and celebrate all the small wins made over the\\nyear\\n98'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 50}, page_content='APPENDIX C. ANSWERS TO SELECTED ACTIVITIES\\nUsing NLTK tools, page 39\\n1. ‘Stylistic’ analysis\\nScience Fiction (948 sentences) N (2232) V (1473) DET (1345) PRO (1268) P\\n(1182) ‘.’ (1078) ADJ (793) ‘,’ (791) CNJ (685) ADV (644) VD (531) NP (467)\\n. . .\\nNews (4623 sentences) N (22236) P (10845) DET (10648) NP (8336) V (7346)\\nADJ (5435) ‘,’ (5188) ‘.’ (4472) CNJ (4227) PRO (3408) ADV (2770) VD (2531)\\n. . .\\nReligion (1716 sentences) N (7304) P (4364) DET (4239) V (3863) ADJ (2620)\\nCNJ (2324) PRO (2243) ‘,’ (1913) ‘.’ (1892) ADV (1485) NP (1224) VN (952)\\n. . .\\nSome counts:\\nSF: N 2232, PRO 1268, NP 467 ADJ 793\\nNE: N 22236, NP 8336, PRO 3408 ADJ 5435\\nRE: N 7304, PRO 2243 NP 1224 ADJ 2620\\nSF: S 948, COMMA 791, CNJ 685\\nNE: COM 5188 S 4623 CNJ 4227\\nRE: CNJ 2324 COM 1913 S 1716\\nSome tentative conclusions:\\n1. Reference and description: both SF and RE use pronouns more than proper\\nnames; News has more proper names. Hard to interpret without further\\nanalysis: if an SF work includes a lot of dialogue for example, it might be more\\nnatural for characters to refer to each other as I, we, you and so on rather than\\nby name. And news stories tend to be about named individuals.\\n2. Syntactic complexity: we cannot be very precise with this data but it looks as if\\nthe SF genre has the least syntactic complexity and the RE genre the highest,\\njudging from the numbers of commas and conjunctions per sentence. Of course\\nwe cannot tell whether these tokens are connecting clauses or other types of\\nphrases.\\nIn an examination or coursework question, you would get credit for discussing these\\nand other characteristics in the light of your impressionistic understanding of the\\ntypical styles for these genres.\\n2. Reuters\\nDisplay the README ﬁle from the Reuters corpus.\\nfrom nltk.corpus import reuters\\ndesc = reuters.readme()\\nprint desc\\n99'),\n",
              " Document(metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 51}, page_content=\"CO3354 Introduction to natural language processing\\nCreate a variable soysents containing all sentences from reports concerning soy\\nproducts.\\nreuters.categories()\\nPick out categories relating to soy:\\nsoysents = reuters.sents(categories=['soy-meal', ...])\\nDisplay the ﬁrst ten sentences in soysents.\\nprint soysents[:10]\\nCreate a variable metalwords containing all words from reports concerning\\nmetals.\\nmetalwords = reuters.words(categories = ['alum','copper','gold', ...])\\n(Note that inspection of texts in thealum category conﬁrms that they are about\\naluminium.)\\nWhat are the most frequently mentioned metals in this collection? Caution: why\\nmight this result be less than 100 per cent reliable?\\nfrom nltk.book import *\\nfreqmetal = FreqDist(metalwords)\\nfreqmetalkeys = freqmetal.keys()\\nfreqmetal[:100]\\nRemember that the contents of a frequency distribution are listed in the order of\\ntheir frequency of occurrence. By scanning the output you should see that the\\nﬁrst three metals listed are gold, copper and steel. However caution is in order\\nas Reuters is an overlapping corpus, so we may be double-counting some\\noccurrences. These metals may also be mentioned under the category\\nstrategic-metal, or some reports may mention more than one kind of metal\\nand so come under multiple categories.\\nChapter 4: Computational tools for text analysis\\nComparing stemmers, page 48\\nLancaster rules Remove ist/s/e/ing/en/th/ity/ate/al/a/ed/ment/ation.\\nReplace -ies with -y.\\nSome motivations: reduce verbs to stem form, remove plural afﬁx and\\nreturn stem in irregular cases (study), remove ordinal afﬁx -th, remove\\nafﬁxes that form nominalisations or adjectives: -ment, -al.\\nPorter rules Remove s/ing/ity/e/ate/ed/ment/ational.\\nReplace -y with -i.\\nMotivations: similar to Lancaster rules but applied more sparingly .\\nErrors Lancaster removes -th from south as if it were an ordinal and -e from are\\nthough ar is not a stem here; not clear why -a removed from area. Lancaster and\\nPorter both treat some proper names as common nouns; for example, by\\nremoving the last letter fromLyons and Stanhope (both) or by postulating an -i\\nstem for names ending in -y (Porter).\\n100\")]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MPvG9_YkBI26",
        "outputId": "496b4eb2-c863-4a57-9b2b-36d950689f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastembed in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in /usr/local/lib/python3.10/dist-packages (from fastembed) (0.27.0)\n",
            "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from fastembed) (0.7.3)\n",
            "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from fastembed) (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from fastembed) (1.26.4)\n",
            "Requirement already satisfied: onnx>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from fastembed) (1.17.0)\n",
            "Requirement already satisfied: onnxruntime!=1.20.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from fastembed) (1.20.1)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from fastembed) (10.4.0)\n",
            "Requirement already satisfied: py-rust-stemmers<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from fastembed) (0.1.3)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in /usr/local/lib/python3.10/dist-packages (from fastembed) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from fastembed) (0.21.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.10/dist-packages (from fastembed) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.20->fastembed) (4.12.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.15.0->fastembed) (4.25.5)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.31->fastembed) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.31->fastembed) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.31->fastembed) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.31->fastembed) (2024.12.14)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install fastembed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import FastEmbedEmbeddings"
      ],
      "metadata": {
        "id": "ksw2kWfCrVpw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "b488044648e94bee81836d91854e3b67",
            "ab84d33893c746bf920b0cfa4d0fdabe",
            "a64b574b93b744ba865b91e9cb760008",
            "3709d15c9201489db7791fc70e219f40",
            "daba22c335c740e398c1867dc54b9a13",
            "0faba8118a5f43f4980815729c087e60",
            "9b37a6129d0b4a6c821b7199ee9182ab",
            "5bc353e833ae40a78a431c68a6a2ae8c",
            "af66c1190e2b425d913243f90a4aa420",
            "45d438c736e34c67aab3b09b34ce61a8",
            "dbbcd61b9b4843c594831f26aeeb967f",
            "86057ee7a14c42fb809a00c67b84576e",
            "ecae364179d54499acced04d08876e98",
            "92543d4e7ad147b3b40853eeabaad2b5",
            "31e96b6dc6764a6bbd12c96143f49d8a",
            "04a7654659dd49ca845791118b160ddb",
            "4d8011cc9f734d6ea24f518642eddda2",
            "e3a8668fe80546b7871b75e0acab71be",
            "d8ea8c4359eb4a898e91dd67a354c52f",
            "f941b4e111c240a6afe47575ca3e8a54",
            "201ec69d3c9b4ff1a3e85a8689b63ce9",
            "75715aad8f3e4fe7a6841b32069b1df4",
            "c1679bedcb0947c0a1c5c3f33469f152",
            "a69276f3e9fc484ebef956e5cb6744bf",
            "16fdb64785094e07b7f6fb88f521d966",
            "1735cbd629694b6291bc01fa47aac7e8",
            "ad47cd2f53be412bb8d26bce15a5c9ab",
            "05a04d78ef354d68ba4c7fd5c1b9262c",
            "50ee82c3a28548f39eecc2eb01594d67",
            "c7b17a90189f4ffa95c2f6ffb545b095",
            "848e45da8949483fa67934889316b3fb",
            "709ef1a2ad3f45f5a5e87a3073368d4f",
            "16a8801400b74da9b84acf6085331f5c",
            "bb1de2bad3714f218f4159196f2de298",
            "0ee25276dfd04b8d9ae3b27932fb144b",
            "aa53a60d6dbe4c4b89ccc1be6b71b279",
            "71907eb4654b4eeca53008b4338b9b91",
            "4599678f724844eda25af210debaad94",
            "0c053fc9091d4caf8ff1f233f9fa6bb7",
            "f6aa661d9e4f407799fb9dc860e9ae8a",
            "46a276267e1e49b1a30453e7d6731d88",
            "44115cb79ce74db3b4c034eb9c3611e9",
            "52af36c4358f433390fa269614025001",
            "8d96d5ac977b4fdc9696a2d0989e3bf6",
            "451c4a807b5b4d0eb2c97137da8c78a4",
            "e7c60e29e43249a89b204658a49a479f",
            "0a825504c36e494cbd5cf1b925567acc",
            "158ca19c0db0476dbc1fce7a550d01ef",
            "ae818d4807574ed4844a3d1961f7e36d",
            "d0ac3fc489674822a30327438b199f58",
            "759c0e6dc29d4861a5b36aa32879d2aa",
            "a6f94851b55e4211a201c8f54eeb77b5",
            "4c9b108147ab4a58813c10a90ad88598",
            "18372524d32d4158a2ef584b24e80eaf",
            "c95bbc5c63f24a7eb7f499976fa4f4a9",
            "c13ff7d7533440558e02e434af1685ff",
            "1d2e0865feea4b39be9beb36b2bd2c95",
            "29ac2f20d5874883a43059a2c5cf5ba5",
            "d611d3d2dfdb401784b415a0309dc335",
            "7233d43ae19e439db6386da49a3cb7c2",
            "5632cc18690a4117ba7315db2410e978",
            "3feda0417f4c407d94d15b3cbfb13322",
            "9a48254a2e414def9bab87673024498b",
            "e7d64ed4c34645ae8587d46cbddbf4ed",
            "082ac6d23cc44a8ebea4e19a99786d69",
            "d783e44fa9624297b02b6faf05581f6a"
          ]
        },
        "collapsed": true,
        "id": "WOfiFD7LGzwE",
        "outputId": "9d40b29d-f15c-4e20-e96d-f990cf3e3f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b488044648e94bee81836d91854e3b67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86057ee7a14c42fb809a00c67b84576e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/740 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1679bedcb0947c0a1c5c3f33469f152"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb1de2bad3714f218f4159196f2de298"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "451c4a807b5b4d0eb2c97137da8c78a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_optimized.onnx:   0%|          | 0.00/218M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c13ff7d7533440558e02e434af1685ff"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "embeddings = FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_HpNGjQ3H9i7",
        "outputId": "c26c5e0f-167c-4a1d-b76b-023de92bb539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n"
          ]
        }
      ],
      "source": [
        "pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9nAWaSqLIw2H"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = FAISS.from_documents(text,embeddings)"
      ],
      "metadata": {
        "id": "-jwdedwpw2-K"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(db))"
      ],
      "metadata": {
        "id": "9a_o8VHkw-qK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6b841544-2bec-4bc9-b70d-668f7bad37e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_community.vectorstores.faiss.FAISS'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "83u2h-6DRQ-0"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dBhR7KBnRYiY"
      },
      "outputs": [],
      "source": [
        "query = \"what is nlp\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yeHcHuMDRfJz"
      },
      "outputs": [],
      "source": [
        "retrieved_docs = retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YafMVTegR61k",
        "outputId": "8fa088a7-747d-4c50-84f8-7043d99c12df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='aa4af27b-05a0-4e77-8427-5445e45c3f7d', metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 13}, page_content='CO3354 Introduction to natural language processing\\n1.5 Software requirements\\nThis course assumes you have access to the Natural Language Toolkit (NLTK) either\\non your own computer or at your institution. The NLTK can be freely downloaded\\nand it is strongly recommended that you install it on your own machine: Windows,\\nMac OSX and Linux distributions are available from http://nltk.org (last visited\\nApril 10th 2013) and some distributions of Linux have it in their package/software\\nmanagers. Full instructions are available at the cited website along with details of\\nassociated packages which should also be installed, including Python itself which is\\nalso freely available. Once you have installed the software you should also download\\nthe required datasets as explained in the textbook (Bird et al., 2009, p. 3).\\nYou should check the NLTK website to determine what versions of Python are\\nsupported. Current stable releases of NLTK are compatible with Python 2.6 and 2.7.\\nA version supporting Python 3 is under development and may be available for\\ntesting by the time you read this guide (as of April 2013).\\n1.6 How to use the guide/structure of the course\\nThis section gives a brief summary of each chapter. These learning outcomes are\\nlisted at the beginning of each main chapter and assume that you have worked\\nthrough the recommended readings and activities for that chapter.\\n1.6.1 Chapter 2: Introducing NLP: patterns and structures in language\\nThis chapter looks at different approaches to analysing texts, ranging from ‘shallow’\\ntechniques that focus on individual words and phrases to ‘deeper’ methods that\\nproduce a full representation of the grammatical structure of a sentence as a\\nhierarchical tree diagram. The chapter introduces two important formalisms:\\nregular expressions, which will play an important part throughout the course, and\\ncontext-free grammars which we return to in Chapter 6 of the subject guide.\\n1.6.2 Chapter 3: Getting to grips with natural language data\\nThis chapter looks at the different kinds of data resources that can be used for\\ndeveloping tools to harvest information that has been published as machine-readable\\ndocuments. In particular, we introduce the notion of a ‘corpus’ (pluralcorpora) – for\\nthe purposes of this course, a computer-readable collection of text or speech. The\\nNLTK includes a selection of excerpts from several well-known corpora and we\\nprovide brief descriptions of the most important of these and of the different formats\\nin which corpora are stored.\\n8'),\n",
              " Document(id='b62a250e-9221-4752-93cc-d0ee809a7c88', metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 11}, page_content='CO3354 Introduction to natural language processing\\n1.3 Learning outcomes\\nOn successful completion of this course, including recommended readings, exercises\\nand activities, you should be able to:\\n1. utilise and explain the function of software tools such as corpus readers,\\nstemmers, taggers and parsers\\n2. explain the difference between regular and context-free grammars and deﬁne\\nformal grammars for fragments of a natural language\\n3. critically appraise existing Natural Language Processing (NLP) applications such\\nas chatbots and translation systems\\n4. describe some applications of statistical techniques to natural language analysis,\\nsuch as classiﬁcation and probabilistic parsing.\\nEach main chapter contains a list of learning outcomes speciﬁc to that chapter at the\\nbeginning, as well as a summary at the end of the chapter.\\n1.4 Reading list and other learning resources\\nThis is a list of textbooks and other resources which will be useful for all or most\\nparts of the course. Additional readings will be given at the start of each chapter. See\\nthe bibliography for a full list of books and articles referred to, including all ISBNs.\\nIn some cases several different books will be listed: you are not expected to read all\\nof them, rather the intention is to give you some alternatives in case particular texts\\nare hard to obtain.\\nEssential reading\\nBird, Klein, and Loper (2009): Natural Language Processing with Python. The full\\ntext including diagrams is freely available online at http://nltk.org/book (last\\nvisited 13th April 2013). The main textbook for this course, Natural Language\\nProcessing with Python is the outcome of a project extending over several years\\nto develop the Natural Language Toolkit (NLTK), which is a set of tools and\\nresources for teaching computational linguistics. The NLTK comprises a suite of\\nsoftware modules written in Python and a collection of corpora and other\\nresources. See section 1.5 below for advice on installing the NLTK and other\\nsoftware packages.\\nIn the course of working through this text you will gain some experience and\\nfamiliarity with the Python language, though you will not be expected to\\nproduce substantial original code as part of the learning outcomes of the course.\\nRecommended reading\\nPinker (2007). The Language Instinct. This book is aimed at non-specialists and\\ndeals with many psychological and cultural aspects of language. Chapter 4 is\\nparticularly relevant to this course as it provides a clear and accessible\\npresentation of two standard techniques for modelling linguistic structure:\\nﬁnite-state machines and context-free grammars (though Pinker does not in fact\\nuse these terms, as we will see in Chapter 2 of the subject guide).\\n6'),\n",
              " Document(id='b04706e2-18ef-44ea-a57e-cb657eb2bcaa', metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 8}, page_content='Contents\\nAcknowledgement\\nThis subject guide draws closely on:\\nBird, S., E. Klein and E. Loper, Natural Language Processing with Python. (O’Reilly\\nMedia 2009) [ISBN 9780596516499; http://nltk.org/book].\\nYou will be expected to draw on it in your studies and to use the accompanying\\nsoftware package, the Natural Language Toolkit, which requires the Python\\nlanguage.Natural language processing with Python has been made available under\\nthe terms of the Creative Commons Attribution Noncommercial No-Derivative-Works\\n3.0 US License:http://creativecommons.org/licenses/by-nc-nd.3.0/us/legalcode (last\\nvisited 13th April 2013).\\n3'),\n",
              " Document(id='137a4864-47ec-4cb6-b215-2c3bebbc2586', metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 41}, page_content='CO3354 Introduction to natural language processing\\n,)\\n(VP will\\n(VP join\\n(NP the board)\\n(PP-CLR as\\n(NP a nonexecutive director))\\n(NP-TMP Nov. 29)))\\n.))\\nCombined\\n( (S\\n(NP-SBJ\\n(NP (NNP Pierre) (NNP Vinken) )\\n(, ,)\\n(ADJP\\n(NP (CD 61) (NNS years) )\\n(JJ old) )\\n(, ,) )\\n(VP (MD will)\\n(VP (VB join)\\n(NP (DT the) (NN board) )\\n(PP-CLR (IN as)\\n(NP (DT a) (JJ nonexecutive) (NN director) ))\\n(NP-TMP (NNP Nov.) (CD 29) )))\\n(. .) ))\\n3.5.5 Gutenberg archive\\nThe NLTK includes a small selection of out-of-copyright literary texts from Project\\nGutenberg, an archive of free electronic books hosted at http://www.gutenberg.org/\\nSome of the texts included are:\\nJane Austen: Emma, Persuasion\\nGK Chesterton: Father Brown stories, The Man Who Was Thursday\\nWilliam Blake: Poems\\nMilton: Paradise Lost\\nShakespeare: Julius Caesar, Macbeth, Hamlet\\n3.5.6 Other corpora\\nSome further corpora included with the NLTK are:\\nThe Reuters corpus distributed with the NLTK contains 10,788 news documents\\ntotalling 1.3m words, partitioned into ‘training’ and ‘test’ sets. This split is for\\ntraining and testing machine learning algorithms: we return to this topic in\\nChapter 5 of this subject guide.\\n36'),\n",
              " Document(id='30491109-0b7a-4fde-8b33-34ed7c115a21', metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 35}, page_content='CO3354 Introduction to natural language processing\\nYour turn. You may also ﬁnd it useful to attempt some of the exercises provided at\\nthe end of each chapter.\\nFrom this chapter onwards you will be running Python sessions and using the NLTK.\\nYou should get into the habit of starting sessions with the following commands:\\n>>> from __future__ import division\\n>>> import nltk, re, pprint\\nOne of the features that makes the Python language suitable for natural language\\napplications is the very ﬂexible treatment of data structures such as lists, strings and\\nsequences. You should be familiar with these structures from previous programming\\ncourses, but should ensure you understand the way they are handled in Python. For\\nthis chapter, only lists are relevant and you should study Bird et al. (2009, section\\n1.2) before trying any of the learning activities in this chapter.\\n3.3 Corpora and other data resources\\nAs explained in the previous chapter, much natural language processing relies on\\nlarge collections of linguistic data known as corpora (plural of corpus). A corpus can\\nbe simply deﬁned as no more than a collection of language data, composed of\\nwritten texts, transcriptions of speech or a combination of recorded speech and\\ntranscriptions.\\nCorpora fall into three broad categories (McEnery, 2003, p.450):\\nMonolingual corpora consist, as the name suggests, of data from a single\\nlanguage.\\nComparable corpora include a range of monolingual corpora in different\\nlanguages, preferably with a similar level of balance and representativeness, and\\ncan be used for contrastive studies of those languages.\\nParallel corpora include original texts in one language with translations of those\\ntexts in one or more different languages. Parallel corpora can be used to train\\nstatistical translation systems.\\nA corpus is generally expected to have additional characteristics: corpora are usually\\nconstructed so as to bebalanced and representative of a particular domain (McEnery\\nand Wilson, 2001, pp. 29–30). (Sometimes the term is used more loosely to cover\\nany large collection of language data which need not have been compiled\\nsystematically , as in the phrase ‘the web as corpus’.)Sampling theory is a branch of\\nstatistics that deals with questions such as: how many respondents are needed in an\\nopinion poll for the results to be considered to represent public opinion at large?\\nSimilar considerations arise in corpus linguistics. This is particularly important if a\\ncorpus is to be used for quantitative analysis of the kind described in Chapter 5: if\\nthe corpus data is skewed or unrepresentative then results of the analysis may not be\\nreliable. These considerations may be less important if the corpus is collected for the\\nliterary or historical interest of the documents that make it up, as is the case with\\nProject Gutenberg for example.\\nFor example, Bird et al. (2009, pp. 407–412) refer to the TIMIT corpus, an annotated\\nspeech corpus developed by Texas Instruments and MIT. To ensure\\nrepresentativeness, it was designed to include a wide coverage of dialect variations.\\nCorpus builders need to exercise expert judgment in deciding on the sampling frame,\\n30')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tEXZCqL8gqyj",
        "outputId": "cbffb24f-ae73-4bee-a89b-9e86c1080a0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.13.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\n",
            "Downloading groq-0.13.1-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.13.1\n"
          ]
        }
      ],
      "source": [
        "pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "id": "EF26ePwUmvxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33646ba3-987a-4634-a5c8-5d8b50ce8a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.13.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain-groq) (0.3.28)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-groq) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-groq) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain-groq) (9.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-groq) (3.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-groq) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-groq) (2.2.3)\n",
            "Downloading langchain_groq-0.2.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: langchain-groq\n",
            "Successfully installed langchain-groq-0.2.2\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GVydccOhm5TN",
        "outputId": "56272b4f-512f-446c-c5ab-02334e2bfb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pythonenv\n",
            "  Downloading pythonenv-0.0.34.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pythonenv\n",
            "  Building wheel for pythonenv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pythonenv: filename=pythonenv-0.0.34-py3-none-any.whl size=5886 sha256=4a935ae545c2fe22710a84a86e103dfa5f60076479260acdea2613086022a582\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/3c/c2/5c66ef219cdaf8d8dc05fd724a13a4a65c2c33357ada89ad6a\n",
            "Successfully built pythonenv\n",
            "Installing collected packages: pythonenv\n",
            "Successfully installed pythonenv-0.0.34\n"
          ]
        }
      ],
      "source": [
        "!pip install pythonenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xrAxFZ33_xLY"
      },
      "outputs": [],
      "source": [
        "with open('.env','w') as f:\n",
        "  f.write('GROQ_API_KEY=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')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9m885y-OWMs",
        "outputId": "4c41fc80-3c7a-4a49-c624-1343e197d2a0",
        "collapsed": true
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "FfV78vfMCCBh"
      },
      "outputs": [],
      "source": [
        "from groq import Groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NdODB0XJLETX"
      },
      "outputs": [],
      "source": [
        "client = Groq(api_key=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Bq6nxIWZDgoM"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "client = Groq(api_key=os.getenv('GROQ_API_KEY'))"
      ],
      "metadata": {
        "id": "NlkmmS4kQ1-S"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "nwDJl2zbMFAS"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "client = Groq(api_key=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQNqo2LBQcAK"
      },
      "outputs": [],
      "source": [
        "llm = ChatGroq(api_key=\"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\", model_name=\"llama3-70b-8192\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "S3b2lul8Qk-t",
        "outputId": "bf279d02-af10-4f02-db4e-a754bd889f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "print(os.getenv(\"GROQ_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mAGNP4ojQvPu",
        "outputId": "18d94d77-bfc9-4669-eab2-2fab19471c2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getenv(\"GROQ_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-UIQ_A17Q5y2",
        "outputId": "88269bce-b3a2-4461-80a9-d3d328fbece5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getenv(\"GROQ_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "J_SDLrAeeo4m"
      },
      "outputs": [],
      "source": [
        "llm = ChatGroq(model_name=\"llama3-70b-8192\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fDNN7pEhSP-p",
        "outputId": "c00da501-c6d8-46f5-e4b8-7befb5250955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='A network is a collection of interconnected devices, such as computers, servers, printers, routers, switches, and other hardware and software components, that communicate with each other to share resources, exchange data, and provide services. Networks allow devices to communicate with each other, share information, and provide access to shared resources such as files, printers, and internet connections.\\n\\nNetworks can be categorized based on their geographical scope, size, and topology:\\n\\n1. **Local Area Network (LAN)**: A LAN is a network that connects devices in a limited geographical area, such as a home, office building, or campus.\\n2. **Wide Area Network (WAN)**: A WAN is a network that connects devices over a larger geographical area, such as a city or country.\\n3. ** Metropolitan Area Network (MAN)**: A MAN is a network that connects devices in a metropolitan area, such as a city or town.\\n4. **Wireless Network (WLAN)**: A WLAN is a network that connects devices wirelessly, using radio waves or infrared signals.\\n5. **Virtual Private Network (VPN)**: A VPN is a network that uses encryption and other security measures to create a secure and private connection between devices over the internet.\\n\\nNetworks can also be classified based on their topology, which refers to the physical or logical arrangement of devices and connections:\\n\\n1. **Bus Topology**: A bus topology is a network in which all devices are connected to a single cable or backbone.\\n2. **Star Topology**: A star topology is a network in which all devices are connected to a central device, such as a hub or switch.\\n3. **Ring Topology**: A ring topology is a network in which devices are connected in a circular configuration, and data travels in one direction around the ring.\\n4. **Mesh Topology**: A mesh topology is a network in which each device is connected to every other device, providing multiple paths for data to travel.\\n\\nNetworks use standard protocols and technologies to enable communication between devices, including:\\n\\n1. **TCP/IP (Transmission Control Protocol/Internet Protocol)**: A suite of protocols that provides the foundation for the internet and most modern networks.\\n2. **Ethernet**: A protocol that defines the rules for data transmission over LANs.\\n3. **Wi-Fi**: A technology that enables wireless communication between devices.\\n4. **Router**: A device that connects multiple networks and routes traffic between them.\\n5. **Switch**: A device that connects multiple devices within a network and forwards data packets between them.\\n\\nNetworks have many applications in various fields, including:\\n\\n1. **Communication**: Networks enable communication between people, devices, and systems.\\n2. **Data Sharing**: Networks allow devices to share files, printers, and other resources.\\n3. **Internet Access**: Networks provide access to the internet, enabling online activities such as browsing, emailing, and streaming.\\n4. **Business Operations**: Networks are essential for many business operations, such as inventory management, customer relationship management, and supply chain management.\\n5. **Education**: Networks are used in educational institutions to provide access to online resources, facilitate collaboration, and support online learning.\\n\\nIn summary, a network is a collection of interconnected devices that communicate with each other to share resources, exchange data, and provide services. Networks can be categorized based on their geographical scope, size, and topology, and they use standard protocols and technologies to enable communication between devices.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 692, 'prompt_tokens': 13, 'total_tokens': 705, 'completion_time': 2.026556315, 'prompt_time': 0.003691274, 'queue_time': 0.005341304, 'total_time': 2.030247589}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None} id='run-75b14ca4-f860-44d2-938a-ed0425146947-0' usage_metadata={'input_tokens': 13, 'output_tokens': 692, 'total_tokens': 705}\n"
          ]
        }
      ],
      "source": [
        "OUTPT = \"What is Network\"\n",
        "print(llm.invoke(OUTPT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "gMZwWBxBe8VQ"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "8X3Q4FATLe05"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt_template = \"\"\"\n",
        "greet the user\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(template=prompt_template, input_variables=['context', 'question'])\n"
      ],
      "metadata": {
        "id": "QXhycFmDLmJm"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yTawzjlAxmFW"
      },
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 retriever=retriever,\n",
        "                                 chain_type_kwargs={'prompt': prompt},\n",
        "                                 return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ],
      "metadata": {
        "id": "5zXZULslD8Id"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory_1 = ConversationBufferMemory(memory_key= \"chat_history\", return_messages = True,output_key=\"answer\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OzHOitI_EHIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8057f091-4bc1-483f-9cb4-7673cda3afa9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-387f7232abd8>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory_1 = ConversationBufferMemory(memory_key= \"chat_history\", return_messages = True,output_key=\"answer\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_1 = ConversationalRetrievalChain.from_llm(llm = llm,\n",
        "                                             retriever = retriever,\n",
        "                                             return_source_documents = True,\n",
        "                                             memory = memory_1)"
      ],
      "metadata": {
        "id": "rfEQqO-UJh76"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Q0WSu_yhxwhg"
      },
      "outputs": [],
      "source": [
        "query = \"what is nlp\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "pq_8IhlJybVW"
      },
      "outputs": [],
      "source": [
        "result = qa_1.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lVZlMqfFQ6cm",
        "outputId": "00c25c61-160c-4e3a-933c-48d6c675a485"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'what is nlp',\n",
              " 'chat_history': [HumanMessage(content='what is nlp', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='NLP stands for Natural Language Processing. It is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It involves the development of algorithms and statistical models that enable computers to process, understand, and generate natural language data, such as text or speech.\\n\\nThe goal of NLP is to enable computers to perform tasks that would normally require human-level understanding of language, such as:\\n\\n* Text classification and sentiment analysis\\n* Language translation and machine translation\\n* Speech recognition and speech synthesis\\n* Information extraction and Named Entity Recognition (NER)\\n* Question answering and dialogue systems\\n\\nNLP has numerous applications in areas such as:\\n\\n* Chatbots and virtual assistants\\n* Sentiment analysis and opinion mining\\n* Language translation and localization\\n* Text summarization and information retrieval\\n* Speech recognition and voice assistants\\n\\nIn the context of the course guide provided, NLP is introduced as a field that deals with the analysis and processing of natural language data, with a focus on computational approaches to understanding language. The course covers topics such as regular expressions, context-free grammars, corpora, and statistical techniques for natural language analysis.', additional_kwargs={}, response_metadata={})],\n",
              " 'answer': 'NLP stands for Natural Language Processing. It is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It involves the development of algorithms and statistical models that enable computers to process, understand, and generate natural language data, such as text or speech.\\n\\nThe goal of NLP is to enable computers to perform tasks that would normally require human-level understanding of language, such as:\\n\\n* Text classification and sentiment analysis\\n* Language translation and machine translation\\n* Speech recognition and speech synthesis\\n* Information extraction and Named Entity Recognition (NER)\\n* Question answering and dialogue systems\\n\\nNLP has numerous applications in areas such as:\\n\\n* Chatbots and virtual assistants\\n* Sentiment analysis and opinion mining\\n* Language translation and localization\\n* Text summarization and information retrieval\\n* Speech recognition and voice assistants\\n\\nIn the context of the course guide provided, NLP is introduced as a field that deals with the analysis and processing of natural language data, with a focus on computational approaches to understanding language. The course covers topics such as regular expressions, context-free grammars, corpora, and statistical techniques for natural language analysis.',\n",
              " 'source_documents': [Document(id='aa4af27b-05a0-4e77-8427-5445e45c3f7d', metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 13}, page_content='CO3354 Introduction to natural language processing\\n1.5 Software requirements\\nThis course assumes you have access to the Natural Language Toolkit (NLTK) either\\non your own computer or at your institution. The NLTK can be freely downloaded\\nand it is strongly recommended that you install it on your own machine: Windows,\\nMac OSX and Linux distributions are available from http://nltk.org (last visited\\nApril 10th 2013) and some distributions of Linux have it in their package/software\\nmanagers. Full instructions are available at the cited website along with details of\\nassociated packages which should also be installed, including Python itself which is\\nalso freely available. Once you have installed the software you should also download\\nthe required datasets as explained in the textbook (Bird et al., 2009, p. 3).\\nYou should check the NLTK website to determine what versions of Python are\\nsupported. Current stable releases of NLTK are compatible with Python 2.6 and 2.7.\\nA version supporting Python 3 is under development and may be available for\\ntesting by the time you read this guide (as of April 2013).\\n1.6 How to use the guide/structure of the course\\nThis section gives a brief summary of each chapter. These learning outcomes are\\nlisted at the beginning of each main chapter and assume that you have worked\\nthrough the recommended readings and activities for that chapter.\\n1.6.1 Chapter 2: Introducing NLP: patterns and structures in language\\nThis chapter looks at different approaches to analysing texts, ranging from ‘shallow’\\ntechniques that focus on individual words and phrases to ‘deeper’ methods that\\nproduce a full representation of the grammatical structure of a sentence as a\\nhierarchical tree diagram. The chapter introduces two important formalisms:\\nregular expressions, which will play an important part throughout the course, and\\ncontext-free grammars which we return to in Chapter 6 of the subject guide.\\n1.6.2 Chapter 3: Getting to grips with natural language data\\nThis chapter looks at the different kinds of data resources that can be used for\\ndeveloping tools to harvest information that has been published as machine-readable\\ndocuments. In particular, we introduce the notion of a ‘corpus’ (pluralcorpora) – for\\nthe purposes of this course, a computer-readable collection of text or speech. The\\nNLTK includes a selection of excerpts from several well-known corpora and we\\nprovide brief descriptions of the most important of these and of the different formats\\nin which corpora are stored.\\n8'),\n",
              "  Document(id='b62a250e-9221-4752-93cc-d0ee809a7c88', metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 11}, page_content='CO3354 Introduction to natural language processing\\n1.3 Learning outcomes\\nOn successful completion of this course, including recommended readings, exercises\\nand activities, you should be able to:\\n1. utilise and explain the function of software tools such as corpus readers,\\nstemmers, taggers and parsers\\n2. explain the difference between regular and context-free grammars and deﬁne\\nformal grammars for fragments of a natural language\\n3. critically appraise existing Natural Language Processing (NLP) applications such\\nas chatbots and translation systems\\n4. describe some applications of statistical techniques to natural language analysis,\\nsuch as classiﬁcation and probabilistic parsing.\\nEach main chapter contains a list of learning outcomes speciﬁc to that chapter at the\\nbeginning, as well as a summary at the end of the chapter.\\n1.4 Reading list and other learning resources\\nThis is a list of textbooks and other resources which will be useful for all or most\\nparts of the course. Additional readings will be given at the start of each chapter. See\\nthe bibliography for a full list of books and articles referred to, including all ISBNs.\\nIn some cases several different books will be listed: you are not expected to read all\\nof them, rather the intention is to give you some alternatives in case particular texts\\nare hard to obtain.\\nEssential reading\\nBird, Klein, and Loper (2009): Natural Language Processing with Python. The full\\ntext including diagrams is freely available online at http://nltk.org/book (last\\nvisited 13th April 2013). The main textbook for this course, Natural Language\\nProcessing with Python is the outcome of a project extending over several years\\nto develop the Natural Language Toolkit (NLTK), which is a set of tools and\\nresources for teaching computational linguistics. The NLTK comprises a suite of\\nsoftware modules written in Python and a collection of corpora and other\\nresources. See section 1.5 below for advice on installing the NLTK and other\\nsoftware packages.\\nIn the course of working through this text you will gain some experience and\\nfamiliarity with the Python language, though you will not be expected to\\nproduce substantial original code as part of the learning outcomes of the course.\\nRecommended reading\\nPinker (2007). The Language Instinct. This book is aimed at non-specialists and\\ndeals with many psychological and cultural aspects of language. Chapter 4 is\\nparticularly relevant to this course as it provides a clear and accessible\\npresentation of two standard techniques for modelling linguistic structure:\\nﬁnite-state machines and context-free grammars (though Pinker does not in fact\\nuse these terms, as we will see in Chapter 2 of the subject guide).\\n6'),\n",
              "  Document(id='b04706e2-18ef-44ea-a57e-cb657eb2bcaa', metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 8}, page_content='Contents\\nAcknowledgement\\nThis subject guide draws closely on:\\nBird, S., E. Klein and E. Loper, Natural Language Processing with Python. (O’Reilly\\nMedia 2009) [ISBN 9780596516499; http://nltk.org/book].\\nYou will be expected to draw on it in your studies and to use the accompanying\\nsoftware package, the Natural Language Toolkit, which requires the Python\\nlanguage.Natural language processing with Python has been made available under\\nthe terms of the Creative Commons Attribution Noncommercial No-Derivative-Works\\n3.0 US License:http://creativecommons.org/licenses/by-nc-nd.3.0/us/legalcode (last\\nvisited 13th April 2013).\\n3'),\n",
              "  Document(id='137a4864-47ec-4cb6-b215-2c3bebbc2586', metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 41}, page_content='CO3354 Introduction to natural language processing\\n,)\\n(VP will\\n(VP join\\n(NP the board)\\n(PP-CLR as\\n(NP a nonexecutive director))\\n(NP-TMP Nov. 29)))\\n.))\\nCombined\\n( (S\\n(NP-SBJ\\n(NP (NNP Pierre) (NNP Vinken) )\\n(, ,)\\n(ADJP\\n(NP (CD 61) (NNS years) )\\n(JJ old) )\\n(, ,) )\\n(VP (MD will)\\n(VP (VB join)\\n(NP (DT the) (NN board) )\\n(PP-CLR (IN as)\\n(NP (DT a) (JJ nonexecutive) (NN director) ))\\n(NP-TMP (NNP Nov.) (CD 29) )))\\n(. .) ))\\n3.5.5 Gutenberg archive\\nThe NLTK includes a small selection of out-of-copyright literary texts from Project\\nGutenberg, an archive of free electronic books hosted at http://www.gutenberg.org/\\nSome of the texts included are:\\nJane Austen: Emma, Persuasion\\nGK Chesterton: Father Brown stories, The Man Who Was Thursday\\nWilliam Blake: Poems\\nMilton: Paradise Lost\\nShakespeare: Julius Caesar, Macbeth, Hamlet\\n3.5.6 Other corpora\\nSome further corpora included with the NLTK are:\\nThe Reuters corpus distributed with the NLTK contains 10,788 news documents\\ntotalling 1.3m words, partitioned into ‘training’ and ‘test’ sets. This split is for\\ntraining and testing machine learning algorithms: we return to this topic in\\nChapter 5 of this subject guide.\\n36'),\n",
              "  Document(id='30491109-0b7a-4fde-8b33-34ed7c115a21', metadata={'source': '/content/DOCUMENTS/NLP50.pdf', 'page': 35}, page_content='CO3354 Introduction to natural language processing\\nYour turn. You may also ﬁnd it useful to attempt some of the exercises provided at\\nthe end of each chapter.\\nFrom this chapter onwards you will be running Python sessions and using the NLTK.\\nYou should get into the habit of starting sessions with the following commands:\\n>>> from __future__ import division\\n>>> import nltk, re, pprint\\nOne of the features that makes the Python language suitable for natural language\\napplications is the very ﬂexible treatment of data structures such as lists, strings and\\nsequences. You should be familiar with these structures from previous programming\\ncourses, but should ensure you understand the way they are handled in Python. For\\nthis chapter, only lists are relevant and you should study Bird et al. (2009, section\\n1.2) before trying any of the learning activities in this chapter.\\n3.3 Corpora and other data resources\\nAs explained in the previous chapter, much natural language processing relies on\\nlarge collections of linguistic data known as corpora (plural of corpus). A corpus can\\nbe simply deﬁned as no more than a collection of language data, composed of\\nwritten texts, transcriptions of speech or a combination of recorded speech and\\ntranscriptions.\\nCorpora fall into three broad categories (McEnery, 2003, p.450):\\nMonolingual corpora consist, as the name suggests, of data from a single\\nlanguage.\\nComparable corpora include a range of monolingual corpora in different\\nlanguages, preferably with a similar level of balance and representativeness, and\\ncan be used for contrastive studies of those languages.\\nParallel corpora include original texts in one language with translations of those\\ntexts in one or more different languages. Parallel corpora can be used to train\\nstatistical translation systems.\\nA corpus is generally expected to have additional characteristics: corpora are usually\\nconstructed so as to bebalanced and representative of a particular domain (McEnery\\nand Wilson, 2001, pp. 29–30). (Sometimes the term is used more loosely to cover\\nany large collection of language data which need not have been compiled\\nsystematically , as in the phrase ‘the web as corpus’.)Sampling theory is a branch of\\nstatistics that deals with questions such as: how many respondents are needed in an\\nopinion poll for the results to be considered to represent public opinion at large?\\nSimilar considerations arise in corpus linguistics. This is particularly important if a\\ncorpus is to be used for quantitative analysis of the kind described in Chapter 5: if\\nthe corpus data is skewed or unrepresentative then results of the analysis may not be\\nreliable. These considerations may be less important if the corpus is collected for the\\nliterary or historical interest of the documents that make it up, as is the case with\\nProject Gutenberg for example.\\nFor example, Bird et al. (2009, pp. 407–412) refer to the TIMIT corpus, an annotated\\nspeech corpus developed by Texas Instruments and MIT. To ensure\\nrepresentativeness, it was designed to include a wide coverage of dialect variations.\\nCorpus builders need to exercise expert judgment in deciding on the sampling frame,\\n30')]}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "FWYt7dWKY1o9",
        "outputId": "a59bf8ea-66a1-4439-b98d-558c71e365d5",
        "collapsed": true
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NLP stands for Natural Language Processing. It is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It involves the development of algorithms and statistical models that enable computers to process, understand, and generate natural language data, such as text or speech.\\n\\nThe goal of NLP is to enable computers to perform tasks that would normally require human-level understanding of language, such as:\\n\\n* Text classification and sentiment analysis\\n* Language translation and machine translation\\n* Speech recognition and speech synthesis\\n* Information extraction and Named Entity Recognition (NER)\\n* Question answering and dialogue systems\\n\\nNLP has numerous applications in areas such as:\\n\\n* Chatbots and virtual assistants\\n* Sentiment analysis and opinion mining\\n* Language translation and localization\\n* Text summarization and information retrieval\\n* Speech recognition and voice assistants\\n\\nIn the context of the course guide provided, NLP is introduced as a field that deals with the analysis and processing of natural language data, with a focus on computational approaches to understanding language. The course covers topics such as regular expressions, context-free grammars, corpora, and statistical techniques for natural language analysis.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _answer(query):\n",
        "    result = qa_1(query)\n",
        "    return result['answer']"
      ],
      "metadata": {
        "id": "f1OdQTNM34C1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3gAPNBHHwSfw",
        "outputId": "194e84ad-078f-4d41-c573-94dfd090ebab"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.2 (from gradio)\n",
            "  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.42.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.9.1-py3-none-any.whl (57.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.8.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.9.1 gradio-client-1.5.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.8.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "iface = gr.Interface(\n",
        "    fn=_answer,\n",
        "    inputs=gr.Textbox(label=\"Ask a question \"),\n",
        "    outputs=gr.Textbox(label=\"Answer\"),\n",
        "    live=True,\n",
        ")\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "bDISAxru3bdg",
        "outputId": "aca4a4aa-e61a-47a6-a812-d0d19a83504d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f587e68e38477817d2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f587e68e38477817d2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AcC9O5hc4ROPpY6TaeIr3KiB6mtPI-5d",
      "authorship_tag": "ABX9TyM4ptpLJ8j+aQX1EU2OkMur",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b488044648e94bee81836d91854e3b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab84d33893c746bf920b0cfa4d0fdabe",
              "IPY_MODEL_a64b574b93b744ba865b91e9cb760008",
              "IPY_MODEL_3709d15c9201489db7791fc70e219f40"
            ],
            "layout": "IPY_MODEL_daba22c335c740e398c1867dc54b9a13"
          }
        },
        "ab84d33893c746bf920b0cfa4d0fdabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0faba8118a5f43f4980815729c087e60",
            "placeholder": "​",
            "style": "IPY_MODEL_9b37a6129d0b4a6c821b7199ee9182ab",
            "value": "Fetching 5 files: 100%"
          }
        },
        "a64b574b93b744ba865b91e9cb760008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bc353e833ae40a78a431c68a6a2ae8c",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af66c1190e2b425d913243f90a4aa420",
            "value": 5
          }
        },
        "3709d15c9201489db7791fc70e219f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45d438c736e34c67aab3b09b34ce61a8",
            "placeholder": "​",
            "style": "IPY_MODEL_dbbcd61b9b4843c594831f26aeeb967f",
            "value": " 5/5 [00:05&lt;00:00,  3.35s/it]"
          }
        },
        "daba22c335c740e398c1867dc54b9a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0faba8118a5f43f4980815729c087e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b37a6129d0b4a6c821b7199ee9182ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bc353e833ae40a78a431c68a6a2ae8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af66c1190e2b425d913243f90a4aa420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45d438c736e34c67aab3b09b34ce61a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbcd61b9b4843c594831f26aeeb967f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86057ee7a14c42fb809a00c67b84576e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecae364179d54499acced04d08876e98",
              "IPY_MODEL_92543d4e7ad147b3b40853eeabaad2b5",
              "IPY_MODEL_31e96b6dc6764a6bbd12c96143f49d8a"
            ],
            "layout": "IPY_MODEL_04a7654659dd49ca845791118b160ddb"
          }
        },
        "ecae364179d54499acced04d08876e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d8011cc9f734d6ea24f518642eddda2",
            "placeholder": "​",
            "style": "IPY_MODEL_e3a8668fe80546b7871b75e0acab71be",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "92543d4e7ad147b3b40853eeabaad2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ea8c4359eb4a898e91dd67a354c52f",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f941b4e111c240a6afe47575ca3e8a54",
            "value": 695
          }
        },
        "31e96b6dc6764a6bbd12c96143f49d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_201ec69d3c9b4ff1a3e85a8689b63ce9",
            "placeholder": "​",
            "style": "IPY_MODEL_75715aad8f3e4fe7a6841b32069b1df4",
            "value": " 695/695 [00:00&lt;00:00, 5.65kB/s]"
          }
        },
        "04a7654659dd49ca845791118b160ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d8011cc9f734d6ea24f518642eddda2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3a8668fe80546b7871b75e0acab71be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8ea8c4359eb4a898e91dd67a354c52f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f941b4e111c240a6afe47575ca3e8a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "201ec69d3c9b4ff1a3e85a8689b63ce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75715aad8f3e4fe7a6841b32069b1df4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1679bedcb0947c0a1c5c3f33469f152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a69276f3e9fc484ebef956e5cb6744bf",
              "IPY_MODEL_16fdb64785094e07b7f6fb88f521d966",
              "IPY_MODEL_1735cbd629694b6291bc01fa47aac7e8"
            ],
            "layout": "IPY_MODEL_ad47cd2f53be412bb8d26bce15a5c9ab"
          }
        },
        "a69276f3e9fc484ebef956e5cb6744bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05a04d78ef354d68ba4c7fd5c1b9262c",
            "placeholder": "​",
            "style": "IPY_MODEL_50ee82c3a28548f39eecc2eb01594d67",
            "value": "config.json: 100%"
          }
        },
        "16fdb64785094e07b7f6fb88f521d966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b17a90189f4ffa95c2f6ffb545b095",
            "max": 740,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_848e45da8949483fa67934889316b3fb",
            "value": 740
          }
        },
        "1735cbd629694b6291bc01fa47aac7e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_709ef1a2ad3f45f5a5e87a3073368d4f",
            "placeholder": "​",
            "style": "IPY_MODEL_16a8801400b74da9b84acf6085331f5c",
            "value": " 740/740 [00:00&lt;00:00, 5.55kB/s]"
          }
        },
        "ad47cd2f53be412bb8d26bce15a5c9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a04d78ef354d68ba4c7fd5c1b9262c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50ee82c3a28548f39eecc2eb01594d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7b17a90189f4ffa95c2f6ffb545b095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "848e45da8949483fa67934889316b3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "709ef1a2ad3f45f5a5e87a3073368d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a8801400b74da9b84acf6085331f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb1de2bad3714f218f4159196f2de298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ee25276dfd04b8d9ae3b27932fb144b",
              "IPY_MODEL_aa53a60d6dbe4c4b89ccc1be6b71b279",
              "IPY_MODEL_71907eb4654b4eeca53008b4338b9b91"
            ],
            "layout": "IPY_MODEL_4599678f724844eda25af210debaad94"
          }
        },
        "0ee25276dfd04b8d9ae3b27932fb144b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c053fc9091d4caf8ff1f233f9fa6bb7",
            "placeholder": "​",
            "style": "IPY_MODEL_f6aa661d9e4f407799fb9dc860e9ae8a",
            "value": "tokenizer.json: 100%"
          }
        },
        "aa53a60d6dbe4c4b89ccc1be6b71b279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a276267e1e49b1a30453e7d6731d88",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44115cb79ce74db3b4c034eb9c3611e9",
            "value": 711396
          }
        },
        "71907eb4654b4eeca53008b4338b9b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52af36c4358f433390fa269614025001",
            "placeholder": "​",
            "style": "IPY_MODEL_8d96d5ac977b4fdc9696a2d0989e3bf6",
            "value": " 711k/711k [00:00&lt;00:00, 2.92MB/s]"
          }
        },
        "4599678f724844eda25af210debaad94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c053fc9091d4caf8ff1f233f9fa6bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6aa661d9e4f407799fb9dc860e9ae8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46a276267e1e49b1a30453e7d6731d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44115cb79ce74db3b4c034eb9c3611e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52af36c4358f433390fa269614025001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d96d5ac977b4fdc9696a2d0989e3bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "451c4a807b5b4d0eb2c97137da8c78a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7c60e29e43249a89b204658a49a479f",
              "IPY_MODEL_0a825504c36e494cbd5cf1b925567acc",
              "IPY_MODEL_158ca19c0db0476dbc1fce7a550d01ef"
            ],
            "layout": "IPY_MODEL_ae818d4807574ed4844a3d1961f7e36d"
          }
        },
        "e7c60e29e43249a89b204658a49a479f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0ac3fc489674822a30327438b199f58",
            "placeholder": "​",
            "style": "IPY_MODEL_759c0e6dc29d4861a5b36aa32879d2aa",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0a825504c36e494cbd5cf1b925567acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6f94851b55e4211a201c8f54eeb77b5",
            "max": 1242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c9b108147ab4a58813c10a90ad88598",
            "value": 1242
          }
        },
        "158ca19c0db0476dbc1fce7a550d01ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18372524d32d4158a2ef584b24e80eaf",
            "placeholder": "​",
            "style": "IPY_MODEL_c95bbc5c63f24a7eb7f499976fa4f4a9",
            "value": " 1.24k/1.24k [00:00&lt;00:00, 15.5kB/s]"
          }
        },
        "ae818d4807574ed4844a3d1961f7e36d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ac3fc489674822a30327438b199f58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "759c0e6dc29d4861a5b36aa32879d2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f94851b55e4211a201c8f54eeb77b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c9b108147ab4a58813c10a90ad88598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18372524d32d4158a2ef584b24e80eaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c95bbc5c63f24a7eb7f499976fa4f4a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c13ff7d7533440558e02e434af1685ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d2e0865feea4b39be9beb36b2bd2c95",
              "IPY_MODEL_29ac2f20d5874883a43059a2c5cf5ba5",
              "IPY_MODEL_d611d3d2dfdb401784b415a0309dc335"
            ],
            "layout": "IPY_MODEL_7233d43ae19e439db6386da49a3cb7c2"
          }
        },
        "1d2e0865feea4b39be9beb36b2bd2c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5632cc18690a4117ba7315db2410e978",
            "placeholder": "​",
            "style": "IPY_MODEL_3feda0417f4c407d94d15b3cbfb13322",
            "value": "model_optimized.onnx: 100%"
          }
        },
        "29ac2f20d5874883a43059a2c5cf5ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a48254a2e414def9bab87673024498b",
            "max": 217824172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7d64ed4c34645ae8587d46cbddbf4ed",
            "value": 217824172
          }
        },
        "d611d3d2dfdb401784b415a0309dc335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_082ac6d23cc44a8ebea4e19a99786d69",
            "placeholder": "​",
            "style": "IPY_MODEL_d783e44fa9624297b02b6faf05581f6a",
            "value": " 218M/218M [00:05&lt;00:00, 42.5MB/s]"
          }
        },
        "7233d43ae19e439db6386da49a3cb7c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5632cc18690a4117ba7315db2410e978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3feda0417f4c407d94d15b3cbfb13322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a48254a2e414def9bab87673024498b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7d64ed4c34645ae8587d46cbddbf4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "082ac6d23cc44a8ebea4e19a99786d69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d783e44fa9624297b02b6faf05581f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
